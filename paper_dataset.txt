paper_id	venue	authors	year	title	index_keys	author_keys	abstract
811C1626	International Conference on Data Mining	oded mainon + lior rokach	2001	Theory and applications of attribute decomposition	databases + pattern classification + attribute decomposition + records + data mining + testing + greedy procedure + classification model + bayesian methods + learning artificial intelligence + predictive models + industrial engineering + data visualization + Bayes methods + D-IFN + learning (artificial intelligence) + Bayesian combination + principal component analysis + subsets	AuthorProvided Keywords Not Found	This paper examines the attribute decomposition approach with simple Bayesian combination for dealing with classification problems that contain high number of attributes and moderate numbers of records. According to the attribute decomposition approach, the set of input attributes is automatically decomposed into several subsets. A classification model is built for each subset, then all the models are combined using simple Bayesian combination. This paper presents theoretical and practical foundation for the attribute decomposition approach. A greedy procedure, called D-IFN, is developed to decompose the input attributes set into subsets and build a classification model for each subset separately. The results achieved in the empirical compart. son testing with well-known classification methods (like C4.5) indicate the superiority of the decomposition approach
7F302FC1	International Conference on Data Mining	marzena kryszkiewicz	2001	Concise representation of frequent patterns based on disjunction-free generators	association rule + pattern classification + concise representation + frequent patterns + data mining + disjunction-free generators + association rules + sequential patterns + rule discovery + set theory + relational databases + lossless representations + computer science + clustering algorithms + very large databases + knowledge based systems + theorem proving + frequent pattern discovery + data mining problems + frequent itemsets	AuthorProvided Keywords Not Found	Many data mining problems require the discovery of frequent patterns in order to be solved. Frequent itemsets are useful in the discovery of association rules, episode rules, sequential patterns and clusters. The number of frequent itemsets is usually huge. Therefore, it is important to work out concise representations of frequent itemsets. We describe three basic lossless representations of frequent patterns in a uniform way and offer a new lossless representation of frequent patterns based on disjunction-free generators. The new representation is more concise than two of the basic representations and more efficiently computable than the third representation. We propose an algorithm for determining the new representation
8033184B	International Conference on Data Mining	junesuh cho + nabil r adam	2001	Efficient splitting rules based on the probabilities of pre-assigned intervals	image object classification + image classification + classification methods + probability + tree searching + splitting rules + rule based + optimisation + split rules + optimal tree + pre-assigned interval probabilities + knowledge based systems + threshold values + optimal cutoff point + computational complexity	AuthorProvided Keywords Not Found	The paper describes novel methods for classification in order to find an optimal tree. Unlike the current splitting rules that are provided by searching all threshold values, the paper proposes splitting rules that are based on the probabilities of pre-assigned intervals. In experiments, we demonstrate that our methods properly classify image objects based on new split rules
80B05405	International Conference on Data Mining	david j hand + richard j bolton	2001	Significance tests for patterns in continuous data	pattern analysis + mathematics + data mining + probability + testing + earthquake locations + flow cytometry measurements + uncertainty handling + California + sequences + uncertainty + continuous data patterns + statistical tests + statistical test + very large databases + large data sets + detected pattern uncertainty + phytoplankton + flow cytometry + statistical analysis + significance tests	AuthorProvided Keywords Not Found	The authors consider the question of uncertainty of detected patterns in data mining. In particular, we develop statistical tests for patterns found in continuous data, indicating the significance of these patterns in terms of the probability that they have occurred by chance. We examine the performance of these tests on patterns detected in several large data sets, including a data set describing the locations of earthquakes in California and another describing flow cytometry measurements on phytoplankton
7F7E5056	International Conference on Data Mining	changhung lee + chengru lin + mingsyan chen	2001	On mining general temporal association rules in a publication database	transaction processing + association rule + 2-itemset + filtering threshold + cumulant + data mining + association rules + marketing data processing + transactions + association rule mining + exhibition periods + progressive-partition-miner algorithm + very large databases + general temporal association rule mining + publication database	AuthorProvided Keywords Not Found	In this paper, we explore a new problem of mining general temporal association rules in publication databases. In essence, a publication database is a set of transactions where each transaction T is a set of items, each containing an individual exhibition period. The current model of association rule mining is not able to handle a publication database due to the following fundamental problems: (1) lack of consideration of the exhibition period of each individual item; and (2) lack of an equitable support counting basis for each item. To remedy this, we propose an innovative algorithm, progressive-partition-miner (PPM), to discover general temporal association rules in a publication database. The basic idea of PPM is to first partition the publication database into exhibition periods of items and then progressively accumulate the occurrence count of each candidate 2-itemset based on the intrinsic partitioning characteristics. PPM is also designed to employ a filtering threshold in each partition to prune out those cumulatively infrequent 2-itemsets at an early stage. Explicitly, the execution time of PPM is, in orders of magnitude, smaller than those required by schemes which are directly extended from existing methods
80B3895C	International Conference on Data Mining	zarrin langari + frank wm tompa	2001	Subject classification in the Oxford English Dictionary	iterative methods + k nearest neighbors + senses + data mining + classification metrics + subject classification + nearest neighbor + multiple signal classification + computer science + term weighting + naive bayes + labeling + information retrieval method + definitions + testing + information retrieval + lexical information + classification + cited quotations + labels + information guide + subject labels + speech + iterative probabilistic method + naive Bayes + expectation maximization + Bayes methods + probabilistic method + Oxford English Dictionary + highly structured text mining + dictionaries	AuthorProvided Keywords Not Found	The Oxford English Dictionary is a valuable source of lexical information and a rich testing ground for mining highly structured text. Each entry is organized into a hierarchy of senses, which include definitions, labels and cited quotations. Subject labels distinguish the subject classification of a sense, for example they signal how a word may be used in anthropology, music or computing. Unfortunately subject labeling in the dictionary is incomplete. To overcome this incompleteness, we attempt to classify the senses (i.e., definitions) in the dictionary by their subjects, using the citations as an information guide. We report on four different approaches: k nearest neighbors, a standard classification technique; term weighting, an information retrieval method dealing with text; naive Bayes, a probabilistic method; and expectation maximization, an iterative probabilistic method. Experimental performance of these methods is compared based on standard classification metrics
7DD610EC	International Conference on Data Mining	chingyao wang + tzungpei hong + shianshyong tseng	2001	Maintenance of sequential patterns for record deletion	record deletion + very large databases + upper support threshold + data mining + safety bound + deleted customer sequences + incremental mining algorithm + sequential pattern maintenance + sequences + pre-large sequences + lower support threshold	AuthorProvided Keywords Not Found	We previously proposed an incremental mining algorithm for maintenance of sequential patterns based on the concept of pre-large sequences as new records were inserted. In this paper we attempt to apply the concept of pre-large sequences to maintain sequential patterns as records are deleted. Pre-large sequences are defined by a lower support threshold and an upper support threshold. They act as buffers to avoid the movements of sequential patterns directly from large to small and, vice-versa. Our proposed algorithm does not require rescanning original databases until the accumulative amount of deleted customer sequences exceeds a safety bound, which depends on database size. As databases grow larger, the number of deleted customer sequences allowed before database rescanning is required also grows. The proposed approach is thus efficient for a large database
64D0F43A	International Conference on Data Mining	henri briand + pascale kuntz + francois velin	2001	Web cartography for online site promotion: an algorithm for clustering Web resources	spectral decomposition + application software + iterative methods + search engines + hyperlink creation + data mining + hypermedia + corpus + matrix decomposition + business graphics + Web cartography + candidate sites + navigation + graphs + clustering algorithms + text data + data visualisation + iterative approach + geometric space + online site promotion + Laplacian matrix + graph partitioning + strongly connected sites + computer aided design + information resources + stress + site graph partitioning problem + maps + link network + computer-aided design + targeted visitor flow + marketing data processing + design automation + pattern clustering + Cognac + graph analyses + semantic analyses + World Wide Web resource clustering algorithm + laplacian matrix	AuthorProvided Keywords Not Found	Presents a Web cartography approach to be used in the context of online site promotion. The overall objective is to provide users with handy maps offering information about candidate sites for the creation of hyperlinks that enable a large flow of targeted visitors. Two main types of data must be considered: texts and hyperlinks. We propose to exploit the latter to construct a relevant corpus on which semantic as well as graph analyses can be applied. The stress is put on the clustering of Web resources based on the link network, which makes it possible to highlight groups of strongly connected sites which are of the utmost interest for our application. To tackle the site graph partitioning problem, we turn to a promising iterative approach initially developed in the context of computer-aided design. It uses spectral decomposition of the Laplacian matrix to embed the considered graph in a geometric space where efficient methods can be applied. An algorithm that was adapted from an existing one implements the method. Experiments were conducted on a real application case concerning the promotion of a site dealing with Cognac. We present the obtained map as well as leads to exploit it
7EC858CC	International Conference on Data Mining	anders holst + daniel gillblad	2001	Dependency derivation in industrial process data	dependency derivation + data mining + time series + industrial process data + manufacturing data processing + mutual information rate + entropy + computer science + optimization + time measurement + probability distribution + variable selection + mutual information + dependency graphs	AuthorProvided Keywords Not Found	In many industrial processes, finding dependencies and the creation of dependency graphs can increase the understanding of the system significantly. This knowledge can then be used for further optimization and variable selection. Most of the measured attributes in these cases come in the form of time series. There are several ways of determining correlation between series, most of them suffering from specific problems when applied to real-world data. Here, a well performing measure based on the mutual information rate is derived and discussed with results from both synthetic and real data
5FE9C8DA	International Conference on Data Mining	joao gama	2001	Functional trees for classification	discriminant function + benchmark data sets + statistical significance + data mining + supervised learning + generalization ability + multiple representation languages + statistically significant confidence levels + leaf nodes + multivariate tests + decision tree learning + functional leaves + decision tree + regression domains + model sizes + linear model + univariate decision tree + search space + pattern classification + algorithm design and analysis + space exploration + testing + functional trees + model-tree algorithms + multivariate tree generation + confidence level + classification + generalisation (artificial intelligence) + tree searching + linear models + attribute combinations + decision trees + tree pruning + constructive induction + search spaces + decision nodes + decision tests + learning by example + algorithm design	AuthorProvided Keywords Not Found	The design of algorithms that explore multiple representation languages and explore different search spaces has an intuitive appeal. In the context of classification problems, algorithms that generate multivariate trees are able to explore multiple representation languages by using decision tests based on a combination of attributes. The same applies to model-tree algorithms in regression domains, but using linear models at leaf nodes. In this paper, we study where to use combinations of attributes in decision tree learning. We present an algorithm for multivariate tree learning that combines a univariate decision tree with a discriminant function by means of constructive induction. This algorithm is able to use decision nodes with multivariate tests, and leaf nodes that predict a class using a discriminant function. Multivariate decision nodes are built when growing the tree, while functional leaves are built when pruning the tree. Functional trees can be seen as a generalization of multivariate trees. Our algorithm was compared against to its components and two simplified versions using 30 benchmark data sets. The experimental evaluation shows that our algorithm has clear advantages with respect to the generalization ability and model sizes at statistically significant confidence levels
NE65	International Conference on Data Mining	S. Sahar	2001	Interestingness preprocessing	overfitting + data mining + task-independent methods + interestingness pre-processing + knowledge discovery + importance sampling + interestingness analysis framework + transition + database size + potentially interesting patterns + rule mining + very large databases + user-independent methods + domain-independent methods	AuthorProvided Keywords Not Found	As the size of databases increases, the number of rules mined from them also increases, often to an extent that overwhelms users. To address this problem, an important part of the knowledge discovery in databases (KDD) process is dedicated to determining which of these patterns is interesting. In this paper, we define the interestingness pre-processing (IPP) step and introduce a new framework for interestingness analysis. In a similar fashion to data pre-processing, this pre-processing should always be applied prior to interestingness processing. A strict requirement, and the biggest challenge, in defining IPP techniques is that the pre-processing does not eliminate any potentially interesting patterns. That is, the pre-processing methods must be domain-, task- and user-independent. This property differentiates the pre-processing methods from existing interestingness criteria and, since they can be applied automatically, makes them very useful. This generic nature also makes them rare: pre-processing methods are very challenging to define. We define the first two IPP techniques (overfitting and transition) and present empirical results of applying them to six databases. The results indicate that the IPP step is very powerful: in most cases, an average of half the rules mined were eliminated by the application of the two IPP techniques. These results are particularly significant since no user interaction is required to achieve them
7E1F6EC4	International Conference on Data Mining	d cooke + l de braal + ernest v garcia + edward omiecinski + c e ordonez + norberto f ezquerra + elizabeth g krawczynska + cesar a santana + javier taboada	2001	Mining constrained association rules to predict heart disease	transaction processing + association rule + transaction format + data analysis + data mining + association rules + diseases + medical information systems + heart disease prediction + cardiology + medical data + biomedical imaging + medical computing + constrained association rule mining	AuthorProvided Keywords Not Found	This work describes our experiences in discovering association rules in medical data to predict heart disease. We focus on two aspects of this work: mapping medical data to a transaction format suitable for mining association rules, and identifying useful constraints. Based on these aspects we introduce an improved algorithm to discover constrained association rules. We present an experimental section explaining several interesting discovered rules
NE12	International Conference on Data Mining	H. M. Jamil	2001	Ad hoc association rule mining as SQL3 queries	query processing + ad hoc association rule mining + object-oriented databases + data mining + item set patterns + aggregation + join query + relational databases + object relational database + SQL3 queries + SQL + large item set	AuthorProvided Keywords Not Found	Although there have been several encouraging attempts at developing methods for data mining using SQL, simplicity and efficiency still remain significant impediments for further development. In this paper, we propose a significantly new approach and show that any object relational database can be mined for association rules without any restructuring or preprocessing using only basic SQL3 constructs and functions, and hence no additional machinery is necessary. In particular, we show that the cost of computing association rules for a given database does not depend on support and confidence thresholds. More precisely, the set of large items can be computed using one simple join query and an aggregation once the set of all possible meets (least fixpoint) of item set patterns in the input table is known. The principal focus of this paper is to demonstrate that several SQL3 expressions exists for the mining of association rules
737FF8BE	International Conference on Data Mining	shoji hirano + shusaku tsumoto	2001	Indiscernibility degree of objects for evaluating simplicity of knowledge in the clustering procedure	rough sets + classification knowledge simplicity evaluation + data mining + clustering procedure + iterative refinement + set theory + scalability + equivalence relations + threshold level + simple clusters + clustering algorithms + very large databases + rough set + coarse classification + databases + data analysis + algorithm design and analysis + equivalence class + sections + biomedical informatics + pattern clustering + indiscernibility degree + equivalence relation + coarse clusters + rough set-based clustering method + rough set theory + equivalence classes + artificial data	AuthorProvided Keywords Not Found	The paper presents a novel, rough set-based clustering method that enables the evaluation of classification knowledge simplicity during the clustering procedure. The method iteratively refines equivalence relations so that they become a more simple set of relations that give adequate coarse classification to the objects. At each step of the iteration, the importance of the equivalence relation is evaluated on the basis of the newly introduced measure, indiscernibility degree. An indiscernibility degree is defined as a ratio of equivalence relations that classify the two objects into the same equivalence class. If an equivalence relation has the ability to discern two objects that have a high indiscernibility degree, a very fine classification is performed and then modified to regard them as indiscernible objects. The refinement is repeated, decreasing the threshold level of indiscernibility degree, and finally simple clusters can be obtained. Experimental results on the artificial data shows that iterative refinement of equivalence relation leads to successful generation of coarse clusters that can be represented by simple knowledge
8076F0DE	International Conference on Data Mining	jamil saquer + jitender s deogun + sherri k harms + tsegaye tadesse	2001	Discovering representative episodal association rules from event sequences using frequent closed episode sets and event constraints	association rule + data mining + association rules + automated weather stations + event sequences + representative episodal association rule discovery + multiple climatology datasets + government + clustering algorithms + time series data + event constraints + frequent itemsets + risk management + pattern analysis + hydrology + geophysics computing + time series + frequent closed episode sets + transactions + formal concept analysis + decision support systems + time measurement + decision support system + climatology + drought risk management decision support system	AuthorProvided Keywords Not Found	Discovering association rules from time-series data is an important data mining problem. The number of potential rules grows quickly as the number of items in the antecedent grows. It is therefore difficult for an expert to analyze the rules and identify the useful. An approach for generating representative association rules for transactions that uses only a subset of the set of frequent itemsets called frequent closed itemsets was presented by Saquer and Deogun (2000). We employ formal concept analysis to develop the notion of frequent closed episodes. The concept of representative association rules is formalized in the context of event sequences. Applying constraints to target highly, significant rules further reduces the number of rules. Our approach results in a significant reduction of the number of rules generated, while maintaining the minimum set of relevant association rules and retaining the ability to generate the entire set of association rules with respect to the given constraints. We show how our method can be used to discover associations in a drought risk management decision support system and use multiple climatology datasets related to automated weather stations
7DAE398E	International Conference on Data Mining	michael j anderson	2001	Knowledge discovery from diagrammatically represented data	artificial intelligent + autonomous artificially intelligent agent + database languages + gray scale + data mining + information retrieval + diagrammatic data mining + diagrammatic information + diagrams + knowledge discovery + Diagrammatic SQL + software agents + sql + SQL + intelligent agent + knowledge representation + diagrammatically represented data + information systems + visual programming	AuthorProvided Keywords Not Found	Knowledge discovery from diagrammatic data can be facilitated by a language that permits queries on such data. Such a language (Diagrammatic SQL) is being developed to expedite the development of an autonomous artificial intelligent agent with a capacity to deal with diagrammatic information. This language is described and examples of how it can be used to facilitate diagrammatic data mining are detailed
7080AFC1	International Conference on Data Mining	yueshi lee + showjane yen	2001	An efficient data mining technique for discovering interesting sequential patterns	databases + sequential pattern discovery + user requests + customer transactions + information management + data mining + high level languages + interested items + data mining language + interesting sequential pattern discovery + sequential purchasing behavior discovery + computer science + very large databases + data mining technique + petroleum + bismuth + retail data processing	AuthorProvided Keywords Not Found	Mining sequential patterns is used to discover sequential purchasing behaviors of most customers from a large amount of customer transactions. A data mining language is presented. From the data mining language, users can specify the interested items and the criteria of the sequential patterns to be discovered. Also, an efficient data mining technique is proposed to extract sequential patterns according to user requests
7E575401	International Conference on Data Mining	g richards + v j raywardsmith	2001	Discovery of association rules in tabular data	association rule + data analysis + association rule discovery + ARA algorithm + satisfiability + data mining + testing + association rules + dense miner algorithm + information systems + tabular data + constraints	AuthorProvided Keywords Not Found	In this paper we address the problem of finding all association rules in tabular data. An algorithm, ARA, for finding rules, that satisfy clearly specified constraints, in tabular data is presented. ARA is based on the dense miner algorithm but includes an additional constraint and an improved method of calculating support. ARA is tested and compared with our implementation of dense miner; it is concluded that ARA is usually more efficient than dense miner and is often considerably more so. We also consider the potential for modifying the constraints used in ARA in order to find more general rules
6E6F54C1	International Conference on Data Mining	katia lida kermanidis + manolis maragoudakis + nikolaos fakotakis + george k kokkinakis	2001	Learning automatic acquisition of subcategorization frames using Bayesian inference and support vector machines	learning automata + bayesian belief network + feedforward backpropagation neural networks + computational linguistics + Modern Greek + natural language human computer interaction systems + bayesian methods + phrase chunking + decision table + corpora + morphological tagging + belief networks + Bayesian inference + support vector machines + robustness + automatic verb subcategorization frame acquisition + machine learning methods + performance evaluation + machine learning + inference mechanisms + decision tables + vector quantisation + Bayesian belief network learning + support vector machine + backpropagation + learning vector quantization + minimal linguistic resources + natural languages + human computer interaction + natural language + bayesian inference + feedforward neural nets	AuthorProvided Keywords Not Found	Learning Bayesian belief networks (BBN) from corpora and support vector machines (SVM) have been applied to the automatic acquisition of verb subcategorization frames for Modern Greek. We are incorporating minimal linguistic resources, i.e. basic morphological tagging and phrase chunking, to demonstrate that verb subcategorization, which is of great significance for developing robust natural language human computer interaction systems, could be achieved using large corpora, without having any general-purpose, syntactic parser at all. In addition, apart from BBN and SVM, which have not previously used for this task, we have experimented with three well-known machine learning methods (feedforward backpropagation neural networks, learning vector quantization and decision tables), which are also being applied to the task of verb subcategorization frame defection for the first time. We argue that both BBN and SVM are well suited for learning to identify verb subcategorization frames. Empirical results will support this claim. Performance has been methodically evaluated using two different corpora types, one balanced and one domain-specific in order to determine the unbiased behaviour of the trained models. Limited training data are proved to endow with satisfactory results. We have been able to achieve precision exceeding 80% on the identification of subcategorization frames which were not known beforehand
7E0EDDBF	International Conference on Data Mining	s noel + vijay v raghavan + cheehung henry chu	2001	Visualizing association mining results through hierarchical clusters	search engines + visualization + web pages + data mining + information retrieval + hypermedia + hypertext documents + itemset supports + hierarchical clusters + Science Citation Index + hierarchical clustering dendrograms + directed graphs + association mining results visualization + inter-item distances + link mining + www + WWW + directed graph + citation analysis + hierarchical clustering + frequently occurring itemsets + information systems + collection link structure + information spaces	AuthorProvided Keywords Not Found	We propose a new methodology for visualizing association mining results. Inter-item distances are computed from combinations of itemset supports. The new distances retain a simple pairwise structure, and are consistent with important frequently occurring itemsets. Thus standard tools of visualization, e.g. hierarchical clustering dendrograms can still be applied, while the distance information upon which they are based is richer. Our approach is applicable to general association mining applications, as well as applications involving information spaces modeled by directed graphs, e.g. the Web. In the context of collections of hypertext documents, the inter-document distances capture the information inherent in a collection's link structure, a form of link mining. We demonstrate our methodology with document sets extracted from the Science Citation Index, applying a metric that measures consistency between clusters and frequent itemsets
NE108	International Conference on Data Mining	Xiong Wang	2001	α-surface and its application to mining protein data	pattern classification + biology computing + protein data mining + surface structures + data mining + proteins + α-surface extraction algorithm + pattern discovery + molecular biophysics + 3D Euclidean space + finite points set + protein classification	AuthorProvided Keywords Not Found	Given a finite set of points in three dimensional Euclidean space R3, the subset that forms its surface could be different when observed at different levels of detail. In this paper we introduce a notion called α-surface. We present an algorithm that extracts the α-surface from a finite set of points in R3. We apply the algorithm to extracting the α-surfaces of proteins and discover patterns from these surface structures using a pattern discovery algorithm. We then use these patterns to classify the proteins. Experimental results demonstrate the good performance of the proposed approach
7E2B176C	International Conference on Data Mining	tom fawcett	2001	Using rule sets to maximize ROC performance	categorical classifications + pattern classification + decision theory + ROC performance maximization + rule sets + sensitivity analysis + data mining + probability + skewed class distributions + robustness + association rules + classification accuracy + machine learning + scoring performance maximization + learning artificial intelligence + optimisation + classification rule learning + performance index + instance scores + receiver operating characteristic + learning (artificial intelligence) + unequal error costs + errors	AuthorProvided Keywords Not Found	Rules are commonly used for classification because they are modular intelligible and easy to learn. Existing work in classification rule learning assumes the goal is to produce categorical classifications to maximize classification accuracy. Recent work in machine learning has pointed out the limitations of classification accuracy: when class distributions are skewed or error costs are unequal, an accuracy-maximizing rule set can perform poorly. A more flexible use of a rule set is to produce instance scores indicating the likelihood that an instance belongs to a given class. With such an ability, we can apply rule sets effectively when distributions are skewed or error costs are unequal. This paper empirically investigates different strategies for evaluating rule sets when the goal is to maximize the scoring (ROC) performance
7F87A1CF	International Conference on Data Mining	weicheng lai + kwangting cheng + edward chang + beitao li	2001	Mining image features for efficient query processing	efficient query processing + divide and conquer methods + concept learning + data mining + image similarity measurement + indexation + neural networks + degradation + image analysis + divide-and-conquer method + feature groupings + minimized intra-group feature correlation + image query concept learning + database indexing + feature extraction + divide and conquer + search speed + indexing + multimedia databases + image features + genetic algorithms + content-based retrieval + genetic-based mining algorithm + image feature mining + decision trees + image retrieval	AuthorProvided Keywords Not Found	The number of features required to depict an image can be very large. Using all features simultaneously to measure image similarity and to learn image query-concepts can suffer from the problem of dimensionality curse, which degrades both search accuracy and search speed. Regarding search accuracy, the presence of irrelevant features with respect to a query can contaminate similarity measurement, and hence decrease both the recall and precision of that query. To remedy this problem, we present a mining method that learns online users' query concepts and identifies important features quickly. Regarding search speed, the presence of a large number of features can slow down query-concept learning and indexing performance. We propose a divide-and-conquer method that divides the concept-learning task into G subtasks to achieve speedup. We notice that a task must be divided carefully, or search accuracy may suffer. We thus propose a genetic-based mining algorithm to discover good feature groupings. Through analysis and mining results, we observe that organizing image features in a multi-resolution manner and minimizing intra-group feature correlation, can speed up query-concept learning substantially while maintaining high search accuracy
7F6EEDCC	International Conference on Data Mining	pierreyves rolland	2001	FIExPat: flexible extraction of sequential patterns	amino acid sequences + sequential databases + data representation + amino acid + data mining + music data + amino acids + sequential data mining + computational efficiency + temporal data + temporal data sequences + sequences + regularity detection + chronological series + music + strings + proteins + flexible sequential pattern extraction + macromolecule banks + proteic sequences + pattern recognition + edit distance + multimedia data + data analysis + algorithm design and analysis + multimedia databases + FlExPat + sequence segment similarity + similarity metrics + daily stock indices + segment repetition + finance	AuthorProvided Keywords Not Found	This paper addresses sequential data mining, a sub-area of data mining where the data to be analyzed is organized in sequences. In many problem domains a natural ordering exists over data. Examples of sequential databases (SDBs) include: (a) collections of temporal data sequences, such as chronological series of daily stock indices or multimedia data (sound, music, video, etc.); and (b) macromolecule banks, where amino acid or proteic sequences are represented as strings. In a SDB it is often valuable to detect regularities through one or several sequences. In particular, finding exact or approximate repetitions of segments can be utilized directly (e.g. for determining the biochemical activity of a protein region) or indirectly, e.g. for prediction in finance. To this end, we present concepts and an algorithm for automatically extracting sequential patterns from a sequential database. Such a pattern is defined as a group of significantly similar segments from one or several sequences. Appropriate functions for measuring similarity between sequence segments are proposed, generalizing the edit distance framework. There is a trade off between flexibility, particularly in sequence data representation and in associated similarity metrics, and computational efficiency. We designed the FlExPat algorithm to satisfactorily cope with this trade-off. FlExPat's complexity is in practice lesser than quadratic in the total length of the SDB analyzed, while allowing high flexibility. Some experimental results obtained with FlExPat on music data are presented and commented
7D7CBFB8	International Conference on Data Mining	meiliu lu + quoc luan ha + du zhang	2001	Mining California vital statistics data	data mining + decision making process + Cubist + cause of death + knowledge discovery + data mining tool + health issues + predictive models + computer science + demography + very large databases + decision-making process + social sciences computing + policy-making process + health care + data preprocessing + prediction model + causes of death + data mining project + testing + information services + California vital statistics data mining + statistical analysis + government data processing + statistics	AuthorProvided Keywords Not Found	Vital statistics data offer a fertile ground for data mining. The authors discuss the results of a data mining project on the causes of death aspect of the vital statistics data in the state of California. A data mining tool called Cubist is used to build predictive models out of two million cases over a nine-year period. The objective of our study is to discover knowledge that can be used to gain insight into various aspects of mortality in California, to predict health issues related to the causes of death, to offer an aid to decision- or policy-making processes, and to provide useful information services to the customers. The results obtained in our study contain valuable new information
7E477A22	International Conference on Data Mining	joaquim c g esteves da silva + agra coelho + gabriel pereira lopes + joao mexia	2001	Document clustering and cluster topic extraction in multilingual corpora	instruction sets + document handling + data mining + document clustering + probability + relevant expressions + document classification features + cluster topic extraction + principal components analysis + agriculture + model-based clustering analysis + pattern clustering + feature extraction + statistics-based approach + dispersion + multilingual corpora + principal component analysis	AuthorProvided Keywords Not Found	A statistics-based approach for clustering documents and for extracting cluster topics is described relevant (meaningful) expressions (REs) automatically extracted from corpora are used as clustering base features. These features are transformed and its number is strongly reduced in order to obtain a small set of document classification features. This is achieved on the basis of principal components analysis. Model-based clustering analysis finds the best number of clusters. Then, the most important REs are extracted from each cluster and taken as document cluster topics
80A66633	International Conference on Data Mining	jose l balcazar + osamu watanabe + yang dai	2001	Provably fast training algorithms for support vector machines	learning automata + data analysis algorithms + biomedical engineering + data mining + provably fast training algorithms + random sampling + learning artificial intelligence + quasilinear time bound + classifying hyperplane + kernels + learning (artificial intelligence) + sampling methods + data analysis + feature space + support vector machines + kernel + space technology + data points + upper bound + convex programming + convex quadratic programming + randomized algorithm + quadratic programming + SVM algorithms + randomised algorithms + support vector machine + quasilinear + random sampling techniques + linear time + dual formulation + expected running time	AuthorProvided Keywords Not Found	Support vector machines are a family of data analysis algorithms based on convex quadratic programming. We focus on their use for classification: in that case, the SVM algorithms work by maximizing the margin of a classifying hyperplane in a feature space. The feature space is handled by means of kernels if the problems are formulated in dual form. Random sampling techniques successfully used for similar problems are studied. The main contribution is a randomized algorithm for training SVMs, for which we can formally prove an upper bound on the expected running time that is quasilinear on the number of data points. To our knowledge, this is the first algorithm for training SVMs in dual formulation and with kernels for which such a quasilinear time bound has been formally proved
72621A92	International Conference on Data Mining	aijun an + yuanyuan wang	2001	Comparisons of classification methods for screening potential compounds	highly skewed class distribution + pharmaceutical industry + down sampling + classification methods + data mining + imbalanced data set + performance measures + chemical compounds + learning artificial intelligence + computer science + training data + throughput + learning (artificial intelligence) + high temperature superconductors + pattern classification + drug design + testing + data set + drug design problem + predictive performance + down-sampling + potential compound screening + chemical structures + global techniques + pruning techniques + molecular structure + up-sampling + chemistry computing + active compounds + molecular structure-activity relationships + chemical structure + local learning methods + statistical methods + statistics	AuthorProvided Keywords Not Found	We compare a number of data mining and statistical methods on the drug design problem of modeling molecular structure-activity relationships. The relationships can be used to identify active compounds based on their chemical structures from a large inventory of chemical compounds. The data set of this application has a highly skewed class distribution, in which only 2% of the compounds are considered active. We apply a number of classification methods to this extremely imbalanced data set and propose to use different performance measures to evaluate these methods. We report our findings on the characteristics of the performance measures, the effect of using pruning techniques in this application and a comparison of local learning methods with global techniques. We also investigate whether reducing the imbalance in the training data by up-sampling or down-sampling would improve the predictive performance
5D4CBDFE	International Conference on Data Mining	richard wherry + sam steingold + gregory piatetskyshapiro	2001	Measuring real-time predictive models	prediction model + cost + data mining + accuracy + predictive models + timeliness + time measurement + real-time systems + real time systems + real-time predictive model measurement + real time + bank data processing + real-time attrition problem	AuthorProvided Keywords Not Found	In this paper we examine the problem of comparing real-time predictive models and propose a number of measures for selecting the best model, based on a combination of accuracy, timeliness, and cost. We apply the measure to the real-time attrition problem
7D4DA335	International Conference on Data Mining	viviane crestana jensen + nandit soparkar	2001	Heuristic optimization for decentralized frequent itemset counting	merging + data mining + algebra + query processing + decentralized frequent itemset counting + heuristic techniques + database system + optimisation + heuristic programming + computer science + distributed algorithms + demography + very large databases + cost function + decentralized data mining + heuristic optimization + database systems + heuristic approach	AuthorProvided Keywords Not Found	The choices for mining of decentralized data are numerous, and we have developed techniques to enumerate and optimize decentralized frequent itemset counting. We introduce our heuristic approach to improve the performance of such techniques developed in ways similar to query processing in database systems. We also describe empirical results that validate our heuristic techniques
65288455	International Conference on Data Mining	maria halkidi + michalis vazirgiannis	2001	Clustering validity assessment: finding the optimal partitioning of a data set	visual perception + data mining + indexation + reliability + reliability theory + informatics + multidimensional systems + clustering validity assessment + optimal partitioning data set + SDbw validity index + pattern clustering + clustering algorithms + geometry + data visualization	AuthorProvided Keywords Not Found	Clustering is a mostly unsupervised procedure and the majority of clustering algorithms depend on certain assumptions in order to define the subgroups present in a data set. As a consequence, in most applications the resulting clustering scheme requires some sort of evaluation regarding its validity. In this paper we present a clustering validity procedure, which evaluates the results of clustering algorithms on data sets. We define a validity index, S Dbw, based on well-defined clustering criteria enabling the selection of optimal input parameter values for a clustering algorithm that result in the best partitioning of a data set. We evaluate the reliability of our index both theoretically and experimentally, considering three representative clustering algorithms run on synthetic and real data sets. We also carried out an evaluation study to compare S Dbw performance with other known validity indices. Our approach performed favorably in all cases, even those in which other indices failed to indicate the correct partitions in a data set
7D81A821	International Conference on Data Mining	george karypis + valerie guralnik	2001	A scalable algorithm for clustering sequential data	dataset clustering + sequential data clustering + algorithm design and analysis + data mining + scalable algorithm + intrusion detection + sequences + near-linear complexity K-means based clustering algorithm + computer science + biology computing + pattern clustering + clustering algorithms + proteins + purchasing transaction sequences + molecular biophysics + protein sequences + computational complexity + retail data processing	AuthorProvided Keywords Not Found	In recent years, we have seen an enormous growth in the amount of available commercial and scientific data. Data from domains such as protein sequences, retail transactions, intrusion detection, and Web-logs have an inherent sequential nature. Clustering of such data sets is useful for various purposes. For example, clustering of sequences from commercial data sets may help marketer identify different customer groups based upon their purchasing patterns. Grouping protein sequences that share similar structure helps in identifying sequences with similar functionality. Over the years, many methods have been developed for clustering objects according to their similarity. However these methods tend to have a computational complexity that is at least quadratic on the number of sequences. In this paper we present an entirely different approach to sequence clustering that does not require an all-against-all analysis and uses a near-linear complexity K-means based clustering algorithm. Our experiments using data sets derived from sequences of purchasing transactions and protein sequences show that this approach is scalable and leads to reasonably good clusters
6EF107BC	International Conference on Data Mining	meijung lo + jongsheng cherng	2001	A hypergraph based clustering algorithm for spatial data sets	spatial data + delaunay triangulation + intracluster similarity + graph theory + data mining + visual databases + discovery process + data analysis techniques + hypergraph + clustering algorithms + clustering problem + hierarchical clustering algorithm + consumer behavior + densely populated regions + intercluster similarity + clustering algorithm + data analysis + shape + data set + data points + mesh generation + noise shaping + hypergraph based clustering algorithm + Delaunay triangulation graph + spatial data sets + pattern clustering + hierarchical clustering + clustering	AuthorProvided Keywords Not Found	Clustering is a discovery process in data mining and can be used to group together the objects of a database into meaningful subclasses which serve as the foundation for other data analysis techniques. The authors focus on dealing with a set of spatial data. For the spatial data, the clustering problem becomes that of finding the densely populated regions of the space and thus grouping these regions into clusters such that the intracluster similarity is maximized and the intercluster similarity is minimized. We develop a novel hierarchical clustering algorithm that uses a hypergraph to represent a set of spatial data. This hypergraph is initially constructed from the Delaunay triangulation graph of the data set and can correctly capture the relationships among sets of data points. Two phases are developed for the proposed clustering algorithm to find the clusters in the data set. We evaluate our hierarchical clustering algorithm with some spatial data sets which contain clusters of different sizes, shapes, densities, and noise. Experimental results on these data sets are very encouraging
701C9BA0	International Conference on Data Mining	hui wang + david bell + ivo duntsch + dayou liu	2001	Classification through maximizing density	data model + pattern classification + algorithm design and analysis + supervised learning + tail + classification + density maximization + data models + learning artificial intelligence + computer science + hyper tuples + decision trees + software engineering + lattices + learning (artificial intelligence) + measurement units + lattice machine	AuthorProvided Keywords Not Found	This paper presents a novel method for classification, which makes use of models built by the lattice machine (LM). The LM approximates data resulting in, as a model of data, a set of hyper tuples that are equilabelled, supported and maximal. The method presented uses the LM model of data to classify new data with a view to maximising the density of the model. Experiments show that this method, when used with the LM, outperforms the C2 algorithm and is comparable to the C5.0 classification algorithm
81272861	International Conference on Data Mining	waiho au + keith c c chan	2001	Classification with degree of membership: a fuzzy approach	degree of membership + production + computational linguistics + data mining algorithms + uninteresting rules + data mining + fuzzy set theory + interesting rules + marketing management + missing data + gold + decision tree + very large databases + discovered rules + objective interestingness measure + real-life databases + databases + pattern classification + data mining tasks + human knowledge representation + testing + decision tree based approach + classification + attribute values + linguistic terms + fuzzy approach + knowledge representation + decision trees + human experts + fuzzy technique	AuthorProvided Keywords Not Found	Classification is an important topic in data mining research. It is concerned with the prediction of the values of some attribute in a database based on other attributes. To tackle this problem, most of the existing data mining algorithms adopt either a decision tree based approach or an approach that requires users to provide some user-specified thresholds to guide the search for interesting rules. The authors propose a new approach based on the use of an objective interestingness measure to distinguish interesting rules from uninteresting ones. Using linguistic terms to represent the revealed regularities and exceptions, this approach is especially useful when the discovered rules are presented to human experts for examination because of the affinity with the human knowledge representation. The use of a fuzzy technique allows the prediction of attribute values to be associated with degree of membership. Our approach is therefore able to deal with the cases where an object can belong to more than one class. Furthermore, our approach is more resilient to noise and missing data values because of the use of a fuzzy technique. To evaluate the performance of our approach, we tested it using several real-life databases. The experimental results show that it can be very effective at data mining tasks. When compared to popular data mining algorithms, the approach is better able to uncover useful rules hidden in databases
7CFEB211	International Conference on Data Mining	changshing perng + haixun wang + sheng ma + joseph l hellerstein	2001	FARM: a framework for exploring mining spaces with multiple attributes	transaction processing + production + computer networks + data mining + multiple attributes + space exploration + functional dependency + taxonomy + complex networks + transactions + data collection + frequent itemset mining + downward closure properties + mining space exploration + computer network + fixed attribute mining + production computer network + FARM + pediatrics + transaction definition discovery + item definition discovery + efficient algorithms	AuthorProvided Keywords Not Found	Mining for frequent itemsets typically involves a preprocessing step in which data with multiple attributes are grouped into transactions, and items are defined based on attribute values. We hake observed that such fixed attribute mining can severely constrain the patterns that are discovered. Herein, we introduce mining spaces, a new framework for mining multi-attribute data that includes the discovery of transaction and item definitions (with the exploitation of taxonomies and functional dependencies if they are available). We prove that special downward closure properties (or anti-monotonic property) hold for mining spaces, a result that allows us to construct efficient algorithms for mining patterns without the constraints of fixed attribute mining. We apply our algorithms to real world data collected from a production computer network. The results show that by exploiting the special kinds of downward closure in mining spaces, execution times for mining can be reduced by a factor of three to four
7D52F9F2	International Conference on Data Mining	mohammad elhajj + paul lu + osmar r zaiane	2001	Fast parallel association rule mining without candidacy generation	parallel algorithms + frequent patterns + parallel algorithm + data mining + testing + association rules + datasets + transactions + MLFPT parallel algorithm + association rule mining + optimal processor balancing + partitioning strategies + recommender systems + resource allocation + fast parallel association rule mining + very large databases + FP-growth mining + I/O scans + multiple local frequent pattern tree	AuthorProvided Keywords Not Found	In this paper we introduce a new parallel algorithm MLFPT (multiple local frequent pattern tree) for parallel mining of frequent patterns, based on FP-growth mining, that uses only two full I/O scans of the database, eliminating the need for generating candidate items, and distributing the work fairly among processors. We have devised partitioning strategies at different stages of the mining process to achieve near optimal balancing between processors. We have successfully tested our algorithm on datasets larger than 50 million transactions
7DD2E882	International Conference on Data Mining	re chen + haiying li + shiwei tang	2001	Association rules enhanced classification of underwater acoustic signal	classification algorithms + association rule + underwater acoustics + misclassification data sets + underwater acoustic signal classification + data mining + underwater sound + neural networks + association rules + sonar + classification accuracy enhancement + signal classification + two-phase training algorithm + understandable intrinsic rules + learning artificial intelligence + sonar signal processing + feature extraction + learning (artificial intelligence) + classification association rules + pattern recognition	AuthorProvided Keywords Not Found	The classification of underwater acoustic signals is one of the important fields of pattern recognition. Inspired by the experience of training human experts in sonar, we propose a two-phase training algorithm to exploit association rules to reveal understandable intrinsic rules which contribute to correct classification in known mis-classification data sets. Preliminary experimental results demonstrate the potential of these classification association rules to enhance the classification accuracy of underwater acoustic signals
7DA6CE8C	International Conference on Data Mining	kiho lee + won kim + jungwon lee	2001	Preparations for semantics-based XML mining	information management + term frequency + vector space model + data mining + on-line bookstore + information retrieval + document management + quantitative similarity determination + xml document + XML document preparation + data engineering + semantics-based XML mining + query processing + indexes + xml + hypermedia markup languages	AuthorProvided Keywords Not Found	XML allows users to define elements using arbitrary words and organize them in a nested structure. These features of XML offer both challenges and opportunities in information retrieval, document management, and data mining. In this paper, we propose a new methodology for preparing XML documents for quantitative determination of similarity between XML documents by taking into account XML semantics (i.e., meanings of the elements and nested structures of XML documents). Accurate quantitative determination of similarity between XML documents provides an important basis for a variety of applications of XML document mining and processing. Experiments with XML documents show that our methodology provides a 50-100% improvement in determining similarity over the traditional vector-space model that considers only term-frequency and 100% accuracy in identifying the category of each document from an on-line bookstore
7E04F58F	International Conference on Data Mining	chris h q ding + horst d simon + hongyuan zha + xiaofeng he	2001	Automatic topic identification using webpage clustering	information resources + search engines + textual information + unsupervised clustering method + co-citation relations + information retrieval + information analysis + taxonomy + computer science + pattern clustering + image segmentation + clustering algorithms + automatic topic identification + normalized cut criterion + Web page clustering + graph partitioning + similarity metric + spectral graph partitioning method + hyperlink structure	AuthorProvided Keywords Not Found	Grouping Web pages into distinct topics is one way of organizing the large amount of retrieved information on the Web. In this paper, we report that, based on a similarity metric, which incorporates textual information, hyperlink structure and co-citation relations, an unsupervised clustering method can automatically and effectively identify relevant topics, as shown in experiments on several retrieved sets of Web pages. The clustering method is a state-of-art spectral graph partitioning method based on the normalized cut criterion first developed for image segmentation
7FA0D715	International Conference on Data Mining	y y yao + ying sai + ning zhong	2001	Data analysis and mining in ordered information tables	associations + data analysis + rough sets + data mining + ordering rules + consumer products + educational administrative data processing + machine learning + object ordering + attribute values + Maclean's university rankings + learning artificial intelligence + computer science + manufacturing + order relations + learning (artificial intelligence) + ordered information tables + binary information	AuthorProvided Keywords Not Found	"Many real-world problems deal with ordering objects instead of classifying objects, although the majority of the research in machine learning and data mining has been focused on the latter. For the modeling of ordering problems, we generalize the notion of information tables to ordered information tables by adding order relations on attribute values. The problem of mining ordering rules is formulated as finding associations between the orderings of attribute values and the overall ordering of objects. An ordering rule may state, for example, that ""if the value of an object x on an attribute a is ordered ahead of the value of another object y on the same attribute, then x is ordered ahead of y"". For mining ordering rules, we first transform an ordered information table into binary information, and then apply any standard machine learning and data mining algorithms. As an illustration, we analyze in detail the Maclean's university ranking for the year 2000"
7D79518B	International Conference on Data Mining	rayid ghani	2001	Combining labeled and unlabeled data for text classification with a large number of categories	classification algorithms + text analysis + pattern classification + error correction codes + multiple binary problems + supervised learning + testing + binary classification problems + precision-recall tradeoff + accuracy + text classification + error correcting output coding setup + learning artificial intelligence + multiclass problems + labeling + labeled data + categories + co-training + unlabeled data + binary classification + learning (artificial intelligence)	AuthorProvided Keywords Not Found	We develop a framework to incorporate unlabeled data in the error-correcting output coding (ECOC) setup by decomposing multiclass problems into multiple binary problems and then use co-training to learn the individual binary classification problems. We show that our method is especially useful for classification tasks involving a large number of categories where co-training doesn't perform very well by itself and when combined with ECOC, outperforms several other algorithms that combine labeled and unlabeled data for text classification in terms of accuracy, precision-recall tradeoff, and efficiency
7D88E428	International Conference on Data Mining	wolfgang gaul + lars schmidtthieme	2001	Mining generalized association rules for sequential and path data	local features + association rule + databases + algorithm design and analysis + data mining + generalized association rule mining + association rules + subsequence relation + sequences + contiguous subsequences + database theory + global features + wild cards + sequential data + noncontiguous subsequences + path data + database sequences + sequence valued object + graph structure + set valued objects	AuthorProvided Keywords Not Found	While association rules for set data use and describe relations between parts of set valued objects completely, association rules for sequential data are restricted by specific interpretations of the subsequence relation: contiguous subsequences describe local features of a sequence valued object, noncontiguous subsequences its global features. We model both types of features with generalized subsequences that describe local deviations by wild cards, and present a new algorithm of a priori type for mining all generalized subsequences with prescribed minimum support from a given database of sequences. Furthermore we show that the given algorithm automatically takes into account an eventually underlying graph structure, i.e., is applicable to path data also
7E751660	International Conference on Data Mining	donlin yang + mingchuan hung	2001	An efficient Fuzzy C-Means clustering algorithm	data analysis + convergence + FCM algorithm + final cluster center + fuzzy set theory + initial value + data mining + initial cluster center + modified FCM + psFCM algorithm + convergence time + database management systems + initial membership value + optimisation + pattern clustering + computation time + image segmentation + clustering algorithms + Fuzzy C-Means clustering algorithm + system performance + pattern recognition	AuthorProvided Keywords Not Found	The Fuzzy C-Means (FCM) algorithm is commonly used for clustering. The performance of the FCM algorithm depends on the selection of the initial cluster center and/or the initial membership value. If a good initial cluster center that is close to the actual final cluster center can be found, the FCM algorithm will converge very quickly and the processing time can be drastically reduced. The authors propose a novel algorithm for efficient clustering. This algorithm is a modified FCM called the psFCM algorithm, which significantly reduces the computation time required to partition a dataset into desired clusters. We find the actual cluster center by using a simplified set of the original complete dataset. It refines the initial value of the FCM algorithm to speed up the convergence time. Our experiments show that the proposed psFCM algorithm is on average four times faster than the original FCM algorithm. We also demonstrate that the quality of the proposed psFCM algorithm is the same as the FCM algorithm
7F21BCB5	International Conference on Data Mining	gary r livingston + bruce g buchanan + john rosenberg	2001	Closing the loop: heuristics for autonomous discovery	domain-specific knowledge + databases + rule-induction targets + prototypes + data mining + autonomous discovery systems + very large database + mining industry + HAMB + autonomous discovery heuristics + justification based framework + heuristic programming + very large databases + crystallization + domain-independent heuristics	AuthorProvided Keywords Not Found	Autonomous discovery systems will be able to peruse very large databases more thoroughly than people can. In a companion paper by G.R. Livingston et al. (see ibid., p.385-92, 2001), we describe a general framework for autonomous systems. We present and evaluate heuristics for use in this framework. Although these heuristics were designed for a prototype system, we believe they provide good initial solutions to problems encountered when implementing fully autonomous discovery systems. As such, these heuristics may be used as the starting point for future research into fully autonomous discovery systems
7D6DE8DE	International Conference on Data Mining	wenhsiang lu + hsijian lee + leefeng chien	2001	Anchor text mining for translation of Web queries	information resources + databases + text analysis + web pages + anchor text + data mining + information retrieval + term translation + CLIR + Web anchor texts + link structures + proper names + Web query terms + terminology + automatic translation extraction + cross-language information retrieval + natural languages + anchor text mining + text mining + Web query translation + information science + ontologies + Web search + language translation	AuthorProvided Keywords Not Found	The paper presents an approach to automatically extracting translations of Web query terms through mining of Web anchor texts and link structures. One of the existing difficulties in cross-language information retrieval (CLIR) and Web search is the lack of the appropriate translations of new terminology and proper names. Such a difficult problem can be effectively alleviated by our proposed approach, and the resource of anchor texts in the Web is proven a valuable corpus for this kind of term translation
7E30E520	International Conference on Data Mining	pekka uronen + henry tirri + tomi silander + petri myllymaki	2001	Bayesian data mining on the Web with B-Course	bayesian network + application software + causal dependency inference + data mining + world wide web + World Wide Web + user interfaces + B-Course + Bayesian network models + power analysis + bayesian methods + modeling assumptions + tutorial style user friendly interface + computer science + Bayesian modeling + bayesian approach + free Web based Bayesian data mining service + context modeling + multivariate probabilistic dependencies + belief networks + information resources + data analysis + educational purposes + analysis methods + causal modeling + inference mechanisms + bayesian modeling + Bayesian approach + powerful analysis tool + causal models	AuthorProvided Keywords Not Found	B-Course is a free Web based Bayesian data mining service. This service allows the users to analyze their own data for multivariate probabilistic dependencies represented as Bayesian network models. In addition to this, B-Course also offers facilities for inferring certain types of causal dependencies from the data. The software is especially suitable for educational purposes as the tutorial style user friendly interface intertwines steps in the data analysis with support material that gives an informal introduction to the Bayesian approach adopted. Nevertheless, although the analysis methods, modeling assumptions and restrictions are totally transparent to the user, this transparency is not achieved at the expense of analysis power: with the restrictions stated in the support material, B-Course is a powerful analysis tool exploiting several theoretically elaborate results developed recently in the fields of Bayesian and causal modeling
7DCC6B60	International Conference on Data Mining	gary r livingston + bruce g buchanan + john rosenberg	2001	Closing the loop: an agenda- and justification-based framework for selecting the next discovery task to perform	macromolecules + erbium + prototypes + data mining + justification-based architecture + user interfaces + patient rehabilitation + autonomous agent + learning artificial intelligence + protein crystallization + biology computing + very large databases + background knowledge + proteins + autonomous machine learning + learning (artificial intelligence) + next discovery task selection + health care + agenda-based framework + databases + discovery systems + general discovery strategies + prototype discovery program + encoding + machine learning + inference mechanisms + patient care + HAMB + justification-based framework + knowledge discovery in databases + crystallization + user interests	AuthorProvided Keywords Not Found	We propose and evaluate an agenda- and justification-based architecture for discovery systems that selects the next tasks to perform. This framework has many desirable properties: (1) it facilitates the encoding of general discovery strategies using a variety of background knowledge, (2) it reasons about the appropriateness of the tasks being considered, and (3) it tailors its behavior toward a user's interests. A prototype discovery program called HAMB demonstrates that both reasons and estimates of interestingness contribute to performance in the domains of protein crystallization and patient rehabilitation
80418C9C	International Conference on Data Mining	sung young jung + taeksoo kim	2001	An agglomerative hierarchical clustering using partial maximum array and incremental similarity computation method	incremental similarity computation method + partial maximum array + databases + merging + scalar calculation + data mining + high-dimensional data + time complexity + machine intelligence + accuracy deterioration + agglomerative hierarchical clustering + database theory + fast clustering algorithm + approximation method + computer science + high dimensional data + pattern clustering + clustering algorithms + very large databases + large data sets + data structures + arrays + large databases + computational complexity	AuthorProvided Keywords Not Found	As the tractable amount of data grows in the computer science area, fast clustering algorithms are required, because traditional clustering algorithms are not feasible for very large and high-dimensional data. Many studies have been reported on the clustering of large databases, but most of them circumvent this problem by using an approximation method, resulting in the deterioration of accuracy. In this paper, we propose a new clustering algorithm by means of a partial maximum array, which can realize agglomerative hierarchical clustering with the same accuracy as the brute-force algorithm and has O(N2 ) time complexity. We also present an incremental method of similarity computation which substitutes a scalar calculation for the time-consuming calculation of vector similarity. Experimental results show that clustering becomes significantly fast for large and high-dimensional data
7DA9A9A0	International Conference on Data Mining	dimitrios gunopulos + carlotta domeniconi	2001	Incremental support vector machine construction	learning automata + incremental support vector machine construction + batch mode + CPU time + condensation properties + updated representation + data streams + stream data + large memory requirement + SVMs + learning artificial intelligence + computer science + incremental schemes + very large databases + batch processing (computers) + large data sets + training data + learning (artificial intelligence) + support vector machines + data analysis + solids + batch algorithm + cpu time + incremental learning algorithms + support vector machine + telephony + svms	AuthorProvided Keywords Not Found	SVMs (support vector machines) suffer from the problem of large memory requirement and CPU time when trained in batch mode on large data sets. We overcome these limitations, and at the same time make SVMs suitable for learning with data streams, by constructing incremental learning algorithms. We first introduce and compare different incremental learning techniques, and show that they are capable of producing performance results similar to the batch algorithm, and in some cases superior condensation properties. We then consider the problem of training SVMs using stream data. Our objective is to maintain an updated representation of recent batches of data. We apply incremental schemes to the problem and show that their accuracy is comparable to the batch algorithm
7E53066B	International Conference on Data Mining	sheng ma + joseph l hellerstein	2001	Mining mutually dependent patterns	pattern analysis + application software + m-pattern + production system + level-wise search + production + frequent patterns + computer networks + data mining + minsup + association rules + intrusion detection + minimum probability + minp + mutually dependent pattern mining + scalability + computer network + infrequent patterns + production computer network + synthetic data + candidate pruning + linear algorithm	AuthorProvided Keywords Not Found	In some domains, such as isolating problems in computer networks and discovering stock market irregularities, there is more interest in patterns consisting of infrequent, but highly correlated items rather than patterns that occur frequently (as defined by minsup, the minimum support level). We describe the m-pattern, a new pattern that is defined in terms of minp, the minimum probability of mutual dependence of items in the pattern. We show that all infrequent m-patterns can be discovered by an efficient algorithm that makes use of: (a) a linear algorithm to qualify an m-pattern; (b) an effective technique for candidate pruning based on a necessary condition for the presence of an m-pattern; and (c) a level-wise search for m-pattern discovery (which is possible because m-patterns are downward closed). Further, we consider frequent m-patterns, which are defined in terms of both minp and minsup. Using synthetic data, we study the scalability of our algorithm. Then, we apply our algorithm to data from a production computer network both to show the m-patterns present and to contrast with frequent patterns. We show that when minp=0, our algorithm is equivalent to finding frequent patterns. However, with a larger minp, our algorithm yields a modest number of highly correlated items, which makes it possible to mine for infrequent but highly correlated itemsets. To date, many actionable m-patterns have been discovered in production systems
58CE3BD9	International Conference on Data Mining	viet phanluong	2001	The representative basis for association rules	association rule + associative processing + generating sets + representative basis + knowledge representation + data mining + association rules + set theory + association rule extraction + inference mechanisms + qualitative inference system + interesting association rules	AuthorProvided Keywords Not Found	We define the concept of the representative basis for interesting association rules, and an inference system which is purely qualitative. The representative basis is unique, and minimal with respect to the inference system. On the representative basis, the inference system is correct and complete. Experimental results show that the number of rules in the representative basis is significantly reduced with respect to the number of rules generated by other existing approaches
809BB606	International Conference on Data Mining	h paetz	2001	Metric rule generation with septic shock patient data	septic shock patient data + databases + data preprocessing + data analysis + data mining + patient data analysis + intensive care unit patients + medical information systems + medical research + growing trapezoidal basis function network + learning artificial intelligence + medical data mining cycle + metric rule generation + medical expert systems + immune system + learning (artificial intelligence) + hospital	AuthorProvided Keywords Not Found	The article present an application of metric rule generation in the domain of medical research. We consider intensive care unit patients developing a septic shock during their stay at the hospital. To analyse the patient data, rule generation is embedded in a medical data mining cycle. For rule generation, we improve an architecture based on a growing trapezoidal basis function network
7EA7FC71	International Conference on Data Mining	r lee + yiming ma + bing liu	2001	Analyzing the interestingness of association rules from the temporal dimension	association rule + databases + rule interestingness techniques + data mining + probability + association rules + temporal logic + interesting rules + rule discovery + trusted rules + associative processing + temporal databases + knowledge based systems + discovered rules + temporal dimension + systematic pattern + association rule interestingness + statistical analysis + dataset + statistical methods + statistics	AuthorProvided Keywords Not Found	Rule discovery is one of the central tasks of data mining. Existing research has produced many algorithms for the purpose. These algorithms, however, often generate too many rules. In the past few years, rule interestingness techniques were proposed to help the user find interesting rules. These techniques typically employ the dataset as a whole to mine rules, and then filter and/or rank the discovered rules in various ways. We argue that this is insufficient. These techniques are unable to answer a question that is of critical importance to the application of rules, i.e., can the rules be trusted? In practice, the users are always concerned with the question. They want to know whether the rules indeed represent some true and stable (or reliable) underlying relationships in the domain. If a rule is not stable, does it show any systematic pattern such as a trend? Before any rule can be used, these questions must be answered. The paper proposes a technique to use statistical methods to analyze rules from the temporal dimension to answer these questions. Experimental results show that the proposed technique is very effective
74D1E26D	International Conference on Data Mining	loic martinez + cesar montes + fernando diaz alonso + juan p caracavalente	2001	Discovering similar patterns for characterising time series in a medical domain	time series characterisation + muscular rehabilitation + reference models + data mining + I4 project + training + elite athletes + isokinetic data set + similar patterns discovery + artificial intelligence + patient rehabilitation + medical domain + patient treatment + data mining techniques + muscle + sports research + physician expertise + injury prevention + training planning + pattern classification + muscular diagnosis + algorithm design and analysis + intelligent information interpretation + physiotherapy + reference model + training evaluation + time series + population groups + blind athletes + sport + medical computing + delta modulation + patient diagnosis	AuthorProvided Keywords Not Found	In this article, we describe the process of discovering similar patterns in time series and creating reference models for population groups in a medical domain, and particularly in the field of physiotherapy, using data mining techniques on a set of isokinetic data. The discovered knowledge was evaluated against the expertise of a physician specialising in isokinetic techniques, and applied in the I4 (Intelligent Interpretation of Isokinetic Information) project developed in conjunction with the Spanish National Centre for Sports Research and Sciences and the School of Physiotherapy of the Spanish National Organisation for the Blind for muscular diagnosis and rehabilitation, injury prevention, training evaluation and planning, etc., of elite and blind athletes
808BE0B5	International Conference on Data Mining	george karypis + masakazu seno	2001	LPMiner: an algorithm for finding frequent itemsets using length-decreasing support constraint	transaction processing + transaction length + data mining + association rules + constant support constraint + long item sets + smallest valid extension + frequent item-set discovery + data engineering + exponential complexity + run time + length-decreasing support constraint + computer science + FP-trees + very large databases + very large transaction databases + LPMiner algorithm + high performance computing + tree data structures + FP-growth algorithm + pattern recognition + computational complexity	AuthorProvided Keywords Not Found	Over the years, a variety of algorithms for finding frequent item sets in very large transaction databases has been developed. The key feature in most of these algorithms is that they use a constant support constraint to control the inherently exponential complexity of the problem. In general, item sets that contain only a few items tend to be interesting if they have a high support, whereas long item sets can still be interesting even if their support is relatively small. Ideally, we desire to have an algorithm that finds all the frequent item sets whose support decreases as a function of their length. In this paper, we present an algorithm called LPMiner (Long Pattern Miner) that finds all item sets that satisfy a length-decreasing support constraint. Our experimental evaluation shows that LPMiner is up to two orders of magnitude faster than the FP-growth algorithm for finding item sets at a constant support constraint, and that its run-time increases gradually as the average length of the transactions (and the discovered item sets) increases
7F360DDA	International Conference on Data Mining	haixun wang + philip s yu	2001	SSDT: a scalable subspace-splitting classifier for biased data	association rule + subspace cluster search + data mining + association rules + intrusion detection + scalability + efficient scalable algorithms + decision tree + learning artificial intelligence + predictive models + multivariate splittings + clustering algorithms + SSDT + weighted distances + training data + disk-resident dataset + learning (artificial intelligence) + biased data + pattern classification + biased class distribution + testing + data mining models + scalable subspace-splitting classifier + performance + decision trees + scalable decision tree learning	AuthorProvided Keywords Not Found	Decision trees are extensively used data mining models. Recently, a number of efficient, scalable algorithms for constructing decision trees on large disk-resident datasets have been introduced. In this paper, we study the problem of learning scalable decision trees from datasets with biased class distribution. Our objective is to build decision trees that are more concise and more interpretable while maintaining the scalability of the model. To achieve this, our approach searches for subspace clusters of data cases of the biased class to enable multivariate splittings based on weighted distances to such clusters. In order to build concise and interpretable models, other approaches including multivariate decision trees and association rules, often introduce scalability and performance issues. The SSDT algorithm we present achieves the objective without loss in efficiency, scalability, and accuracy
7FDD1EB5	International Conference on Data Mining	jose ruizshulcloper + guillermo sanchezdiaz	2001	A clustering method for very large mixed data sets	art + cybernetics + mathematics + data mining + connected set partition + explosives + metric space + skeleton + very large mixed incomplete data sets + developing country + pattern clustering + clustering algorithms + very large databases + physics + GLCclustering method + finance + missing values	AuthorProvided Keywords Not Found	In developed countries, especially over the last decade, there has been an explosive growth in the capability to generate, collect and use very large data sets. The objects of these data sets could be simultaneously described by quantitative and qualitative attributes. At present, algorithms able to process either very large data sets (in metric spaces) or mixed (qualitative and quantitative) incomplete data (missing value) sets have been developed, but not for very large mixed incomplete data sets. In this paper we introduce a new clustering method named GLC+ to process very large mixed incomplete data sets in order to obtain a partition in connected sets
7CE899AC	International Conference on Data Mining	wei wang + philip s yu + jiong yang	2001	Meta-patterns: revealing hidden periodic patterns	pattern matching + data mining + component location property + time series + periodic pattern discovery + history + meta-patterns + sequences + symbols + repetitions + frequency + candidate generation + computation-based mining algorithm + fluctuations + noise + power generation + hidden periodic patterns + time series data + pattern recognition	AuthorProvided Keywords Not Found	Discovery of periodic patterns in time series data has become an active research area with many applications. These patterns can be hierarchical in nature, where a higher level pattern may consist of repetitions of lower level patterns. Unfortunately, the presence of noise may prevent these higher level patterns from being recognized in the sense that two portions (of a data sequence) that support the same (high level) pattern may have different layouts of occurrences of basic symbols. There may not exist any common representation in terms of raw symbol combinations; and hence such (high level) patterns may not be expressed by any previous model (defined on raw symbols or symbol combinations) and would not be properly recognized by any existing method. In this paper, we propose a novel model, namely meta-pattern, to capture these high level patterns. As a more flexible model, the number of potential meta-patterns could be very large. A substantial difficulty is how to identify the proper pattern candidates. However the well-known a priori properly is not able to provide sufficient pruning power. A new property, namely component location, is identified and used to conduct candidate generation so that an efficient computation-based mining algorithm can be developed. We apply our algorithm to real and synthetic sequences and interesting patterns are discovered
73163BAA	International Conference on Data Mining	zhiyong liu + lei xu	2001	RPCL-based local PCA algorithm	covariance matrices + data analysis + local structure + shape + data mining + local structure mining + decomposed orthonormal form + unsupervised learning + covariance matrix + Rival Penalized Competitive Learning + RPCL competitive learning + local structures + gaussian processes + high dimensional data + computer science + clustering algorithms + Gaussian processes + RPCL-based Local PCA Algorithm + Gaussian mixture + principal component analysis	AuthorProvided Keywords Not Found	Mining local structure is important in data analysis. Gaussian mixture is able to describe local structure through covariance matrices, but when used on high-dimensional data, specifying such a large number of d(d+1)/2 free elements in each covariance matrix is difficult. By constraining the covariance matrix in decomposed orthonormal form, we propose a Local PCA algorithm to tackle this problem with the help of RPCL (Rival Penalized Competitive Learning), which can automatically determine the number of local structures
7D1E223A	International Conference on Data Mining	guy w mineau + pascal soucy	2001	A simple KNN algorithm for text categorization	text analysis + learning task + solids + testing + world wide web + World Wide Web + text categorization + feature interaction + feature selection method + text classification + classification + word interdependencies + computer science + text document + feature extraction + nonweighted features KNN algorithm + feature selection	AuthorProvided Keywords Not Found	Text categorization (also called text classification) is the process of identifying the class to which a text document belongs. This paper proposes to use a simple non-weighted features KNN algorithm for text categorization. We propose to use a feature selection method that finds the relevant features for the learning task at hand using feature interaction (based on word interdependencies). This will allow us to reduce considerably the number Of selected features from which to learn, making our KNN algorithm applicable in contexts where both the volume of documents and the size of the vocabulary are high, like with the World Wide Web. Therefore, the KNN algorithm that we propose becomes efficient for classifying text documents in that context (in terms of its predictability and interpretability), as is demonstrated. Its simplicity (WRT its implementation and fine-tuning) becomes its main assets for in-the-field applications
7E4FC65B	International Conference on Data Mining	mahesh v joshi + vipin kumar + ramesh c agarwal	2001	Evaluating boosting algorithms to classify rare classes: comparison and improvements	classification algorithms + pattern classification + enhanced algorithms + boosting + algorithm design and analysis + rare event classification + data mining + voting + boosting algorithms + database management systems + weight updating parameters + learning artificial intelligence + classification performance + example weights + computer science + rare classes + qualitative analysis + weak classifier + meta technique + learning (artificial intelligence) + data mining applications + synthetic datasets	AuthorProvided Keywords Not Found	Classification of rare events has many important data mining applications. Boosting is a promising meta-technique that improves the classification performance of any weak classifier. So far, no systematic study has been conducted to evaluate how boosting performs for the task of mining rare classes. The authors evaluate three existing categories of boosting algorithms from the single viewpoint of how they update the example weights in each iteration, and discuss their possible effect on recall and precision of the rare class. We propose enhanced algorithms in two of the categories, and justify their choice of weight updating parameters theoretically. Using some specially designed synthetic datasets, we compare the capability of all the algorithms from the rare class perspective. The results support our qualitative analysis, and also indicate that our enhancements bring an extra capability for achieving better balance between recall and precision in mining rare classes
809AD69B	International Conference on Data Mining	xu liang + yao liang	2001	Applications of data mining in hydrology	data mining + neural networks + long-term range streamflow forecast + neural network + time series forecasting approach + learning artificial intelligence + weather forecasting + water resources + predictive models + learning (artificial intelligence) + time series forecasting + data mining applications + environmental management + hydrology + feedforward neural networks + geophysics computing + time series + water supply + predicted long-term range streamflows + water resource planning + historical streamflow information + multiresolution learning paradigm + artificial neural networks + forecasting theory + predicting skill + neural nets + NNMLP	AuthorProvided Keywords Not Found	Long-term range streamflow forecast plays an invaluable role in water resource planning and management. The potential applicability and limitations of the time series forecasting approach using neural network with the multiresolution learning paradigm (NNMLP) are investigated. The predicted longterm range streamflows using the NNMLP are compared with the observations. The results show that the time series forecasting approach of NNMLP has good predicting skill. The NNMLP requires only historical streamflow information. The time series forecasting approach of NNMLP has great potential for being used alone in regions with limited available information, and for being combined with other approaches to improve long-term range streamflow forecasts
72FC5BF1	International Conference on Data Mining	chunyi shi + hongwei zhang + yuchang lu + fengzhan tian	2001	Incremental learning of Bayesian networks with hidden variables	bayesian network + em algorithm + evolutionary computing + computer networks + intelligent systems + Bayesian network learning + local maxima + storage cost + evolutionary algorithm + bayesian methods + evolutionary computation + hidden variables + learning artificial intelligence + computer science + incremental learning + intelligent networks + belief networks + learning (artificial intelligence) + EM algorithm + missing values + statistics + incremental method	AuthorProvided Keywords Not Found	An incremental method for learning Bayesian networks based on evolutionary computing, IEMA, is put forward. IEMA introduces the evolutionary algorithm and EM algorithm into the process of incremental learning; it can avoid getting into local maxima, and also incrementally learn Bayesian networks with high accuracy in the presence of missing values and hidden variables. In addition, we improved the incremental learning process by N. Friedman and M. Goldschmidt (1997). The experimental results verified the validity of IEMA. In terms of storage cost, IEMA is comparable with the incremental learning method of Friedman et al, while it is more accurate
7EB33B5E	International Conference on Data Mining	juho rousu + tapio elomaa	2001	Preprocessing opportunities in optimal numerical range partitioning	numerical range + evaluation function + segment borders + data mining + optimal multisplit + dynamic programming + convex function + upper bound + alternations + linear-time preprocessing step + convex attribute evaluation functions + learning artificial intelligence + computer science + cutpoint candidates + optimal numerical range partitioning + learning (artificial intelligence) + linear time + training set error	AuthorProvided Keywords Not Found	We show that only segment borders have to be taken into account as cut point candidates when searching for the optimal multisplit of a numerical value range with respect to convex attribute evaluation functions. Segment borders can be found efficiently in a linear-time preprocessing step. With training set error, which is not strictly convex, the data can be preprocessed into an even smaller number of cut point candidates, called alternations, when striving for the optimal partition. We show that no segment borders (resp. alternations) can be overlooked with strictly convex functions (resp. training set error) without risking the loss of optimality. Our experiments show that while in real-world domains a significant reduction in the number of cut point candidates can be obtained for training set error, the number of segment borders is usually not much lower than that of boundary points
81583F7C	International Conference on Data Mining	jon timmis + thomas f knight	2001	AINE: an immunological approach to data mining	data analysis + computer programming + algorithm design and analysis + data mining + testing + complex data + immune system + NonControlled Keywords Not Found + Controlled Keywords Not Found + artificial immune systems + artificial immune system	AuthorProvided Keywords Not Found	First Page of the Article
65FE3E8E	International Conference on Data Mining	robert l rounthwaite + c e meek + david maxwell chickering	2001	Efficient determination of dynamic split points in a decision tree	data analysis + continuous predictor variables + dynamic approach + probability + testing + dynamic method + degradation + candidate split points + potential split + split points + probabilistic decision trees + bayesian methods + decision tree + learning artificial intelligence + decision trees + probability distribution + context modeling + learning (artificial intelligence) + dynamic split point determination + prediction algorithms + continuous predictor value discretization + traditional dynamic approach	AuthorProvided Keywords Not Found	We consider the problem of choosing split points for continuous predictor variables in a decision tree. Previous approaches to this problem typically either: (1) discretize the continuous predictor values prior to learning, or (2) apply a dynamic method that considers all possible split points for each potential split. We describe a number of alternative approaches that generate a small number of candidate split points dynamically with little overhead. We argue that these approaches are preferable to pre-discretization, and provide experimental evidence that they yield probabilistic decision trees with the same prediction accuracy as the traditional dynamic approach. Furthermore, because the time to grow a decision tree is proportional to the number of split points evaluated, our approach is significantly faster than the traditional dynamic approach
7D39D610	International Conference on Data Mining	tzungpei hong + yeongchyi lee	2001	Mining coverage-based fuzzy rules by evolutional computation	offspring fuzzy rules + fuzzy set + credit assignment + fuzzy-rule evolution phase + fuzzy set theory + data mining + fuzzy-rule encoding phase + random number generation + genetic algorithm + learning artificial intelligence + genetics + very large databases + fuzzy systems + learning (artificial intelligence) + compact fuzzy rule base + genetic operator + fuzzy sets + fixed-length bit strings + fuzzy-rule generating phase + evaluation mechanism + genetic operations + mining approach + evolutional computation + genetic algorithms + coverage-based fuzzy rule mining + encoding + machine learning + rule level + genetic engineering + rule based + fuzzy-rule generation + genetic process	AuthorProvided Keywords Not Found	The authors propose a novel mining approach based on the genetic process and an evaluation mechanism to automatically construct an effective fuzzy rule base. The proposed approach consists of three phases: fuzzy-rule generating, fuzzy-rule encoding and fuzzy-rule evolution. In the fuzzy-rule generating phase, a number of fuzzy rules are randomly generated. In the fuzzy-rule encoding phase, all the rules generated are translated into fixed-length bit strings to form an initial population. In the fuzzy-rule evolution phase, genetic operations and credit assignment are applied at the rule level. The proposed mining approach chooses good individuals in the population for mating, gradually creating better offspring fuzzy rules. A concise and compact fuzzy rule base is thus constructed effectively without human expert intervention
7ED29874	International Conference on Data Mining	xiaohua hu	2001	Using rough sets theory and database operations to construct a good ensemble of classifiers for data mining applications	rough sets + data mining + reduct classifiers + voting + induction generators + reducts + classification ability + decision categories + reduct classifier + indispensable attributes + database operations + very large databases + training data + data mining applications + rule induction algorithm + maximal generalized rules + databases + pattern classification + boosting + testing + bagging + minimum subset + inference mechanisms + decision tables + classification rules + decision trees + rough set theory + reduct table + set-oriented database operations	AuthorProvided Keywords Not Found	The article presents a novel approach to constructing a good ensemble of classifiers using rough set theory and database operations. Ensembles of classifiers are formulated precisely within the framework of rough set theory and constructed very efficiently by using set-oriented database operations. Our method first computes a set of reducts which include all the indispensable attributes required for the decision categories. For each reduct, a reduct table is generated by removing those attributes which are not in the reduct. Next, a novel rule induction algorithm is used to compute the maximal generalized rules for each reduct table and a set of reduct classifiers is formed based on the corresponding reducts. The distinctive features of our method as compared to other methods of constructing ensembles of classifiers are: (1) presents a theoretical model to explain the mechanism of constructing ensemble of classifiers; (2) each reduct is a minimum subset of attributes and has the same classification ability as the entire attributes; (3) each reduct classifier constructed from the corresponding reduct has a minimal set of classification rules, and is as accurate and complete as possible and at the same time as diverse as possible from the other classifiers; (4) the test indicates that the number of classifiers used to improve the accuracy is much less than other methods
6DB5F201	International Conference on Data Mining	johanna tikanmaki + kalle korpiaho + heikki mannila + johan himberg + hannu toivonen	2001	Time series segmentation for context recognition in mobile devices	sensor data + global iterative replacement + algorithm design and analysis + dynamic programming + mobile phone applications + time series segmentation + sensor fusion + time series + minimized intrasegment variances + user interfaces + randomized algorithm + user interface + mobile device + acceleration + adaptive personalized user interface + mobile communication + context recognition + cost function + mobile devices + luminosity + humidity + noise level + cellular radio	AuthorProvided Keywords Not Found	Recognizing the context of use is important in making mobile devices as simple to use as possible. Finding out what the user's situation is can help the device and underlying service in providing an adaptive and personalized user interface. The device can infer parts of the context of the user from sensor data: the mobile device can include sensors for acceleration, noise level, luminosity, humidity, etc. In this paper we consider context recognition by unsupervised segmentation of time series produced by sensors. Dynamic programming can be used to find segments that minimize the intra-segment variances. While this method produces optimal solutions, it is too slow for long sequences of data. We present and analyze randomized variations of the algorithm. One of them, global iterative replacement or GIR, gives approximately optimal results in a fraction of the time required by dynamic programming. We demonstrate the use of time series segmentation in context recognition for mobile phone applications
811A3E8A	International Conference on Data Mining	bernard zenko + ljupco todorovski + saso dzeroski	2001	A comparison of stacking with meta decision trees to bagging, boosting, and stacking with other methods	MLC + data mining + linear regression + voting + Weka data mining suite + bagged boosted decision trees + decision tree + learning artificial intelligence + MDTs + MLR + naive bayes + probability distribution + ordinary decision trees + learning (artificial intelligence) + multiple classifiers + meta-level classifiers + pattern classification + boosting + bagging + meta decision trees + classifier ensembles + multi-response linear regression + decision trees + naive Bayes + stacking	AuthorProvided Keywords Not Found	Meta decision trees (MDTs) are a method for combining multiple classifiers. We present an integration of the algorithm MLC4.5 for learning MDTs in the Weka data mining suite. We compare classifier ensembles combined with MDTs to bagged and boosted decision trees, and to classifier ensembles combined with other methods: voting and stacking with three different meta-level classifiers (ordinary decision trees, naive Bayes, and multi-response linear regression, MLR)
813127C3	International Conference on Data Mining	christopher jermaine	2001	The computational complexity of high-dimensional correlation search	association mining application + appropriate technology + probability + data mining + market-basket analysis searching + testing + NP-hard problem definitions + statistical distributions + rigorous metrics + np hard problem + computational implications + support metric + associative processing + simple expectation + high-dimensional correlation search + statistical analysis + data mining task + search problems + co-occurrence frequency + computational complexity	AuthorProvided Keywords Not Found	There is a growing awareness that the popular support metric (often used to guide search in market-basket analysis) is not appropriate for use in every association mining application. Support measures only the co-occurrence frequency of a set of events when determining which patterns to report back to the user. It incorporates no rigorous statistical notion of surprise or interest, and many of the patterns deemed interesting by the support metric are uninteresting to the user. However, a positive aspect of support is that search using support is very efficient. The question addresses in the paper is: can we retain this efficiency if we move beyond support, and to other more rigorous metrics? We consider the computational implications of incorporating simple expectation into the data mining task. It turns out that many variations on the problem which incorporate more rigorous tests of dependence (or independence) result in NP-hard problem definitions
7F482F45	International Conference on Data Mining	wanda pratt + catherine blake	2001	Better rules, fewer features: a semantic approach to selecting features from text	text analysis + association rule + semantic approach + automatically selected medical concepts + computational linguistics + data mining + large textual corpus + association rules + text representation + bibliographic systems + dimensionality reduction + computer science + predictive models + web + bi-directional association rules + feature selection + word features + word representation + manually assigned keywords + words + breast cancer + medical information systems + keyword representations + Web + natural languages + medical texts + semantic levels	AuthorProvided Keywords Not Found	The choice of features used to represent a domain has a profound effect on the quality of the model produced; yet, few researchers have investigated the relationship between the features used to represent text and the quality of the final model. We explored this relationship for medical texts by comparing association rules based on features with three different semantic levels: (1) words (2) manually assigned keywords and (3) automatically selected medical concepts. Our preliminary findings indicate that bi-directional association rules based on concepts or keywords are more plausible and more useful than those based on word features. The concept and keyword representations also required 90% fewer features than the word representation. This drastic dimensionality reduction suggests that this approach is well suited to large textual corpora of medical text, such as parts of the Web
7A49F252	International Conference on Data Mining	xiong wang	2001	-Surface and Its Application to Mining Protein Data	level of detail + three dimensional		"
Given a finite set of points in three dimensional Euclidean space , the subset that forms its surface could be different when observed in different levels of details. In this paper, we introduce a notion called -surface. We present an algorithm that extracts the -surface from a finite set of points in . We apply the algorithm to extracting the surfaces of proteins and discover patterns from these surface structures, using the pattern discovery algorithm we developed earlier. We then use these patterns to classify the proteins. Experimental results show the good performance of the proposed approach.
"
7F3AF35E	International Conference on Data Mining	steven eschrich + lawrence o hall + nitesh v chawla	2001	Creating ensembles of classifiers	application software + data mining + bagging + classification accuracy + machine learning + distributed computing + large datasets + learning artificial intelligence + parallel learning + computer science + pattern clustering + clustering algorithms + random partitioning method + decision trees + distributed learning + disjoint subsets + clustering + classifier ensemble creation + learning (artificial intelligence) + tires	AuthorProvided Keywords Not Found	Ensembles of classifiers offer promise in increasing overall classification accuracy. The availability of extremely large datasets has opened avenues for application of distributed and/or parallel learning to efficiently learn models of them. In this paper, distributed learning is done by training classifiers on disjoint subsets of the data. We examine a random partitioning method to create disjoint subsets and propose a more intelligent way of partitioning into disjoint subsets using clustering. It was observed that the intelligent method of partitioning generally performs better than random partitioning for our datasets. In both methods a significant gain in accuracy may be obtained by applying bagging to each of the disjoint subsets, creating multiple diverse classifiers. The significance of our finding is that a partition strategy for even small/moderate sized datasets when combined with bagging can yield better performance than applying a single learner using the entire dataset
7D457327	International Conference on Data Mining	honghua dai + fu tong + gang li	2001	Evolutionary structure learning algorithm for Bayesian network and Penalized Mutual Information metric	databases + bayesian network + data analysis + Bayesian network structure learning + mathematics + algorithm design and analysis + probability + computer networks + evolutionary structure learning algorithm + uncertainty + distributed computing + evolutionary algorithm + bayesian methods + evolutionary computation + learning artificial intelligence + Penalized Mutual Information metric + probability distribution + structure search + mutual information + belief networks + learning (artificial intelligence) + search problems	AuthorProvided Keywords Not Found	The paper formulates the problem of learning Bayesian network structures from data as determining the structure that best approximates the probability distribution indicated by the data. A new metric, Penalized Mutual Information metric, is proposed, and an evolutionary algorithm is designed to search for the best structure among alternatives. The experimental results show that this approach is reliable and promising
7FD9D4BC	International Conference on Data Mining	monika henzinger + matthias ruhl + baywei chang + krishna bharat	2001	Who links to whom: mining linkage between Web sites	couplings + web pages + weight distribution + data mining + hypermedia + subgraph size + hostgraph + host finding algorithm + connectivity properties + navigation + intermediate levels + observed link weight distributions + computer science + bibliometrics + directed graph + citation analysis + administrative control + macro-structure + information resources + Web graph structure + weighted edges + country domains + directed graphs + hierarchically nested graph + modified copy model + Web sites + data mining application + hyperlinks	AuthorProvided Keywords Not Found	"Previous studies of the Web graph structure have focused on the graph structure at the level of individual pages. In actuality the Web is a hierarchically nested graph, with domains, hosts and Web sites introducing intermediate levels of affiliation and administrative control. To better understand the growth of the Web we need to understand its macro-structure, in terms of the linkage between Web sites. We approximate this by studying the graph of the linkage between hosts on the Web. This was done based on snapshots of the Web taken by Google in Oct 1999, Aug 2000 and Jun 2001. The connectivity between hosts is represented by a directed graph, with hosts as nodes and weighted edges representing the count of hyperlinks between pages on the corresponding hosts. We demonstrate how such a ""hostgraph"" can be used to study connectivity properties of hosts and domains over time, and discuss a modified ""copy model"" to explain observed link weight distributions as a function of subgraph size. We discuss changes in the Web over time in the size and connectivity of Web sites and country domains. We also describe a data mining application of the hostgraph: a related host finding algorithm which achieves a precision of 0.65 at rank 3"
7FEA9D0D	International Conference on Data Mining	wei fan + wenke lee + matthew miller + philip k chan + salvatore j stolfo	2001	Using artificial anomalies to detect unknown and known network intrusions	empirical study + intrusion detection system + intrusion detection systems + data analysis + anomaly detection + training data + government + intrusion detection + computer science + pattern matching		"
Intrusion detection systems (IDSs) must be capable of detecting new and unknown attacks, or anomalies. We study the problem of building detection models for both pure anomaly detection and combined misuse and anomaly detection (i.e., detection of both known and unknown intrusions). We propose an algorithm to generate artificial anomalies to coerce the inductive learner into discovering an accurate boundary between known classes (normal connections and known intrusions) and anomalies. Empirical studies show that our pure anomaly detection model trained using normal and artificial anomalies is capable of detecting more than 77% of all unknown intrusion classes with more than 50% accuracy per intrusion class. The combined misuse and anomaly detection models are as accurate as a pure misuse detection model in detecting known intrusions and are capable of detecting at least 50% of unknown intrusion classes with accuracy measurements between 75% and 100% per class.
"
0C1A3092	International Conference on Data Mining	bernard zenko	2001	A comparison of stacking with meta decision trees to other combining methods	linear regression + decision tree + data mining		"
Meta decision trees (MDTs) are a method for combining multiple classi ers. We present an integration of the algorithm MLC4.5 for learning MDTs into the Weka data mining suite. We compare classi er ensembles combined with MDTs to bagged and boosted decision trees, and to classi er ensembles combined with other methods: voting, grading, multi-scheme and stacking with multi-response linear regression.
"
7D366A0E	International Conference on Data Mining	dhiral gada + vasundhara puttagunta + konstantinos kalpakis	2001	Distance measures for effective clustering of ARIMA time-series	autoregressive moving average processes + data mining + moving average + LPC cepstral coefficients + cepstral coefficients + arima models + auto regressive + socioeconomic data + cepstral analysis + time series data + linear predictive coding + socio-economic effects + indexing + dissimilarity measure + environmental factors + fourier transforms + cepstrum + ARIMA time-series clustering + time series + euclidean distance + arima model + similarity measures + temporal databases + pattern clustering + time measurement + social sciences + Euclidean distance + autoregressive integrated moving average + clustering + economic cybernetics + distance measure + partition-around-medoids method + principal component analysis + environmental data	AuthorProvided Keywords Not Found	"Much environmental and socioeconomic time-series data can be adequately modeled using autoregressive integrated moving average (ARIMA) models. We call such time series ""ARIMA time series"". We propose the use of the linear predictive coding (LPC) cepstrum for clustering ARIMA time series, by using the Euclidean distance between the LPC cepstra of two time series as their dissimilarity measure. We demonstrate that LPC cepstral coefficients have the desired features for accurate clustering and efficient indexing of ARIMA time series. For example, just a few LPC cepstral coefficients are sufficient in order to discriminate between time series that are modeled by different ARIMA models. In fact, this approach requires fewer coefficients than traditional approaches, such as DFT (discrete Fourier transform) and DWT (discrete wavelet transform). The proposed distance measure can be used for measuring the similarity between different ARIMA models as well. We cluster ARIMA time series using the ""partition around medoids"" method with various similarity measures. We present experimental results demonstrating that, using the proposed measure, we achieve significantly better clusterings of ARIMA time series data as compared to clusterings obtained by using other traditional similarity measures, such as DFT, DWT, PCA (principal component analysis), etc. Experiments were performed both on simulated and real data"
5956F698	International Conference on Data Mining	jian pei + jiawei han + dongqing yang + shojiro nishio + shiwei tang + hongjun lu	2001	H-mine: hyper-structure mining of frequent patterns in large databases	dynamic link adjustment + space overhead + data analysis + space-preserving mining + frequent patterns + data mining + very large database + memory-based setting + frequency + database theory + difference set + hyperlinked data structure + H-mine + FP-trees + clustering algorithms + very large databases + hyper-structure mining + assembly + H-struct + data structures + linked data + large databases	AuthorProvided Keywords Not Found	Methods for efficient mining of frequent patterns have been studied extensively by many researchers. However, the previously proposed methods still encounter some performance bottlenecks when mining databases with different data characteristics, such as dense vs. sparse, long vs. short patterns, memory-based vs. disk-based, etc. In this study, we propose a simple and novel hyper-linked data structure, H-struct and a new mining algorithm, H-mine, which takes advantage of this data structure and dynamically adjusts links in the mining process. A distinct feature of this method is that it has very limited and precisely predictable space overhead and runs really fast in memory-based setting. Moreover it can be scaled up to very large databases by database partitioning, and when the data set becomes dense, (conditional) FP-trees can be constructed dynamically as part of the mining process. Our study shows that H-mine has high performance in various kinds of data, outperforms the previously developed algorithms in different settings, and is highly scalable in mining large databases. This study also proposes a new data mining methodology, space-preserving mining, which may have strong impact in the future development of efficient and scalable data mining methods
07216B01	International Conference on Data Mining	s ahmed m aurisicchio + peter b c matthews	2001	Extracting Experience through Protocol Analysis	indexation + protocol analysis + knowledge management system		"
Protocol Analysis provides a means for extracting a person's thoughts while they are performing a task. This paper used this method for generating an index of keywords based on the transcript generated through protocol analysis of an engineer working on a design project. An algorithm for processing such a body of text is described. The means for analyzing the index to form a network of keywords is introduced through the use of an illustration. The illustration is taken from a designer working on a new compressor for a gas turbine engine. The use of such an index is compared to similar indices generated using formal documentation, and the impact this would have on knowledge management systems is discussed.
"
7F9B1611	International Conference on Data Mining	gang li + xiaoshu hang + honghua dai	2001	Inexact field learning: an approach to induce high quality rules from low quality data	data analysis + mathematics + high quality rule induction + prediction accuracy rate + testing + rule derivation + accuracy + uncertainty handling + learning + inexact field learning approach + inexact field learning + gold + learning artificial intelligence + automation + low quality problem + attribute point values + low quality data + very large databases + training data + unseen test cases + learning (artificial intelligence)	AuthorProvided Keywords Not Found	To avoid low quality problems caused by low quality data, the paper introduces an inexact field learning approach which derives rules by working on the fields of attributes with respect to classes, rather than on individual point values of attributes. The experimental results show that field learning achieved a higher prediction accuracy rate on new unseen test cases which is particularly true when the learning is performed on large low quality data
7D9FF117	International Conference on Data Mining	david hart + selina chu + michael pazzani + eamonn keogh	2001	An online algorithm for segmenting time series	databases + data representation + indexing + piecewise linear techniques + online algorithm + data mining + empirical comparison + association rules + time series segmentation + time series + classification + time-series database mining + piecewise linear approximation + association rule mining + computer science + online operation + reviews + clustering algorithms + review + clustering + time series data	AuthorProvided Keywords Not Found	In recent years, there has been an explosion of interest in mining time-series databases. As with most computer science problems, representation of the data is the key to efficient and effective solutions. One of the most commonly used representations is piecewise linear approximation. This representation has been used by various researchers to support clustering, classification, indexing and association rule mining of time-series data. A variety of algorithms have been proposed to obtain this representation, with several algorithms having been independently rediscovered several times. In this paper, we undertake the first extensive review and empirical comparison of all proposed techniques. We show that all these algorithms have fatal flaws from a data-mining perspective. We introduce a novel algorithm that we empirically show to be superior to all others in the literature
7F1D8836	International Conference on Data Mining	stefan ruping	2001	Incremental learning with support vector machines	support vector machines + computer science + working paper + machine learning + learning artificial intelligence + training data + support vector + support vector machine + testing + artificial intelligence + high dimensional data + robustness	 + Support Vector Machines + Incremental Learning	"
Support Vector Machines (SVMs) have become a popular tool for learning with large amounts of high dimensional data. However, it may sometimes be preferable to learn incrementally from previous SVM results, as computing a SVM is very costly in terms of time and memory consumption or because the SVM may be used in an online learning setting. In this paper an approach for incremental learning with Support Vector Machines is presented, that improves existing approaches. Empirical evidence is given to prove that this approach can effectively deal with changes in the target concept that are results of the incremental learning setting.
"
7E9B4BD7	International Conference on Data Mining	byunghoon park + hillol kargupta	2001	Mining decision trees from data streams in a mobile environment	data mining + microcomputer applications + ticker-based approach + fourier analysis + decision tree + mobile computing + touchpad + computer science + data visualisation + Fourier spectrum + data visualization + tree data structures + notebook computers + wireless network + continuous data streams + personal digital assistants + decision tree visualization + decision tree aggregation + mobile environment + decision tree mining + wireless networks + Fourier analysis + Fourier representation + mobile computer + spectrum + decision trees + Fourier transform spectra + decision tree communication + small mobile computing devices	AuthorProvided Keywords Not Found	This paper presents a novel Fourier analysis-based technique to aggregate, communicate and visualize decision trees in a mobile environment. A Fourier representation of a decision tree has several useful properties that are particularly useful for mining continuous data streams from small mobile computing devices. This paper presents algorithms to compute the Fourier spectrum of a decision tree and vice versa. It offers a framework to aggregate decision trees in their Fourier representations. It also describes a touchpad/ticker-based approach to visualize decision trees using their Fourier spectrum and an implementation for PDAs
7E4C6272	International Conference on Data Mining	fanchen tseng + harry chen + chingchi hsu	2001	Mining frequent closed itemsets with the frequent pattern list	candidate generation + computer science + algorithm design and analysis + frequent closed itemset mining + data mining + data structure + association rules + frequent pattern list + data structures + filtering + FPLCI-mining	frequent closed itemset + frequent pattern list	The mining of a complete set of frequent itemsets will lead to a huge number of itemsets. Fortunately, this problem can be reduced to the mining of frequent closed itemsets (FCIs), which results in a much smaller number of itemsets. The approaches to mining frequent closed itemsets can be categorized into two groups: those with candidate generation and those without. In this paper, we propose an approach to mining frequent closed itemsets without candidate generation with a data structure called the frequent pattern list (FPL). We designed the algorithm FPLCI-mining to mine the FCIs. Experimental results show that our method is faster than previous ones
7D429689	International Conference on Data Mining	suhail ansari + zijian zheng + llew mason + ron kohavi	2001	Integrating e-commerce and data mining: architecture and challenges	transaction processing + data warehouse + knowledge discovery projects + visualization + metadata + web pages + data mining algorithms + data mining + knowledge discovery + user interfaces + transaction processing systems + multiple views + integrated architecture + e-commerce domain + computer architecture + data visualisation + data visualization + data transformation + customer event streams + clickstreams + electronic commerce + application server layer + information resources + mining workbench + meta data + data understanding + data logging + data transformation bridges + e commerce + OLAP + data collection + web server + application server + e-commerce/data mining integration + olap + data warehouses	AuthorProvided Keywords Not Found	We show that the e-commerce domain can provide all the right ingredients for successful data mining. We describe an integrated architecture for supporting this integration. The architecture can dramatically reduce the pre-processing, cleaning, and data understanding effort often documented to take 80% of the time in knowledge discovery projects. We emphasize the need for data collection at the application server layer (not the Web server) in order to support logging of data and metadata that is essential to the discovery process. We describe the data transformation bridges required from the transaction processing systems and customer event streams (e.g., clickstreams) to the data warehouse. We detail the mining workbench, which needs to provide multiple views of the data through reporting, data mining algorithms, visualization, and OLAP. We conclude with a set of challenges
7E6DA349	International Conference on Data Mining	andreas hotho + steffen staab + alexander maedche	2001	Text clustering based on good aggregations	text analysis + high dimensional space + web pages + text clustering + preprocessing + data mining + knowledge management + navigation + pattern clustering + clustering algorithms + background knowledge + k means + data warehouses + feature selection + ontology + ontologies + good aggregations	AuthorProvided Keywords Not Found	Text clustering typically involves clustering in a high dimensional space, which appears difficult with regard to virtually all practical settings. In addition, given a particular clustering result it is typically very hard to come up with a good explanation of why the text clusters have been constructed the way they are. We propose a new approach for applying background knowledge (in terms of an ontology) during preprocessing in order to improve clustering results and allow for selection between results. The results may be distinguished and explained by the corresponding selection of concepts in the ontology. Our results compare favourably with a sophisticated baseline preprocessing strategy
7F59D517	International Conference on Data Mining	george karypis + michihiro kuramochi	2001	Frequent subgraph discovery	large graph databases + data mining + association rules + visual databases + subgraph isomorphism + frequent subgraph discovery + computer science + very large databases + labeling + computationally hard problems + data mining techniques + subgraph discovery + data sets + chemical compound dataset + object modeling + computationally efficient algorithm + frequent itemsets + synthetic datasets + canonical labeling + graph transactions + input transactions + computer vision + chemistry computing + image recognition + computational complexity	AuthorProvided Keywords Not Found	As data mining techniques are being increasingly applied to non-traditional domains, existing approaches for finding frequent itemsets cannot be used as they cannot model the requirement of these domains. An alternate way of modeling the objects in these data sets is to use graphs. Within that model, the problem of finding frequent patterns becomes that of discovering subgraphs that occur frequently over the entire set of graphs.The authors present a computationally efficient algorithm for finding all frequent subgraphs in large graph databases. We evaluated the performance of the algorithm by experiments with synthetic datasets as well as a chemical compound dataset. The empirical results show that our algorithm scales linearly with the number of input transactions and it is able to discover frequent subgraphs from a set of graph transactions reasonably fast, even though we have to deal with computationally hard problems such as canonical labeling of graphs and subgraph isomorphism which are not necessary for traditional frequent itemset discovery
7D7BB2D7	International Conference on Data Mining	david johnson + henry chiu + wesley chu + qinghua zou	2001	A pattern decomposition (PD) algorithm for finding all frequent patterns in large datasets	pattern decomposition algorithm + data mining + association rules + FP-tree + set theory + large datasets + computer science + candidate set generation-and-test approach + very large databases + candidate set generation + Apriori algorithm + apriori algorithm + pattern recognition + frequent pattern mining	AuthorProvided Keywords Not Found	Efficient algorithms to mine frequent patterns are crucial to many tasks in data mining. Since the Apriori algorithm was proposed (R. Agrawal and R. Srikant, 1994), there have been several methods proposed to improve its performance. However, most still adopt its candidate set generation-and-test approach. We propose a pattern decomposition (PD) algorithm that can significantly reduce the size of the dataset on each pass, making it more efficient to mine frequent patterns in a large dataset. The proposed algorithm avoids the costly process of candidate set generation and saves time by reducing dataset. Our empirical evaluation shows that the algorithm outperforms Apriori by one order of magnitude and is faster than FP-tree. Further, PD is more scalable than both Apriori and FP-tree
81343169	International Conference on Data Mining	jiawei han + jian pei + w li	2001	CMAR: accurate and efficient classification based on multiple class-association rules	association rule + CMAR + tree structure + UCI machine learning database repository + data mining + association rules + classification accuracy + mined association rules + mined rules + learning artificial intelligence + biased classification + predictive models + very large databases + single high-confidence rule + training data + Classification based on Multiple Association Rules + tree data structures + learning (artificial intelligence) + FP-growth + large database mining + weighted χ2 analysis + overfitting + databases + pattern classification + multiple strong association rules + class distribution-associated FP-tree + information retrieval + machine learning + multiple class-association rules + associative processing + frequent pattern mining method + associative classification method + database coverage + unstructured data + CR-tree structure + efficient classification	AuthorProvided Keywords Not Found	Previous studies propose that associative classification has high classification accuracy and strong flexibility at handling unstructured data. However, it still suffers from the huge set of mined rules and sometimes biased classification or overfitting since the classification is based on only a single high-confidence rule. The authors propose a new associative classification method, CMAR, i.e., Classification based on Multiple Association Rules. The method extends an efficient frequent pattern mining method, FP-growth, constructs a class distribution-associated FP-tree, and mines large databases efficiently. Moreover, it applies a CR-tree structure to store and retrieve mined association rules efficiently, and prunes rules effectively based on confidence, correlation and database coverage. The classification is performed based on a weighted χ2 analysis using multiple strong association rules. Our extensive experiments on 26 databases from the UCI machine learning database repository show that CMAR is consistent, highly effective at classification of various kinds of databases and has better average classification accuracy in comparison with CBA and C4.5. Moreover, our performance study shows that the method is highly efficient and scalable in comparison with other reported associative classification methods
8134D156	International Conference on Data Mining	licheng jiao + lei wang	2001	An immune neural network used for classification	information processing + concrete + artificial neural network + pattern classification + learning algorithm + signal analysis + neural networks + searching + information analysis + classification + neural network + artificial neural networks + learning artificial intelligence + network model + adaptive algorithm + excitation function + learning (artificial intelligence) + neural nets + immune neural network	AuthorProvided Keywords Not Found	Based on an analysis of immune phenomena in nature and utilizing performances of ANN, a novel network mode, i.e., an immune neural network (INN), is proposed which integrates the immune mechanism and the function of neural information processing. The learning algorithm of an INN selects an excitation function and adaptive algorithm of the network. This model makes it easy for a user to utilize directly the characteristic information of a problem and to simplify the original structure by adjusting the excitation function with prior knowledge, improving the working efficiency and searching accuracy. A theoretical analysis and a simulation test for the twin-spiral problem show that, compared with an artificial neural network, INN is not only effective but also feasible. INN can simplify the structure of the existent model and show good working performance
816010D6	International Conference on Data Mining	rodney topor + hong shen + jiuyong li	2001	Mining the smallest association rule set for predictions	transaction processing + association rule + direct method + informative rule set + information technology + very large databases + data mining + association rules + database access + smallest association rule set mining + predictions + transaction database mining	AuthorProvided Keywords Not Found	Mining transaction databases for association rules usually generates a large number of rules, most of which are unnecessary when used for subsequent prediction. In this paper we define a rule set for a given transaction database that is much smaller than the association rule set but makes the same predictions as the association rule set by the confidence priority. We call this subset the informative rule set. The informative rule set is not constrained to particular target items; and it is smaller than the non-redundant association rule set. We present an algorithm to directly generate the informative rule set, i.e., without generating all frequent itemsets first, and that accesses the database less often than other unconstrained direct methods. We show experimentally that the informative rule set is much smaller than both the association rule set and the non-redundant association rule set, and that it can be generated more efficiently
807F3561	International Conference on Data Mining	carlos ordonez + edward omiecinski + norberto ezquerra	2001	A fast algorithm to cluster high dimensional basket data	databases + data mining + association rules + data points + multidimensional systems + maximum likelihood estimation + basket data transactions + pattern clustering + clustering algorithms + very large databases + data set dimensionality + high dimensional basket data clustering + database community + sparse binary vectors + large binary data set clustering + fast algorithm + statistical analysis + data mining problem + data set size + sparse matrices	AuthorProvided Keywords Not Found	Clustering is a data mining problem that has received significant attention by the database community. Data set size, dimensionality and sparsity have been identified as aspects that make clustering more difficult. The article introduces a fast algorithm to cluster large binary data sets where data points have high dimensionality and most of their coordinates are zero. This is the case with basket data transactions containing items, that can be represented as sparse binary vectors with very high dimensionality. An experimental section shows performance, advantages and limitations of the proposed approach
7B9E70F7	International Conference on Data Mining	floris geerts + j van den bussche + bart goethals	2001	A tight upper bound on the number of candidate patterns	artificial intelligent + combinatorial mathematics + database scans + tight upper bound + data mining + level-wise algorithm + upper bound + maximal candidate pattern number + heart + pattern recognition + database theory + frequent pattern mining	AuthorProvided Keywords Not Found	In the context of mining for frequent patterns using the standard level-wise algorithm, the following question arises: given the current level and the current set of frequent patterns, what is the maximal number of candidate patterns that can be generated on the next level? We answer this question by providing a tight upper bound, derived from a combinatorial result by J. Kruskal (1963) and G. Katona (1968). Our result is useful for reducing the number of database scans
7F0F970D	International Conference on Data Mining	tobias scheffer + stefan wrobel + christian decomain	2001	Mining the Web with active hidden Markov models	active hidden Markov models + web mining + data mining + xml document + semi-structured textual documents + sequences + hidden Markov models + unstructured textual documents + hidden markov models + active learning + learning artificial intelligence + speech recognition + clustering algorithms + xml + Web mining + tin + learning (artificial intelligence) + information resources + databases + probability + information retrieval + robustness + unlabeled documents + information extraction + hidden markov model	AuthorProvided Keywords Not Found	Given the enormous amounts of information available only in unstructured or semi-structured textual documents, tools for information extraction (IE) have become enormously important. IE tools identify the relevant information in such documents and convert it into a structured format such as a database or an XML document. While first IE algorithms were hand-crafted sets of rules, researchers soon turned to learning extraction rules from hand-labeled documents. Unfortunately, rule-based approaches sometimes fail to provide the necessary robustness against the inherent variability of document, structure, which has led to the recent interest in using hidden Markov models (HMMs). By using additional unlabeled documents as they are usually readily available in most applications, we can perform active learning of HMMs. The idea of active learning algorithms is to identify unlabeled observations that would be most useful when labeled by the user. Such algorithms are known for classification, clustering, and regression; we present the first algorithm for active learning of hidden Markov models
7E77F813	International Conference on Data Mining	henner graubitz + myra spiliopoulou + karsten winkler	2001	The DIAsDEM framework for converting domain-specific texts into XML documents with data mining techniques	data mining + markup language + XML documents + xml document + semantic tagging + knowledge discovery + knowledge management + markup languages + DIAsDEM framework + domain-specific text conversion + satisfiability + terminology + xml + xml documents + text mining + court filings + hypermedia markup languages + semiautomatically determined cluster labels + structural text units + project management + flat XML DTD + company reports + content similarity + archive + relational databases + iterative clustering + German Commercial Register + quality criteria + data warehouses	AuthorProvided Keywords Not Found	Modern organizations are accumulating huge volumes of textual documents. To turn archives into valuable knowledge sources, textual content must become explicit and able to be queried. Semantic tagging with markup languages such as XML satisfies both requirements. We thus introduce the DIAsDEM* framework for extracting semantics from structural text units (e.g., sentences), assigning XML tags to them and deriving a flat XML DTD for the archive. DIAsDEM focuses on archives characterized by a peculiar terminology and by an implicit structure such as court filings and company reports. In the knowledge discovery phase, text units are iteratively clustered by similarity of their content. Each iteration outputs clusters satisfying a set of quality criteria. Text units contained in these clusters are tagged with semiautomatically determined cluster labels and XML tags respectively. Additionally, extracted named entities (e.g., persons) serve as attributes of XML tags. We apply the framework in a case study on the German Commercial Register
815AC65F	International Conference on Data Mining	jaana laiho + olli simula + kimmo raivio	2001	Neural analysis of mobile radio access network	multidimensional data clustering + input vector transformation + operational states + prototypes + data mining + telecommunication computing + state vectors + clustering algorithms + self-organising feature maps + call quality information + self-organizing map + data visualization + one cell model + multidimensional data visualization + mobile radio + data analysis + spatiotemporal data + radio access network + data engineering + radio access networks + data consistency + self organizing map + pattern clustering + 2D prototype vector grid + neural analysis + information science + mobile radio access network + base stations + mobile network	AuthorProvided Keywords Not Found	The self-organizing map (SOM) is an efficient tool for visualization and clustering of multidimensional data. It transforms the input vectors on two-dimensional grid of prototype vectors and orders them. The ordered prototype vectors are easier to visualize and explore than the original data. Mobile networks produce a huge amount of spatiotemporal data. The data consists of parameters of base stations (BS) and quality information of calls. There are two alternatives in starting the data analysis. We can build either a general one-cell-model trained using state vectors from all cells, or a model of the network using state vectors with parameters from all mobile cells. In both methods, further analysis is needed to understand the reasons for various operational states of the entire network
7FE80864	International Conference on Data Mining	hisao ishibuchi + takashi yamamoto + tomoharu nakashima	2001	Fuzzy data mining: effect of fuzzy discretization	association rule + continuous attribute + domain interval + pattern classification problem + computational linguistics + data mining + fuzzy set theory + extracted rules + generalization ability + association rules + rule weights + fuzzy data mining + knowledge based systems + computer simulation + pattern classification + standard nonfuzzy discretization + basic measures + testing + fuzzy logic + continuous attributes + computer simulations + machine learning + fuzzy categories + linguistic terms + associative processing + fuzzy regions + knowledge representation + fuzzy discretization + industrial engineering + unseen test patterns + computational modeling + linguistic association rules + discretization + association rule generation	AuthorProvided Keywords Not Found	When we generate association rules, continuous attributes have to be discretized into intervals while our knowledge representation is not always based on such discretization. For example, we usually use some linguistic terms (e.g., young, middle age, and old) for dividing our ages into some fuzzy categories. We describe the extraction of linguistic association rules and examine the performance of extracted rules. First we modify the definitions of the two basic measures (i.e., confidence and support) of association rules for extracting linguistic association rules. The main difference between standard and linguistic association rules is the discretization of continuous attributes. We divide the domain interval of each attribute into some fuzzy regions (i.e., linguistic terms) when we extract linguistic association rules. Next, we compare fuzzy discretization with standard non-fuzzy discretization through computer simulations on a pattern classification problem with many continuous attributes. The classification performance of extracted rules on unseen test patterns is examined under various conditions. Simulation results show that linguistic association rules with rule weights have high generalization ability even when the domain of each continuous attribute is homogeneously partitioned
08B9E4E5	International Conference on Data Mining	bernard zenko	2001	A comparison of stacking with MDTs to bagging, boosting, and other stacking methods	data mining + decision tree + linear regression + nearest neighbor + naive bayes		"
In this paper, we present an integration of the algorithm MLC4.5 for learning meta decision trees (MDTs) into the Weka data mining suite. MDTs are a method for combining multiple classi ers. Instead of giving a prediction, MDT leaves specify which classi er should be used to obtain a prediction. The algorithm is based on the C4.5 algorithm for learning ordinary decision trees. An extensive performance evaluation of stacking with MDTs on twenty-one data sets has been performed. We combine base-level classi ers generated by three learning algorithms: an algorithm for learning decision trees, a nearest neighbor algorithm and a naive Bayes algorithm. We compare MDTs to bagged and boosted decision trees, and to combined classi ers with voting and three di erent stacking methods: with ordinary decision trees, with naive Bayes algorithm and with multi-response linear regression as a meta-level classi er. In terms of performance, stacking with MDTs gives better results than other methods except when compared to stacking with multi-response linear regression as a meta-level classi er; the latter is slightly better than MDTs.
"
7F3D83B3	International Conference on Data Mining	chris h q ding + xiaofeng he + horst d simon + ming gu + hongyuan zha	2001	A min-max cut algorithm for graph partitioning and data clustering	data object pairwise similarities + application software + linkage-based refinements + mathematics + graph theory + data mining + data clustering + minimax techniques + linkage differential + adjacency matrix + computer science + clustering algorithms + graph model + weighted graph adjacency matrix + newsgroup data sets + graph partitioning + Fiedler vector + objective function + linearized search order + relaxed optimization + fiedler vector + testing + helium + lower bounds + balanced partitions + clustering quality + vectors + pattern clustering + algorithm performance + spectral graph partition + mathematical model + min-max cut algorithm	AuthorProvided Keywords Not Found	An important application of graph partitioning is data clustering using a graph model - the pairwise similarities between all data objects form a weighted graph adjacency matrix that contains all necessary information for clustering. In this paper, we propose a new algorithm for graph partitioning with an objective function that follows the min-max clustering principle. The relaxed version of the optimization of the min-max cut objective function leads to the Fiedler vector in spectral graph partitioning. Theoretical analyses of min-max cut indicate that it leads to balanced partitions, and lower bounds are derived. The min-max cut algorithm is tested on newsgroup data sets and is found to out-perform other current popular partitioning/clustering methods. The linkage-based refinements to the algorithm further improve the quality of clustering substantially. We also demonstrate that a linearized search order based on linkage differential is better than that based on the Fiedler vector, providing another effective partitioning method
7F30C6C7	International Conference on Data Mining	ning zhong + muneaki ohshima + setsuo ohsuga + y y yao	2001	Interestingness, peculiarity, and multi-database mining	hidden pattern discovery + association rule + peculiarity oriented mining + data mining + association rules + distributed processing + peculiarity rules + relational databases + relevance + filtration + computer science + interestingness + distributed databases + multidatabase mining + exception rules	AuthorProvided Keywords Not Found	In order to discover new, surprising, interesting patterns hidden in data, peculiarity oriented mining and multidatabase mining are required. In the paper, we introduce peculiarity rules as a new class of rules, which can be discovered from a relatively low number of peculiar data by searching the relevance among the peculiar data. We give a formal interpretation and comparison of three classes of rules: association rules, exception rules, and peculiarity rules, as well as describe how to mine more interesting peculiarity rules in multiple databases
7F795E8F	International Conference on Data Mining	karam gouda + mohammed j zaki	2001	Efficiently mining maximal frequent itemsets	progressive focusing + data mining + association rules + frequency + optimisation + computer science + efficient maximal frequent itemset mining + backtracking + backtrack search based algorithm + search space + dataset + diffset propagation + GenMax + search space pruning + maximality checking + optimizations	AuthorProvided Keywords Not Found	We present GenMax, a backtracking search based algorithm for mining maximal frequent itemsets. GenMax uses a number of optimizations to prune the search space. It uses a novel technique called progressive focusing to perform maximality checking, and diffset propagation to perform fast frequency computation. Systematic experimental comparison with previous work indicates that different methods have varying strengths and weaknesses based on dataset characteristics. We found GenMax to be a highly efficient method to mine the exact set of maximal patterns
7DB0BE09	International Conference on Data Mining	virginia wheway	2001	Using boosting to simplify classification models	artificial intelligent + ensemble classifiers + information technology + unseen cases + mathematics + data mining + artificial intelligence + edge analysis + computer science + border region detection + classification model simplification + margin balancing + training data + interpretability + classification error + overfitting + pattern classification + boosting + error analysis + generalisation error + inverse sub-contexts + robustness + diagnostic measures + acoustical engineering + generalisation (artificial intelligence) + margin analysis + modelling + iterations + data set partitioning + mislabelled observations + edge distribution + confounding removal	AuthorProvided Keywords Not Found	"Ensemble classification techniques such as bagging, boosting and arcing algorithms have been shown to lead to reduced classification errors on unseen cases and seem immune to the problem of overfitting. Several explanations for the reduction in generalisation error have been presented, with recent authors defining and applying diagnostics such as ""edge"" and ""margin"". These measures provide insight into the behaviour of ensemble classifiers, but can they be exploited further? In this paper, a four-stage classification procedure in introduced, which is based on an extension of edge and margin analysis. This new procedure allows inverse sub-contexts and difficult border regions to be detected using properties of the edge distribution. It is widely known that ensemble classifiers 'balance' the margin as the number of iterations increases. However, by exploiting this balancing property and flagging observations whose edges (and margins) are not 'balanced', data sets can often be partitioned into sub contexts and the classification can be made more robust as confounding within a data set is removed. In the majority of cases, the sub-contexts detected are inverse to each other or, quite possibly, the smaller sub-context contains mis-labelled observations. The majority of classification techniques have not been adapted to detect contexts within a data set, and the generalisation error reported in studies to date is based on the entire data set and can be improved by partitioning the data set in question. The aim of this study is to move towards interpretability, and it is shown that, by training on a sub-set of the original training data, we gain simplicity of models and reduced generalisation error"
7E324C96	International Conference on Data Mining	eepeng lim + aixin sun	2001	Hierarchical text classification and evaluation	information system + text analysis + top down + leaf categories + topdown level-based classification method + category-similarity measures + hierarchical text evaluation + trees (mathematics) + testing + document + space technology + classification + performance measures + sun + tree graphs + distance-based measures + hierarchical category space + internal categories + hierarchical text classification + Reuters text collection + information systems + category tree	AuthorProvided Keywords Not Found	Hierarchical classification refers to the assignment of one or more suitable categories from a hierarchical category space to a document. While previous work in hierarchical classification focused on virtual category trees where documents are assigned only to the leaf categories, we propose a top-down level-based classification method that can classify documents to both leaf and internal categories. As the standard performance measures assume independence between categories, they have not considered the documents incorrectly classified into categories that are similar to or not far from correct ones in the category tree. We therefore propose category-similarity measures and distance-based measures to consider the degree of misclassification in measuring the classification performance. An experiment has been carried out to measure the performance of our proposed hierarchical classification method. The results showed that our method performs well for a Reuters text collection when enough training documents are given and the new measures have indeed considered the contributions of misclassified documents
809A40DE	International Conference on Data Mining	huan liu + kian lee tan + manoranjan dash	2001	Efficient yet accurate clustering	sampling methods + data analysis + cluster pair merging + tree structure + HAC algorithms + partially overlapping partitioning + data mining + efficient accurate clustering + high-dimensional data + robustness + world wide web + memory requirement + POP + 90-10 rule + high dimensional data + pattern clustering + clustering algorithms + very large databases + labeling + maximum dissimilarity + tree data structures + hierarchical agglomerative clustering algorithms	AuthorProvided Keywords Not Found	The authors show that most hierarchical agglomerative clustering (HAC) algorithms follow a 90-10 rule where roughly 90% iterations from the beginning merge cluster pairs with dissimilarity less than 10% of the maximum dissimilarity. We propose two algorithms: 2-phase and nested, based on partially overlapping partitioning (POP). To handle high-dimensional data efficiently, we propose a tree structure particularly suitable for POP. Extensive experiments show that the proposed algorithms reduce the time and memory requirement of existing HAC algorithms significantly without compromising accuracy
81060C49	International Conference on Data Mining	mohamed bendou + paul munteanu	2001	The EQ framework for learning equivalence classes of Bayesian networks	bayesian network + data mining + essential graphs + generic learning model + bayesian methods + score + learning artificial intelligence + search + directed graph + probability distribution + belief networks + learning (artificial intelligence) + search problems + bayesian networks + databases + processing procedures + algorithm design and analysis + space exploration + testing + operational characterizations + sections + EQ framework + directed graphs + Bayesian networks + equivalence classes + equivalence class learning + algorithm design	AuthorProvided Keywords Not Found	This paper proposes a theoretical and an algorithmic framework for the analysis and the design of efficient learning algorithms which explore the space of equivalence classes of Bayesian network structures. This framework is composed of a generic learning model which uses essential graphs and more general partially directed graphs in order to represent the equivalence classes evaluated during search, operational characterizations of these graphs, processing procedures and formulas for directly calculating their score. The experimental results of the algorithms designed within this framework show that the space of equivalence classes may be explored efficiently and with better results than the classical search in the space of Bayesian network structures
80458B06	International Conference on Data Mining	tadashi nomoto + yuji matsumoto	2001	An experimental comparison of supervised and unsupervised approaches to text summarization	k means clustering + text analysis + text summarization + K-means clustering algorithm + unsupervised text summarization + supervised text summarization + decision tree + learning artificial intelligence + pattern clustering + clustering algorithms + minimum description length principle + decision trees + C4.5 decision tree algorithm + natural languages + k means clustering algorithm + learning (artificial intelligence)	AuthorProvided Keywords Not Found	The paper presents a direct comparison of supervised and unsupervised approaches to text summarization. As a representative supervised method, we use the C4.5 decision tree algorithm, extended with the minimum description length principle (MDL), and compare it against several unsupervised methods. It is found that a particular unsupervised method based on an extension of the K-means clustering algorithm, performs equal to and in some cases superior to the decision tree based method
80E621D1	International Conference on Data Mining	rong chen + krishnamoorthy sivakumar + hillol kargupta	2001	Distributed Web mining using Bayesian networks from multiple data streams	information resources + distributed Web mining + bayesian network + design optimization + scalability issues + collective Bayesian network + web mining + data mining + world wide web + nonlocal variables + web design + web server + bayesian methods + learning artificial intelligence + multiple data streams + response time + distributed algorithms + local variables + collective approach + distributed heterogenous Web-log data streams + local Bayesian network + belief networks + learning (artificial intelligence) + data centralization	AuthorProvided Keywords Not Found	We present a collective approach to mining Bayesian networks from distributed heterogenous Web-log data streams. In this approach we first learn a local Bayesian network at each site using the local data. Then each site identifies the observations that are most likely to be evidence of coupling between local and non-local variables and transmits a subset of these observations to a central site. Another Bayesian network is learnt at the central site using the data transmitted from the local site. The local and central Bayesian networks are combined to obtain a collective Bayesian network that models the entire data. We applied this technique to mining multiple data streams, where data centralization is difficult because of large response time and scalability issues. Experimental results and theoretical justification that demonstrate the feasibility of our approach are presented
7DC3FDDC	International Conference on Data Mining	henry e kyburg	2001	Statistical considerations in learning from data	databases + sampling methods + cognition + data mining + classical statistics + sociotechnical systems + uncertainty handling + reliability theory + uncertainty + objectivity + bayesian methods + learning artificial intelligence + Bayesian statistics + background knowledge + learning from data + probability distribution + bayesian statistics + Bayes methods + learning (artificial intelligence) + objective reliability measure + statistics	AuthorProvided Keywords Not Found	In this paper, we focus on statistics. Classical statistics and Bayesian statistics are both employed in data mining. Both have advantages but both also have severe limitations in this context. We point out some of these limitations as well as some of the advantages. The fact that we may need to take account of evidence both internal and external to the data set presents a difficulty for classical statistics. The need to incorporate an objective measure of reliability creates a difficulty for Bayesian statistics. We outline an approach to uncertainty that promises to capture the best of both worlds by incorporating both background knowledge and objectivity
7F75E223	International Conference on Data Mining	mohamed ben haj rhouma + hichem frigui	2001	A synchronization based algorithm for discovering ellipsoidal clusters in large datasets	cluster number determination + self-organization + color + mathematics + data mining + data subset loading + large color image segmentation + data point representation + oscillator interactions + image segmentation + clustering algorithms + scaling phenomena + self-organising feature maps + synthetic data + ellipsoidal cluster discovery + large data sets + pulse-coupled oscillator synchronization + image colour analysis + scalable clustering approach + oscillations + stability + oscillators + robust method + data analysis + integrate-and-fire oscillators + robustness + self-adjusting systems + synchronization-based algorithm + stable phase-locked subgroups + synchronisation + pattern clustering + self organization + color image + relative point similarity + synchronized oscillator group summarization + memory purging	AuthorProvided Keywords Not Found	This paper introduces a new scalable approach to clustering based on the synchronization of pulse-coupled oscillators. Each data point is represented by an integrate-and-fire oscillator and the interaction between oscillators is defined according to the relative similarity between the points. The set of oscillators self-organizes into stable phase-locked subgroups. Our approach proceeds by loading only a subset of the data and allowing it to self-organize. Groups of synchronized oscillators are then summarized and purged from memory. We show that our method is robust, scales linearly and can determine the number of clusters. The proposed approach is empirically evaluated with several synthetic data sets and is used to segment large color images
7E027131	International Conference on Data Mining	yongdai kim	2002	Convex Hull Ensemble Machine	data mining + accuracy + hilbert spaces + learning artificial intelligence + CHEM + Gradient Boost + hilbert space + Hilbert space + learning (artificial intelligence) + ensemble algorithm + pattern classification + adaboost + solid modeling + output noise + bagging + empirical study + Hilbert spaces + classification + machine learning + convex hull + AdaBoost + Convex Hull Ensemble Machine + regression + decision trees + geometry + statistical analysis + Bagging + statistics	AuthorProvided Keywords Not Found	We propose a new ensemble algorithm called Convex Hull Ensemble Machine (CHEM). CHEM in Hilbert space is developed first and it is modified to regression and classification problems. Empirical studies show that in classification problems CHEM has similar prediction accuracy as AdaBoost, but CHEM is much more robust to output noise. In regression problems, CHEM works competitively with other ensemble methods such as Gradient Boost and Bagging.
72C2027A	International Conference on Data Mining	neil dunstan + r d murison + stephen hodgson	2002	Wavelet based UXO detection	wavelet based UXO detection + pattern classification + large template sets + unexploded ordnance classification + wavelet transforms + data mining + wavelet transform + azimuth + frequency + library + computer science + environmental economics + multidimensional pattern recognition problem + calibration + landmine detection + military computing + pattern recognition	AuthorProvided Keywords Not Found	The detection and classification of unexploded ordnance (UXO) is considered a multidimensional pattern recognition problem. Standard techniques in solving multidimensional detection and classification problems involve using large sets of templates or libraries. This paper shows that by using wavelet transformation a single library will allow a particular class of ordnance to be classified over a range of depths.
72ACB3B1	International Conference on Data Mining	stefano m trisolini + stefano cazzella + luigi dragone	2002	Telecommunications strategic marketing - KDD and economic modeling	profitability + microeconomics + sampling methods + TELECOM Italia + economic impact + data mining + testing + economic modeling + telecommunication computing + decision support systems + telecommunications + Italian deregulation process + econometrics + decision support system + economic model + environmental economics + economic forecasting + residential telecommunications market	AuthorProvided Keywords Not Found	The Italian deregulation process of telecommunications market in the last years has produced a large economic impact since it has altered equilibriums that were established for a long time. In this framework, we notice a strong need for adequate tools to analyze the market and its trends and, at the same time, a lack of specific solutions within the scientific literature, due to the new technical challenges issued by the problem. In particular, in the context of building a Decision Support System (DSS) for the strategic marketing unit of TELECOM Italia (TI) we have devised a new methodology to profitably combine most powerful tools from KDD and Economic Sciences. We have tested our approach by analyzing the residential telecommunications market demand in Italy during the transition from a monopolistic structure to an oligopolistic one. In this paper, we first address the state of the art in DSS design, then we describe the proposed methodology and its application in the case study.
7CE9EAEB	International Conference on Data Mining	t natarajan + se june hong + j r m hosking	2002	Ensemble modeling through multiplicative adjustment of class probability	machine learning data set + UCI dataset + data mining + logistics + APMR + learning artificial intelligence + predictive models + naive bayes + very large databases + training data + niobium + parameter estimation + learning (artificial intelligence) + feature selection + boosting + probability + multiplicative adjustment + bagging + sections + class probability estimation + Adjusted Probability Model + Naive Bayes + additives + feature importance + ensemble modeling + Bayes methods	AuthorProvided Keywords Not Found	We develop a new concept for aggregating items of evidence for class probability estimation. In Naive Bayes, each feature contributes an independent multiplicative factor to the estimated class probability. We modify this model to include an exponent in each factor in order to introduce feature importance. These exponents are chosen to maximize the accuracy of estimated class probabilities on the training data. For Naive Bayes, this modification accomplishes more than what feature selection can. More generally, since the individual features can be the outputs of separate probability models, this yields a new ensemble modeling approach, which we call APM (Adjusted Probability Model), along with a regularized version called APMR.
8140C4D1	International Conference on Data Mining	joseph l hellerstein + genady grabarnik + sheng ma + changshing perng	2002	Progressive and interactive analysis of event data using event miner	application software + pattern analysis + data model + Event Miner + data analysis + data selection + data summarization + data security + data mining + information security + knowledge discovery + information analysis + scalability + data models + computer network + event data mining + data visualisation + categorical data + data visualization + interactive data analysis	AuthorProvided Keywords Not Found	Exploring large data sets typically involves activities that iterate between data selection and data analysis, in which insights obtained from analysis result in new data selection. Further, data analysis needs to use a combination of analysis techniques: data summarization, mining algorithms and visualization. This interweaving of functions arises both from the semantics of what the analyst hopes to achieve and from scalability requirements for dealing with large data volumes. We refer to such a process as a progressive analysis. Herein is described a tool, Event Miner, that integrates data selection, mining and visualization for progressive analysis of temporal, categorical data. We discuss a data model and architecture. We illustrate how our tool can be used for complex mining tasks such as finding patterns not occurring on Monday. Further, we discuss the novel visualization employed, such as visualizing categorical data and the results of data mining. Also, we discuss the extension of the existing mining framework needed to mine temporal events with multiple attributes. Throughout, we illustrate the capabilities of Event Miner by applying it to event data from large computer networks.
80A78742	International Conference on Data Mining	john yen + thomas r ioerger + dwi h widyantoro	2002	An incremental approach to building a cluster hierarchy	data analysis + data mining + information retrieval + information analysis + monotonicity + homogeneity + incremental hierarchical clustering algorithm + pattern clustering + satisfiability + clustering algorithms + hierarchy restructuring process sequence + bottom up + tree data structures + computational time + ontologies + cluster hierarchy + computational complexity	AuthorProvided Keywords Not Found	In this paper we present a novel incremental hierarchical clustering (IHC) algorithm. Our approach aims to construct a hierarchy that satisfies homogeneity and monotonicity properties. Working in a bottom-up fashion, a new instance is placed in the hierarchy and a sequence of hierarchy restructuring processes is performed only in regions that have been affected by the presence of the new instance. The experimental results on a variety of domains demonstrate that our algorithm is not sensitive to input ordering, can produce a quality cluster hierarchy, and is efficient in terms of computational time.
7F27776F	International Conference on Data Mining	shotaro akaho + toshihiro kamishima	2002	Learning from order examples	pattern classification + experimental results + data mining + testing + performance evaluation + learning from order examples task + classification + proper order estimation + sections + regression + sorting + statistical analysis + ordered item set + learning by example + unordered item set	AuthorProvided Keywords Not Found	We advocate a new learning task that deals with orders of items, and we call this the learning from order examples (LOE) task. The aim of the task is to acquire the rule that is used for estimating the proper order of a given unordered item set. The rule is acquired from training examples that are ordered item sets. We present several solution methods for this task, and evaluate the performance and the characteristics of these methods based on the experimental results of tests using both artificial data and realistic data.
81449882	International Conference on Data Mining	phil tse + jiming liu	2002	Mining associated implication networks: computational intermarket analysis	association rule + data analysis + inference + probability + data mining + computer networks + financial market + testing + association rules + inference mechanisms + probabilistic networks + bayesian methods + computer science + technical analysis + associated network structure + financial data processing + belief networks + stock markets + inter market actions + association rules mining + international financial markets	AuthorProvided Keywords Not Found	Current attempts to analyze international financial markets include the use of financial technical analysis and data mining techniques. In this paper, we propose a new approach that incorporates implication networks and association rules to form an associated network structure. The proposed approach explicitly addresses the issue of local vs. global influences between financial markets.
7E5E4CC8	International Conference on Data Mining	shoji hirano + shusaku tsumoto	2002	Mining similar temporal patterns in long time-series data and its application to medicine	temporal sequences + databases + chronic hepatitis dataset + phase-constraint multiscale matching + pattern matching + data analysis + data mining + time-series medical databases + time series + long time-series data + rough clustering + biomedical informatics + pattern clustering + interpretable sequence clusters + disease onset time + similar temporal pattern mining + medical examination results + time series data + medical computing	AuthorProvided Keywords Not Found	Data mining in time-series medical databases has been receiving considerable attention since it provides a way of revealing useful information hidden in the database; for example relationships between temporal course of examination results and onset time of diseases. This paper presents a new method for finding similar patterns in temporal sequences. The method is a hybridization of phase-constraint multiscale matching and rough clustering. Multiscale matching enables us cross-scale comparison of the sequences, namely, it enable us to compare temporal patterns by partially changing observation scales. Rough clustering enable us to construct interpretable clusters of the sequences even if their similarities are given as relative similarities. We combine these methods and cluster the sequences according to multiscale similarity of patterns. Experimental results on the chronic hepatitis dataset showed that clusters demonstrating interesting temporal patterns were successfully discovered.
812B9F40	International Conference on Data Mining	michael r berthold + david e patterson + bemd wiswedel	2002	Neighborgram clustering. Interactive exploration of cluster neighborhoods	pattern analysis + data analysis + histograms + greedy algorithms + prototypes + expert knowledge + algorithm design and analysis + data mining + data set + local histograms + pattern clustering + clustering algorithms + large data sets + bioinformatics + training data + Neighborgrarn + clustering + data visualization + interactive visualization + program visualisation + computational complexity	AuthorProvided Keywords Not Found	We describe an interactive way to generate a set of clusters for a given data set. The clustering is done by constructing local histograms, which can then be used to visualize, select, and fine-tune potential cluster candidates. The accompanying algorithm can also generate clusters automatically, allowing for an automatic or semi-automatic clustering process where the user only occasionally interacts with the algorithm. We illustrate the ability to automatically identify and visualize clusters using NCI's AIDS Antiviral Screen data set.
7E6A64B5	International Conference on Data Mining	jun wang + bei yu + les gasser	2002	Concept tree based clustering visualization with shaded similarity matrices	conceptual clustering + iris + data mining + graphics + cluster interpretations + machine learning + tree graphs + matrix algebra + learning artificial intelligence + pattern clustering + data visualisation + concept tree based clustering visualization + shaded similarity matrices + data visualization + tree data structures + learning (artificial intelligence) + information science + symmetric matrices + statistics	AuthorProvided Keywords Not Found	One problem with existing clustering methods is that the interpretation of clusters may be difficult. Two different approaches have been used to solve this problem: conceptual clustering in machine learning and clustering visualization in statistics and graphics. The purpose of this paper is to investigate the benefits of combining clustering visualization and conceptual clustering to obtain better cluster interpretations. In our research we have combined concept trees for conceptual clustering with shaded similarity matrices for visualization. Experimentation shows that the two interpretation approaches can complement each other to help us understand data better.
7D4F4289	International Conference on Data Mining	vincent ng + fulai chung + takchug fu + robert luk	2002	Evolutionary time series segmentation for stock data mining	time series analysis + optimization problem + pattern matching + time domain + multiple time series + dynamic approach + fitness computation + evolutionary computing + data mining + pattern templates + perceptually important points + stock patterns + optimisation + controllability + optimization + evolutionary time series segmentation + intuitive pattern matching + technical patterns + financial data processing + stock markets + pattern analysis + shape + testing + time series + meaningful symbols + evolutionary computation + stock data mining + Hong Kong stocks	AuthorProvided Keywords Not Found	Stock data in the form of multiple time series are difficult to process, analyze and mine. However, when they can be transformed into meaningful symbols like technical patterns, it becomes easier. Most recent work on time series queries concentrates only on how to identify a given pattern from a time series. Researchers do not consider the problem of identifying a suitable set of time points for segmenting the time series in accordance with a given set of pattern templates (e.g., a set of technical patterns for stock analysis). On the other hand, using fixed length segmentation is a primitive approach to this problem; hence, a dynamic approach (with high controllability) is preferred so that the time series can be segmented flexibly and effectively according to the needs of users and applications. In view of the fact that such a segmentation problem is an optimization problem and evolutionary computation is an appropriate tool to solve it, we propose an evolutionary time series segmentation algorithm. This approach allows a sizeable set of stock patterns to be generated for mining or query. In addition, defining the similarity between time series (or time series segments) is of fundamental importance in fitness computation. By identifying perceptually important points directly from the time domain, time series segments and templates of different lengths can be compared and intuitive pattern matching can be carried out in an effective and efficient manner. Encouraging experimental results are reported from tests that segment the time series of selected Hong Kong stocks.
7E92F5AF	International Conference on Data Mining	mahesh v joshi	2002	On evaluating performance of classifiers for rare classes	pattern classification + precision values + point-metrics + data mining + testing + rare class prediction + learning + classifier evaluation metric + learning artificial intelligence + predictive models + recall + learning (artificial intelligence) + software performance evaluation + software metrics + classifier performance evaluation	AuthorProvided Keywords Not Found	Predicting rare classes effectively is an important problem. The definition of effective classifier, embodied in the classifier evaluation metric, is however very subjective, dependent on the application domain. In this paper a wide variety of point-metrics are put into a common analytical context defined by the recall and precision of the target rare class. This enables us to compare various metrics in an objective, domain-independent manner. We judge their suitability for the rare class problems along the dimensions of learning difficulty and levels of rarity. This yields many valuable insights. In order to address the goal of achieving better recall and precision, we also propose a way of comparing classifiers directly based on the relationships between recall and precision values. It resorts to a composite point-metric only when recall-precision based comparisons yield conflicting results.
7D3F5CB2	International Conference on Data Mining	loongfah cheong + ankush mittal	2002	Employing discrete Bayes error rate for discretization and feature selection tasks	learning automata + video databases + image classification + data mining + large database + K-nearest neighbor classifier + feature selection tasks + SVM + decision tree + discrete approximation + k nearest neighbor + computer science + very large databases + probability distribution + discrete Bayes error rate + feature selection + support vector machines + svm + video classification problem + classification + neural network classifier + error rate + minimization + decision trees + class-pair discriminatory measure + Bayes methods + discretization + neural nets	AuthorProvided Keywords Not Found	The tasks of discretization and feature selection are frequently used to improve classification accuracy. We use discrete approximation of Bayes error rate to perform discretization on the features. The discretization procedure targets minimization of Bayes error rate within each partition. A class-pair discriminatory measure can be defined on discretized partitions which forms the basis of the feature selection algorithm. A small value of this measure for a class-pair indicates that the class-pair in consideration is confusing and the features which distinguish them well should be chosen first. A video classification problem on a large database is considered for showing the comparison of a classifier using our discretization and feature selection tasks with SVM, neural network classifier, decision trees and K-nearest neighbor classifier.
7E76E86E	International Conference on Data Mining	yoshitsugu kakemoto + ryota suzuki + mariko yohda + akira okada + makiko saitoarita	2002	Demand forecasting by the neural network with discrete Fourier transform	discrete fourier transform + supply chains + data mining + indexation + neural networks + neural network + sales results + frequency + product properties + indexes + very large databases + time series data + economic indicator + demand forecasting + discrete Fourier transforms + fourier transforms + time series + marketing data processing + fourier transform + discrete Fourier transform + marketing + supply chain management + economic indicators + economic forecasting + neural nets	AuthorProvided Keywords Not Found	This paper proposes a new demand forecasting method using a neural network and Fourier transform. In this method, time series data of sales results considered as a combination of frequency are transformed into several frequency data. They are identified from objective indexes that consist of product properties or economic indicators and so forth. This method is efficient for demand forecasting aimed at new products that have no historical data.
7E89E665	International Conference on Data Mining	teresa mah + ying li	2002	Visually mining Web user clickpaths	visual representation + data analysis + data mining + packaging + feedback + clickpath mining methods + navigation + clickpath visualizer PAVE + interactive representation + data visualization + Internet + clickpath visualization + internet + Web user clickpaths mining + mineable knowledge	AuthorProvided Keywords Not Found	As powerful as clickpath mining methods can be, they often lead to huge incomprehensible and non-interesting result sets. Our clickpath mining practice at MSN was faced with challenges of keeping analysts closer to the data exploration process, revealing powerful insight from clickpath mining that business owners can directly act upon. These challenges stressed the importance of an interactive and visual representation of clickpath mining results. Most products today that can perform clickpath visualization do so by presenting massive cross-weaving web graphs. We present a new type of clickpath visualization which focuses only on clickpaths of interest, simplifying the visualization space while still retaining the same degree of mineable knowledge in the data. We also describe visualization techniques we have used to enhance the detection of interesting clickpath patterns from data, and provide a real-life case study that has benefited from the use of our implemented clickpath visualizer PAVE.
7F040391	International Conference on Data Mining	liqiang geng + howard j hamilton	2002	ESRS: a case selection algorithm using extended similarity-based rough sets	complexity + rough sets + case based reasoning + case selection + data mining + accuracy + set theory + machine learning + frequency + ESRS + case base reasoning + learning artificial intelligence + computer science + clustering algorithms + case-based reasoning + computer aided software engineering + rough set + rough set theory + learning (artificial intelligence)	AuthorProvided Keywords Not Found	A case selection algorithm selects representative cases from a large data set for future case-based reasoning tasks. This paper proposes the ESRS algorithm, based on extended similarity-based rough set theory, which selects a reasonable number of the representative cases while maintaining satisfactory classification accuracy. It also can handle noise and inconsistent data. Experimental results on synthetic and real sets of cases showed that its predictive accuracy is similar to that of well-known machine learning systems on standard data sets, while it has the advantage of being applicable to any data set where a similarity function can be defined.
80B6270C	International Conference on Data Mining	jiawei han + kevin chenchuan chang + hwanjo yu	2002	Heterogeneous learner for Web page classification	document handling + pattern classification + search engines + web pages + testing + classification accuracy + machine learning + heterogeneous learner + decision list + linear separator + learning artificial intelligence + computer science + feature extraction + xml + training data + low-margin data + Web sites + learning (artificial intelligence) + machine learning algorithms + Web page classification	AuthorProvided Keywords Not Found	"Classification of an interesting class of Web pages has been an interesting problem. Typical machine learning algorithms for this problem require two classes of data for training: positive and negative training examples. However in application to Web page classification, gathering an unbiased sample of negative examples appears to be difficult. We propose a heterogeneous learning framework for classifying Web pages, which (1) eliminates the need for negative training data, and (2) increases classification accuracy by using two heterogeneous learners. Our framework uses two heterogeneous learners-a decision list and a linear separator which complement each other-to eliminate the need for negative training data in the training phase and to increase the accuracy in the testing phase. Our results show that our heterogeneous framework achieves high accuracy without requiring negative training data; it enhances the accuracy of linear separators by reducing the errors on ""low-margin data"". That is, it classifies more accurately while requiring less human efforts in training."
7D2F738D	International Conference on Data Mining	qiang yang + hong cheng	2002	Mining case bases for action recommendation	profitability + case based reasoning + nearest neighbor algorithm + corporate data + data mining + marketing management + artificial intelligence + informed advice + telecommunications + nearest neighbor + computer science + customers + databases + marketing strategy + action recommendation + marketing strategies + case bases mining + direct marketing + role models + corporations + case base reasoning + institutions + cost effectiveness + case-based reasoning + computer aided software engineering + employees + nearest-neighbor algorithm + finance + business data processing	AuthorProvided Keywords Not Found	Corporations and institutions are often interested in deriving marketing strategies from corporate data and providing informed advice for their customers or employees. For example, a financial institution may derive marketing strategies for turning their reluctant customers into active ones and a telecommunications company may plan actions to stop their valuable customers from leaving. In data mining terms, these advice and action plans are aimed at converting individuals from an undesirable class to a desirable one, or to help devising a direct-marketing plan in order to increase the profit for the institution. We present an approach which uses 'role models' for generating such advice and plans. These role models are typical cases that form a case base and can be used for customer advice generation. For each new customer seeking advice, a nearest-neighbor algorithm is used to find a cost-effective and highly probable plan for switching a customer to the most desirable role models. We explore the tradeoff among time, space and quality of computation in this case-based reasoning framework. We demonstrate the effectiveness of the methods through empirical results.
7D875632	International Conference on Data Mining	wesley w chu + baojing lu + qinghua zou	2002	SmartMiner: a depth first algorithm guided by tail information for mining maximal frequent itemsets	pattern analysis + sampling methods + enumeration trees + data mining + tail + testing + Connect + Mushroom + association rules + datasets + tree searching + transactions + computation complexity + maximal frequent itemsets + computer science + heuristic select function + SmartMiner + discovering association rules + depth first search	eol>Data mining + frequent patterns + maximal frequent pattern + tail information + search space pruning	Maximal frequent itemsets (MR) are crucial to many tasks in data mining. Since the MaxMiner algorithm first introduced enumeration trees for mining MR in 1998, several methods have been proposed to use depth first search to improve performance. To further improve the performance of mining MR, we proposed a technique that takes advantage of the information gathered from previous steps to discover new MR. More specifically, our algorithm called SmartMiner gathers and passes tail information and uses a heuristic select function which uses the tail information to select the next node to explore. Compared with Mafia and GenMax, SmartMiner generates a smaller search tree, requires a smaller number of support counting, and does not require superset checking. Using the datasets Mushroom and Connect, our experimental study reveals that SmartMiner generates the same MFI as Mafia and GenMax, but yields an order of magnitude improvement in speed.
7F03B3C7	International Conference on Data Mining	angela nebot + luis carlos molina + lluis a belanche	2002	Feature selection algorithms: a survey and experimental evaluation	probability + data mining + experimental evaluation + impedance matching + performance + sample data sets + scoring measure + very large databases + feature selection algorithms + supervised inductive learning + noise reduction + survey + feature selection + learning by example	AuthorProvided Keywords Not Found	In view of the substantial number of existing feature selection algorithms, the need arises to count on criteria that enables to adequately decide which algorithm to use in certain situations. This work assesses the performance of several fundamental algorithms found in the literature in a controlled scenario. A scoring measure ranks the algorithms by taking into account the amount of relevance, irrelevance and redundance on sample data sets. This measure computes the degree of matching between the output given by the algorithm and the known optimal solution. Sample size effects are also studied.
7DC2C270	International Conference on Data Mining	giuseppe psaila + rosa meo	2002	Toward XML-based knowledge discovery systems	XDM + data model + pattern analysis + database management system + open systems + data analysis + heterogeneous mined patterns + data mining + information retrieval + knowledge discovery + data models + deductive databases + xml + XML + knowledge discovery systems + inductive databases + hypermedia markup languages	AuthorProvided Keywords Not Found	Inductive databases are intended to be general purpose databases in which both source data and mined patterns can be represented, retrieved and manipulated. However, the heterogeneity of models for mined patterns makes difficult to realize them. In this paper, we explore the feasibility of using XML as the unifying framework for inductive databases, introducing a suitable data model called XDM (XML for data mining). XDM is designed to describe source raw data, heterogeneous mined patterns and data mining statements, so that they can be stored inside a unique XML-based inductive database.
7DB9F1B7	International Conference on Data Mining	yuhjyh hu	2002	Mining a set of coregulated RNA sequences	supervised learning + data mining + coregulated RNA sequence mining + post-transcriptional regulation + RNA secondary structure prediction + sequences + functional interactions + pseudoknot motifs + learning artificial intelligence + biology computing + very large databases + dna + proteins + data sets + stochastic processes + learning (artificial intelligence) + binding site + rna + testing + dynamic programming + genetic algorithms + post transcriptional regulation + bioinformatics + RNA regulatory proteins + scientific information systems + RNA motifs + information science	AuthorProvided Keywords Not Found	Post-transcriptional regulation, though less studied, is an important research topic in bioinformatics. In a set of post-transcriptionally coregulated RNAs, the basepair interactions can organize the molecules into domains and provide a framework for functional interactions. Their consensus motifs may represent the binding sites of RNA regulatory proteins. Unlike DNA motifs, RNA motifs are more conserved in structures than in sequences. Knowing the structural motifs can help us better understand the regulation activities. We propose a novel data mining approach to RNA secondary structure prediction. To demonstrate the performance of our new approach, we first tested it on the same data sets previously used and published in literature. Secondly, to show the flexibility of our new approach, we also tested it on a data set that contains pseudoknot motifs that most current systems cannot identify.
NE153	International Conference on Data Mining	Hong Yao+H. J. Hamilton+C. J. Butz	2002	FD_Mine: discovering functional dependencies in a database using equivalences	databases + pruning + data mining + UCI datasets + functional dependence discovery + relational databases + FD_Mine algorithm + discovered equivalences	AuthorProvided Keywords Not Found	The discovery of FDs from databases has recently become a significant research problem. In this paper, we propose a new algorithm, called FD-Mine. FD-Mine takes advantage of the rich theory of FDs to reduce both the size of the dataset and the number of FDs to be checked by using discovered equivalences. We show that the pruning does not lead to loss of information. Experiments on 15 UCI datasets show that FD-Mine can prune more candidates than previous methods.
7D21C971	International Conference on Data Mining	chiechming wu + yinfu huang	2002	Mining generalized association rules using pruning techniques	transaction processing + association rule + cumulant + data mining + trees (mathematics) + generalized association rule mining + association rules + taxonomy + database management systems + tree graphs + hierarchical taxonomy tree + mining industry + pruning techniques + associative processing + large transaction database + internet + GAMR + frequent itemsets	AuthorProvided Keywords Not Found	The goal of the paper is to mine generalized association rules using pruning techniques. Given a large transaction database and a hierarchical taxonomy tree of the items, we try to find the association rules between the items at different levels in the taxonomy tree under the assumption that original frequent itemsets and association rules have already been generated beforehand In the proposed algorithm GMAR, we use join methods and pruning techniques to generate new generalized association rules. Through several comprehensive experiments, we find that the GMAR algorithm is much better than BASIC and Cumulate algorithms.
NE204	International Conference on Data Mining	Wei Fan+Haixun Wang+P. S. Yu+Shaw-hwa Lo+S. Stolf	2002	Progressive modeling	pattern classification + inductive learning + data mining + batch process + interactive systems + progressive modeling + learning by example	AuthorProvided Keywords Not Found	Presently, inductive learning is still performed in a frustrating batch process. The user has little interaction with the system and no control over the final accuracy and training time. If the accuracy of the produced model is too low, all the computing resources are misspent. In this paper we propose a progressive modeling framework. In progressive modeling, the learning algorithm estimates online both the accuracy of the final model and remaining training time. If the estimated accuracy is far below expectation, the user can terminate training prior to completion without wasting further resources. If the user chooses to complete the learning process, progressive modeling will compute a model with expected accuracy in expected time. We describe one implementation of progressive modeling using ensemble of classifiers.
NE227	International Conference on Data Mining	Xiong Wang	2002	ΔB+ tree: indexing 3D point sets for pattern discovery	data representation + 3D point set indexing + multiple point sets + data mining +  tree + pattern discovery + performance evaluation + geometric hashing technique + index structure + ΔB + database indexing + tree data structures + pattern recognition + point triplet information storage + subsets	AuthorProvided Keywords Not Found	Three-dimensional point sets can be used to represent data in different domains. Given a database of 3D point sets, pattern discovery looks for similar subsets that occur in multiple point sets. Geometric hashing has proved to be an effective technique in discovering patterns in 3D point sets. However, the method are has shortcomings. We propose a new indexing technique called ΔB+ trees. It is an extension of B+-trees that stores point triplet information and overcomes shortcomings of the geometric hashing technique. We introduce four different ways of constructing the key from a triplet. We give an analytical comparison between the new index structure and the geometric hashing technique. We also conduct experiments on both synthetic data and real data to evaluate performance.
7EE36AEC	International Conference on Data Mining	masakazu seno + george karypis	2002	SLPMiner: an algorithm for finding frequent sequential patterns using length-decreasing support constraint	algorithms + SLPMiner + data mining + frequent sequential pattern finding + patterns + association rules + speedup + constant support constraint + runtime + sequences + very large sequential databases + exponential complexity + length-decreasing support constraint + computer science + satisfiability + very large databases + high performance computing + search space + data bases	AuthorProvided Keywords Not Found	Over the years, a variety of algorithms for finding frequent sequential patterns in very large sequential databases have been developed. The key feature in most of these algorithms is that they use a constant support constraint to control the inherently exponential complexity of the problem. In general, patterns that contain only a few items will tend to be interesting if they have good support, whereas long patterns can still be interesting even if their support is relatively small. Ideally, we need an algorithm that finds all the frequent patterns whose support decreases as a function of their length. In this paper we present an algorithm called SLPMiner that finds all sequential patterns that satisfy a length-decreasing support constraint. Our experimental evaluation shows that SLPMiner achieves up to two orders of magnitude of speedup by effectively exploiting the length-decreasing support constraint, and that its runtime increases gradually as the average length of the sequences (and the discovered frequent patterns) increases.
7D73224A	International Conference on Data Mining	huiwen wu + dimitrios gunopulos	2002	Evaluating the utility of statistical phrases and latent semantic indexing for text classification	text analysis + support vector machines + latent semantic indexing + indexing + vector space model + data mining + information retrieval + adjacent phrase extraction + textual information retrieval + text classification + classification + frequency + statistical phrases + term-based vector space model + computer science + vector-based document classification + window phrase extraction + statistical analysis + dimensionality reduction method + dictionaries + single-word terms	AuthorProvided Keywords Not Found	The term-based vector space model is a prominent technique for retrieving textual information. In this paper we examine the usefulness of phrases as terms in vector-based document classification. We focus on statistical techniques to extract both adjacent and window phrases from documents. We discover that the positive effect of adding phrase terms is very limited, if we have already achieved good performance using single-word terms, even when SVD/LSI is used as the dimensionality reduction method.
7D4AFEE4	International Conference on Data Mining	rong chen + k sivakumar	2002	A new algorithm for learning parameters of a Bayesian network from distributed data	collective learning + bayesian network + bandwidth + data security + data mining + directed acyclic graph + bayesian methods + learning artificial intelligence + probabilistic graph model + distributed databases + decision making + learning parameters + belief networks + learning (artificial intelligence) + distributed heterogeneous dataset + Bayesian network	AuthorProvided Keywords Not Found	We present a novel approach for learning parameters of a Bayesian network from distributed heterogeneous dataset. In this case, the whole dataset is distributed in several sites and each site contains observations for a different subset of features. The new method uses the collective learning approach proposed in our earlier work and substantially reduces the computational and transmission overhead. Theoretical analysis is given and experimental results are provided to illustrate the accuracy and efficiency of our method.
8035450F	International Conference on Data Mining	takuya wada + hiroshi motoda + takashi washio + tetsuya yoshida	2002	Adaptive ripple down rules method based on minimum description length principle	knowledge acquisition + switches + inductive learning methods + useless knowledge + encoding + adaptive ripple down rules method + knowledge deletion + knowledge based systems + minimum description length principle + class distribution + UCI repository + dynamically changing environment + computational modeling + search problems	AuthorProvided Keywords Not Found	When class distribution changes, some pieces of knowledge previously acquired become worthless, and the existence of such knowledge may hinder acquisition of new knowledge. The paper proposes an adaptive ripple down rules (RDR) method based on the minimum description length principle aiming at knowledge acquisition in a dynamically changing environment. To cope with the change of class distribution, knowledge deletion is carried out as well as knowledge acquisition so that useless knowledge is properly discarded. To cope with the change of the source of knowledge, RDR knowledge based systems can be constructed adaptively by acquiring knowledge from both domain experts and data. By incorporating inductive learning methods, knowledge acquisition can be carried out even when only either data or experts are available by switching the source of knowledge from domain experts to data and vice versa at any time of knowledge acquisition. Since experts need not be available all the time, it contributes to reducing the cost of personnel expenses. Experiments were conducted by simulating the change of the source of knowledge and the change of class distribution using the datasets in UCI repository. The results are encouraging.
7D6A10BE	International Conference on Data Mining	stephan vogel + bing zhao	2002	Adaptive parallel sentences mining from web bilingual news collection	sentence length models + web pages + adaptive approach + data mining + maximum likelihood estimation + machine translation modeling + lexicon-based models + computer science + Xinhua bilingual news collection + maximum likelihood + machine translation + parameter estimation + Web bilingual news collection + natural language processing + probability + information retrieval + robustness + dynamic programming + adaptive parallel sentences mining + mined parallel data + data collection + translation probability parameter estimation + vocabulary coverage + natural languages + maximum likelihood criterion + language translation	AuthorProvided Keywords Not Found	In this paper a robust, adaptive approach for mining parallel sentences from a bilingual comparable news collection is described Sentence length models and lexicon-based models are combined under a maximum likelihood criterion. Specific models are proposed to handle insertions and deletions that are frequent in bilingual data collected from the web. The proposed approach is adaptive, updating the translation lexicon iteratively using the mined parallel data to get better vocabulary coverage and translation probability parameter estimation. Experiments are carried out on 10 years of Xinhua bilingual news collection. Using the mined data, we get significant improvement in word-to-word alignment accuracy in machine translation modeling.
8104417E	International Conference on Data Mining	ken sadohara	2002	On a capacity control using Boolean kernels for the learning of Boolean functions	learning automata + projections + capacity control + boolean function + data mining + naive bayes classifier + Boolean literals + learning artificial intelligence + Boolean functions + Boolean function learning algorithm + engines + discrete attribute spaces + training data + hypothesis space + Boolean kernels + learning (artificial intelligence) + pattern classification + subspace + feature space + support vector machines + kernel + Boolean kernel classifier + space technology + empirical study + feature spaces + machine learning + aerospace industry + boolean functions + classification task + support vector machine	AuthorProvided Keywords Not Found	This paper concerns the classification task in discrete attribute spaces, but considers the task in a more fundamental framework: the learning of Boolean functions. The purpose of this paper is to present a new learning algorithm for Boolean functions called Boolean kernel classifier (BKC) employing capacity control using Boolean kernels. BKC uses support vector machines (SVMs) as learning engines and Boolean kernels are primarily used for running SVMs in feature spaces spanned by conjunctions of Boolean literals. However, another important role of Boolean kernels is to appropriately control the size of its hypothesis space, to avoid overfitting. After applying a SVM to learn a classifier f in a feature space H induced by a Boolean kernel, BKC uses another Boolean kernel to compute the projections fk of f onto a subspace Hk of H spanned by conjunctions with length at most k. By evaluating the accuracy of fk on training data for any k, BKC can determine the smallest k such that fk is as accurate as f and learn another f' in Hk expected to have lower error for unseen data. By an empirical study on learning of randomly generated Boolean functions, it is shown that the capacity control is effective, and BKC outperforms C4.5 and naive Bayes classifiers.
7EDF928A	International Conference on Data Mining	a waichee fu + e ka ka ng + ke wang	2002	Mining association rules from stars	association rule + entity sets + data mining + association rules + relational databases + join-then-mine approach + data engineering + distributed computing + star schema + association rule mining + relational data + computer science + association rules mining	AuthorProvided Keywords Not Found	Association rule mining is an important data mining problem. It is found to be useful for conventional relational data. However, previous work has mostly targeted on mining a single table. In real life, a database is typically made up of multiple tables and one important case is where some of the tables form a star schema. The tables typically correspond to entity sets and joining the tables in a star schema gives relationships among entity sets which can be very interesting information. Hence mining on the join result is an important problem. Based on characteristics of the star schema we propose an efficient algorithm for mining association rules on the join result but without actually performing the join operation. We show that this approach can significantly out-perform the join-then-mine approach even when the latter adopts a fastest known mining algorithm.
7D1B8D84	International Conference on Data Mining	jani mantyjarvi + john a flanagan + johan himberg	2002	Unsupervised clustering of symbol strings and context recognition	symbol string recognition + symbol string clustering map + weighted average + data mining + multidimensional systems + unsupervised clustering + information representation + mobile computing + hidden markov models + context recognition + online operation + pattern clustering + clustering algorithms + symbol manipulation + computationally simple similarity measure + data structures + string matching + statistical analysis + scm + SCM + computational complexity	AuthorProvided Keywords Not Found	The representation of information based on symbol strings has been applied to the recognition of context. A framework for approaching the context recognition problem has been described and interpreted in terms of symbol string recognition. The symbol string clustering map (SCM) is introduced as an efficient algorithm for the unsupervised clustering and recognition of symbol string data. The SCM can be implemented in an online manner using a computationally simple similarity measure based on a weighted average. It is shown how measured sensor data can be processed by the SCM algorithm to learn, represent and distinguish different user contexts without any user input.
7E308E9A	International Conference on Data Mining	honghua dai + tao luo + miki nakagawa + bamshad mobasher	2002	Using sequential and non-sequential patterns in predictive Web usage mining tasks	web personalization + search engines + pattern mining + data mining + Web recommender systems + Web prefetching + sequential pattern + scalability + association rule mining + web usage mining + navigation + recommender system + recommender systems + Web personalization systems + computer science + Web usage mining + collaboration + information systems + Web sites	AuthorProvided Keywords Not Found	We describe an efficient framework for Web personalization based on sequential and non-sequential pattern discovery from usage data. Our experimental results performed on real usage data indicate that more restrictive patterns, such as contiguous sequential patterns (e.g., frequent navigational paths) are more suitable for predictive tasks, such as Web prefetching, (which involve predicting which item is accessed next by a user), while less constrained patterns, such as frequent item sets or general sequential patterns are more effective alternatives in the context of Web personalization and recommender systems.
7D3AD2AA	International Conference on Data Mining	wai lam + taklam wong	2002	Adapting information extraction knowledge for unseen Web sites	web pages + information extraction knowledge + data mining + information retrieval + text categorization + learning artificial intelligence + information extraction + automation + unseen Web site + rule generalization + natural languages + Web sites + learning (artificial intelligence) + wrapper adaptation framework + extraction rules + lexicon	AuthorProvided Keywords Not Found	We propose a wrapper adaptation framework which aims at adapting a learned wrapper to an unseen Web site. It significantly reduces human effort in constructing wrappers. Our framework makes use of extraction rules previously discovered from a particular site to seek potential training example candidates for an unseen site. Rule generalization and text categorization are employed for finding suitable example candidates. Another feature of our approach is that it makes use of the previously discovered lexicon to classify good training examples automatically for the new site. We conducted extensive experiments to evaluate the quality of the extraction performance and the adaptability of our approach.
7FC37B96	International Conference on Data Mining	gabriel pui cheong fung + jeffrey xu yu + hongjun lu	2002	Discriminative category matching: efficient text classification for huge document collections	text analysis + discriminative category matching + pattern matching + support vector machines + data mining + document management + efficient text classification + document classification + concept-drift + government + technology management + computer science + concept drift + huge document collections + Internet + computational time + internet + computational complexity	AuthorProvided Keywords Not Found	With the rapid growth of textual information available on the Internet, having a good model for classifying and managing documents automatically is undoubtedly important. When more documents are archived, new terms, new concepts and concept-drift will frequently appear Without a doubt, updating the classification model frequently, rather than using the old model for a very long period is absolutely essential. Here, the challenges are: a) obtain a high accuracy classification model; b) consume low computational time for both model training and operation; and c) occupy low storage space. However, none of the existing classification approaches could achieve all of these requirements. In this paper, we propose a novel text classification approach, called discriminative category matching, which could achieve all of the stated characteristics. Extensive experiments using two benchmarks and a large real-life collection are conducted. The encouraging results indicated that our approach is highly feasible.
7D6D8323	International Conference on Data Mining	r florezlopez	2002	Reviewing RELIEF and its extensions: a new approach for estimating attributes considering high-correlated features	pattern analysis + algorithm design and analysis + data mining + linear regression + knowledge discovery + learning + machine learning + learning artificial intelligence + probability distribution + RELIEF algorithm + attributes + classification problems + statistical analysis + learning (artificial intelligence) + pattern recognition	AuthorProvided Keywords Not Found	RELIEF algorithm and its extensions are some of the most known filter methods for estimating the quality of attributes in classification problems dealing with both dependent and independent features. These methods attend to find all meaningful features for each problem (both weakly and strongly ones) so they are usually employed like a first stage for detecting irrelevant attributes. Nevertheless, in this paper we checked that RELIEF-family algorithms present some important limitations that could distort the selection of the final features' subset, specially in the presence of high-correlated attributes. To overcome these difficulties, a new approach has been developed (WACSA algorithm), which performance and validity are verified on wellknown data sets.
7E793037	International Conference on Data Mining	milo kovacevic + veljko m milutinovic + marco gori + michelangelo diligenti	2002	Recognition of common areas in a Web page using visual information: a possible application in a page classification	search engines + web pages + search engine + bag of words + data mining + information retrieval + experiments + HTML + classification + machine learning + naive bayes classifier + frequency + browser screen coordinates + heuristics + hierarchical representation + civil engineering + Web page common area recognition + html + page classification + Web sites + Naive Bayes classifier + hypermedia markup languages + visual information	AuthorProvided Keywords Not Found	"Extracting and processing information from Web pages is an important task in many areas like constructing search engines, information retrieval, and data mining from the Web. A common approach in the extraction process is to represent a page as a ""bag of words"" and then to perform additional processing on such a flat representation. We propose a new, hierarchical representation that includes browser screen coordinates for every HTML object in a page. Using visual information one is able to define heuristics for the recognition of common page areas such as header, left and right menu, footer and center of a page. We show in initial experiments that using our heuristics defined objects are recognized properly in 73% of cases. Finally, we show that a Naive Bayes classifier, taking into account the proposed representation, clearly outperforms the same classifier using only information about the content of documents."
7E7FC7DA	International Conference on Data Mining	mariechristine rousset + michkle sebag + alexandre termier	2002	TreeFinder: a first step towards XML data mining	concrete + XML data mining + data model + complexity + perturbed copies + tree structure + data mining + TreeFinder algorithm + robustness + labelled trees + completeness + data models + artificial medium size datasets + xml + frequent tree searching + tree data structures + exactor copies + tree-structured data + computational complexity + hypermedia markup languages	AuthorProvided Keywords Not Found	In this paper we consider the problem of searching frequent trees from a collection of tree-structured data modeling XML data. The TreeFinder algorithm aims at finding trees, such that their exact or perturbed copies are frequent in a collection of labelled trees. To cope with complexity issues, TreeFinder is correct but not complete: it finds a subset of actually frequent trees. The default of completeness is experimentally investigated on artificial medium size datasets; it is shown that TreeFinder reaches completeness or falls short for a range of experimental settings.
81561E9B	International Conference on Data Mining	k s leung + s y lee + man leung wong	2002	A hybrid approach to discover Bayesian networks from databases using evolutionary programming	bayesian network + dependency analysis + hybrid algorithm + data mining + knowledge discovery + bayesian methods + learning artificial intelligence + computer science + network learning problem + information systems + search efficiency + belief networks + learning (artificial intelligence) + search phases + MDLEP + search problems + bayesian networks + hybrid approach + databases + genetic programming + evolutionary programming + data analysis + algorithm design and analysis + direct marketing + testing + conditional independence test + evolutionary computation + marketing + knowledge representation + dependence analysis + Bayesian networks	AuthorProvided Keywords Not Found	Describes a data mining approach that employs evolutionary programming to discover knowledge represented in Bayesian networks. There are two different approaches to the network learning problem. The first one uses dependency analysis, while the second one searches good network structures according to a metric. Unfortunately, both approaches have their own drawbacks. Thus, we propose a hybrid algorithm of the two approaches, which consists of two phases, namely, the conditional independence test and the search phases. A new operator is introduced to further enhance the search efficiency. We conduct a number of experiments and compare the hybrid algorithm with our previous algorithm, MDLEP, which uses EP for network learning. The empirical results illustrate that the new approach has better performance. We apply the approach to data sets of direct marketing and compare the performance of the evolved Bayesian networks obtained by the new algorithm with the models generated by other methods. In the comparison, the induced Bayesian networks produced by the new algorithm outperform the other models.
80125033	International Conference on Data Mining	yiqing tu + gang li + honghua dai	2002	Linear Causal Model discovery using the MML criterion	MML criterion + data analysis + Linear Causal Model discovery + information technology + data mining + large database + directed acyclic graph + linear relation discovery + knowledge discovery + database theory + directed graphs + very large databases + graphical models + data sets + energy management + parameter estimation + causal models + software performance evaluation + statistics + database systems	AuthorProvided Keywords Not Found	Determining the causal structure of a domain is a key task in the area of data mining and knowledge discovery. The algorithm proposed by Wallace et al. (1996) has demonstrated its strong ability in discovering Linear Causal Models from given data sets. However some experiments showed that this algorithm experienced difficulty in discovering linear relations with small deviation, and it occasionally gives a negative message length, which should not be allowed. In this paper a more efficient and precise MML encoding scheme is proposed to describe the model structure and the nodes in a Linear Causal Model. The estimation of different parameters is also derived. Empirical results show that the new algorithm outperformed the previous MML-based algorithm in terms of both speed and precision.
7F32214A	International Conference on Data Mining	elena baralis + paolo garza	2002	A lazy approach to pruning classification rules	databases + pruning + pattern classification + lazy pruning + data mining + testing + association rules + machine learning + learning artificial intelligence + rule based + associative processing + association rule discovery + associative classification + decision trees + training data + classifiers + rule base + learning (artificial intelligence) + finance	AuthorProvided Keywords Not Found	Associative classification is a promising technique for the generation of highly precise classifiers. Previous works propose several clever techniques to prune the huge set of generated rules, with the twofold aim of selecting a small set of high quality rules, and reducing the chance of overfitting. In this paper, we argue that pruning should be reduced to a minimum and that the availability of a large rule base may improve the precision of the classifier without affecting its performance. In L3 (Live and Let Live), a new algorithm for associative classification, a lazy pruning technique iteratively discards all rules that only yield wrong case classifications. Classification is performed in two steps. Initially, rules which have already correctly classified at least one training case, sorted by confidence, are considered If the case is still unclassified, the remaining rules (unused during the training phase) are considered, again sorted by confidence. Extensive experiments on 26 databases from the UCI machine learning database repository show that L3 improves the classification precision with respect to previous approaches.
7E148717	International Conference on Data Mining	ricco rakotomalala + fabrice muhlenbach	2002	Multivariate supervised discretization, a neighborhood graph approach	supervised learning + data mining + polythetic behavior + neighborhood graph construction + gaussian distribution + machine learning + HyperCluster Finder + artificial intelligence + learning artificial intelligence + learning database + clustering algorithms + multivariate supervised discretization + supervised behavior + learning (artificial intelligence) + XOR problem	AuthorProvided Keywords Not Found	We present a new discretization method in the context of supervised learning. This method entitled HyperCluster Finder is characterized by its supervised and polythetic behavior. The method is based on the notion of clusters and processes in two steps. First, a neighborhood graph construction from the learning database allows discovering homogenous clusters. Second, the minimal and maximal values of each cluster are transferred to each dimension in order to define some boundaries to cut the continuous attribute in a set of intervals. The discretization abilities of this method are illustrated by some examples, in particular processing the XOR problem.
7E0139BB	International Conference on Data Mining	sheng ma + changshing perng + philip s yu + haixun wang	2002	Mining associations by pattern structure in large relational tables	algorithm design and analysis + data security + data mining + patterns discovery + association rules + management system + history + large relational tables + relational databases + mining space + association rule mining + authorization + execution times + structural information + attribute + event management systems + pattern structure + zinc + search problems	AuthorProvided Keywords Not Found	Association rule mining aims at discovering patterns whose support is beyond a given threshold. Mining patterns composed of items described by an arbitrary subset of attributes in a large relational table represents a new challenge and has various practical applications, including the event management systems that motivated this work. The attribute combinations that define the items in a pattern provide the structural information of the pattern. Current association algorithms do not make full use of the structural information of the patterns: the information is either lost after it is encoded with attribute values, or is constrained by a given hierarchy or taxonomy. Pattern structures convey important knowledge about the patterns. We present an architecture that organizes the mining space based on pattern structures. By exploiting the interrelationships among pattern structures, execution times for mining can be reduced significantly. This advantage is demonstrated by our experiments using both synthetic and real-life datasets.
80C819B0	International Conference on Data Mining	sigal sahar	2002	Exploring interestingness through clustering: a framework	association rule clustering + association rule + ancestor coverage + cluster representation + pattern clustering + interestingness + data mining + labeling + association rules + knowledge discovery	AuthorProvided Keywords Not Found	Determining interestingness is a notoriously difficult problem: it is subjective and elusive to capture. It is also becoming an increasingly more important problem in knowledge discovery from database as the number of mined patterns increases. In this work we introduce and investigate a framework for association rule clustering that enables automating much of the laborious manual effort normally involved in the exploration and understanding of interestingness. Clustering is ideally suited for this task; it is the unsupervised organization of patterns into groups, so that patterns in the same group are more similar to each other than to patterns in other groups. We also define a data-driven inferred labeling of these clusters, the ancestor coverage, which provides an intuitive, concise representation of the clusters.
8034CDA7	International Conference on Data Mining	joseph l hellerstein + sheng ma + haixun wang + changshing perng	2002	User-directed exploration of mining space with multiple attributes	transaction processing + domain knowledge + production + data mining + multiple attributes + user preferences + user-directed mining space exploration + taxonomy + semantics + complex networks + functional dependencies + combinatorial complexity + data grouping + exponentially growing mining space reduction + data labelling + pattern analysis + unsupervised unrestricted mining + space exploration + functional dependency + relational databases + transactions + frequent itemset mining + relational data + data schema + grouped data + taxonomies + user directed data mining framework + computational complexity	AuthorProvided Keywords Not Found	There has been a growing interest in mining frequent itemsets in relational data with multiple attributes. A key step in this approach is to select a set of attributes that group data into transactions and a separate set of attributes that labels data into items. Unsupervised and unrestricted mining, however is stymied by the combinatorial complexity and the quantity of patterns as the number of attributes grows. In this paper we focus on leveraging the semantics of the underlying data for mining frequent itemsets. For instance, there are usually taxonomies in the data schema and functional dependencies among the attributes. Domain knowledge and user preferences often have the potential to significantly reduce the exponentially growing mining space. These observations motivate the design of a user-directed data mining framework that allows such domain knowledge to guide the mining process and control the mining strategy. We show examples of tremendous reduction in computation by using domain knowledge in mining relational data with multiple attributes.
7E983774	International Conference on Data Mining	marcos m campos + boriana l milenova	2002	O-Cluster: scalable clustering of large high dimensional data sets	complexity + active sampling technique + sampling methods + shape + curse of dimensionality + data mining + information retrieval + large high dimensional data sets + axis-parallel partitioning strategy + multidimensional systems + scalability + high dimensional data + pattern clustering + clustering algorithms + very large databases + scalable clustering + sampling technique + limited memory buffer + O-Cluster + data handling + multidimensional data sets + computational complexity	AuthorProvided Keywords Not Found	"Clustering large data sets of high dimensionality has always been a challenge for clustering algorithms. Many recently developed clustering algorithms have attempted to address either handling data sets with a very large number of records and/or with a very high number of dimensions. We provide a discussion of the advantages and limitations of existing algorithms when they operate on very large multidimensional data sets. To simultaneously overcome both the ""curse of dimensionality"" and the scalability problems associated with large amounts of data, we propose a new clustering algorithm called O-Cluster. O-Cluster combines a novel active sampling technique with an axis-parallel partitioning strategy to identify continuous areas of high density in the input space. The method operates on a limited memory buffer and requires at most a single scan through the data. We demonstrate the high quality of the obtained clustering solutions, their robustness to noise, and O-Cluster's excellent scalability."
7EE641B8	International Conference on Data Mining	chengyue chang + mingsyan chen + changhung lee	2002	Mining general temporal association rules for items with different exhibition periods	association rule + exhibition periods + cumulant + very large databases + data mining + Segmented Progressive Filter + temporal association rules + association rules + filtering + large databases + scalability	AuthorProvided Keywords Not Found	In this paper we explore a new model of mining general temporal association rules from large databases where the exhibition periods of the items are allowed to be different from one to another. Note that in this new model, the downward closure property which all prior Apriori-based algorithms relied upon to attain good efficiency is no longer valid. As a result, how to efficiently generate candidate itemsets form large databases has become the major challenge. To address this issue, we develop an efficient algorithm, referred to as algorithm SPF (standing for Segmented Progressive Filter) in this paper The basic idea behind SPF is to first segment the database into sub-databases in such a way that items in each sub-database will have either the common starting time or the common ending time. Then, for each sub-database, SPF progressively filters candidate 2-itemsets with cumulative filtering thresholds either forward or backward in time. This feature allows SPF of adopting the scan reduction technique by generating all candidate k-itemsets (k>2) from candidate 2-itemsets directly. The experimental results show that algorithm SPF significantly outperforms other schemes which are extended from prior methods in terms of the execution time and scalability.
7D8C13F4	International Conference on Data Mining	fangfei kuo + mankwan shan	2002	A personalized music filtering system based on melody style classification	personalized music filtering system + data mining + digital music + performance evaluation + melody style classification + content-based filtering system + learning + user interfaces + classification + content-based retrieval + navigation + learning artificial intelligence + recommender systems + music + multiple signal classification + computer science + feature extraction + music recommendation + collaboration + digital filters + user preference + two-way melody preference classifier + learning (artificial intelligence)	AuthorProvided Keywords Not Found	With the growth of digital music, the personalized music filtering system is helpful for users. Melody style is one of the music features to represent user's music preference. We present a personalized content-based music filtering system to support music recommendation based on user's preference of melody style. We propose the multitype melody style classification approach to recommend the music objects. The system learns the user preference by mining the melody patterns from the music access behavior of the user. A two-way melody preference classifier is therefore constructed for each user. Music recommendation is made through this melody preference classifier. Performance evaluation shows that the filtering effect of the proposed approach meets user's preference.
7EA433B8	International Conference on Data Mining	mingsyan chen + weiguang teng + mingjyh hsieh	2002	On the mining of substitution rules for statistically dependent items	concrete + statistical significance + data mining + customer purchase + association rules + empirical study + statistically dependent items + taxonomy + substitution rule mining + substitution rule generation + concrete itemsets + algorithm performance evaluation + retail data processing + frequent itemsets	AuthorProvided Keywords Not Found	In this paper a new mining capability, called mining of substitution rules, is explored. A substitution refers to the choice made by a customer to replace the purchase of items with that of others. The process of mining substitution rules can be decomposed into two procedures. The first identifies concrete itemsets among a large number of frequent itemsets, where a concrete itemset is a frequent itemset whose items are statistically dependent. The second is substitution rule generation. Two concrete itemsets X and Y form a substitution rule, denoted by X ▵ Y to mean that X is a substitute for Y if and only if X and Y are negatively correlated and the negative association rule X → Y~ exists. We derive theoretical properties for the model of substitution rule mining. Then, in light of these properties, the SRM algorithm (substitution rule mining) is designed and implemented to discover substitution rules efficiently while attaining good statistical significance. Empirical studies are performed to evaluate the performance of the SRM algorithm. It is shown that SRM produces substitution rules of very high quality.
7F73EC69	International Conference on Data Mining	ljupco todorovski + peter a flach + branko kavsek + nada lavrac	2002	Adapting classification rule induction to subgroup discovery	CN2-SD + covering algorithm + data mining + association rules + experimental evaluation + learning artificial intelligence + java + heuristic programming + very large databases + rule coverage + ROC curve + learning (artificial intelligence) + search problems + subgroup discovery + databases + pattern classification + UCI data sets + classification rule induction + rule learning + algorithm design and analysis + probability + prediction tasks + machine learning + probabilistic classification + search heuristic + roc curve	AuthorProvided Keywords Not Found	Rule learning is typically used for solving classification and prediction tasks. However learning of classification rules can be adapted also to subgroup discovery. This paper shows how this can be achieved by modifying the covering algorithm and the search heuristic, performing probabilistic classification of instances, and using an appropriate measure for evaluating the results of subgroup discovery. Experimental evaluation of the CN2-SD subgroup discovery algorithm on 17 UCI data sets demonstrates substantial reduction of the number of induced rules, increased rule coverage and rule significance, as well as slight improvements in terms of the area under the ROC curve.
6C2C6798	International Conference on Data Mining	hasan jamil	2002	Implementation of a least fixpoint operator for fast mining of relational databases	database languages + data analysis + SQL3 + large item set generation + object-oriented databases + data mining + object oriented database + association rules + relational databases + sql + association rule mining + SQL + least fixpoint operator + query processing + computer science + experiment + optimization + very large databases + engines + ad hoc querying + aggregate functions + object-relational databases + recursive constructs	AuthorProvided Keywords Not Found	Recent research has focused on computing large item sets for association rule mining using SQL3 least fixpoint computation, and by exploiting the monotonic nature of the SQL3 aggregate functions such as sum and create view recursive constructs. Such approaches allow us to view mining as an ad hoc querying exercise and treat the efficiency issue as an optimization problem. We present a recursive implementation of a recently proposed least fixpoint operator for computing large item sets from object-relational databases. We present experimental evidence to show that our implementation compares well with several well-regarded and contemporary algorithms for large item set generation.
80628131	International Conference on Data Mining	chingyao wang + tzungpei hong + shimshyong tseng	2002	Maintenance of sequential patterns for record modification using pre-large sequences	databases + records management + record modification + computation time + very large databases + data mining + rescanning + sequential pattern maintenance + sequences + pre-large sequences + modified customer sequences	AuthorProvided Keywords Not Found	In previous work we proposed incremental mining algorithms for maintenance of sequential patterns based on the concept of pre-large sequences as records were inserted or deleted. Although maintenance of sequential patterns for record modification can be performed by using the deletion procedure and then the insertion procedure, double the computation time of a single procedure is needed. In this paper, we attempt to apply the concept of pre-large sequences to maintain sequential patterns as records are modified. The proposed algorithm does not require rescanning original databases until the accumulative number of modified customer sequences exceeds a safety bound derived by a pre-large concept. As databases grow larger, the number of modified customer sequences allowed before database rescanning also needs to grow.
80B893CA	International Conference on Data Mining	tatsuya asai + hiroki arimura + setsuo arikawa + shinji kawasoe + kenji abe	2002	Online algorithms for mining semi-structured data stream	pattern analysis + data model + web pages + incremental maintenance + online data mining + algorithm design and analysis + data mining + online algorithm + informatics + tree sweeping technique + technology management + xml + StreamT + semi-structured data + data structures + XML data + frequent pattern discovery + semi structured data + pattern recognition + hypermedia markup languages	AuthorProvided Keywords Not Found	In this paper, we study an online data mining problem from streams of semi-structured data such as XML data. Modeling semi-structured data and patterns as labeled ordered trees, we present an online algorithm StreamT that receives fragments of an unseen possibly infinite semi-structured data in the document order through a data stream, and can return the current set of frequent patterns immediately on request at any time. A crucial part of our algorithm is the incremental maintenance of the occurrences of possibly frequent patterns using a tree sweeping technique. We give modifications of the algorithm to other online mining model. We present theoretical and empirical analyses to evaluate the performance of the algorithm.
7EF92A0B	International Conference on Data Mining	christian bohm + florian krebs	2002	High performance data mining using the nearest neighbor join	databases + similarity search + data analysis + data mining + indexation + multipage index + multidimensional systems + multidimensional databases + database theory + data cleansing + query processing + acceleration + biomedical informatics + similarity join + nearest neighbor + k nearest neighbor + clustering algorithms + cost function + database primitive + k means	AuthorProvided Keywords Not Found	The similarity join has become an important database primitive to support similarity search and data mining. A similarity join combines two sets of complex objects such that the result contains all pairs of similar objects. Well-known are two types of the similarity join, the distance range join where the user defines a distance threshold for the join, and the closest point query or k-distance join which retrieves the k most similar pairs. In this paper, we investigate an important, third similarity join operation called k-nearest neighbor join which combines each point Of one point set with its k nearest neighbors in the other set. It has been shown that many standard algorithms of Knowledge Discovery in Databases (KDD) such as k-means and k-medoid clustering, nearest neighbor classification, data cleansing, postprocessing of sampling-based data mining etc. can be implemented on top of the k-nn join operation to achieve performance improvements without affecting the quality of the result of these algorithms. We propose a new algorithm to compute the k-nearest neighbor join using the multipage index (MuX), a specialized index structure for the similarity join. To reduce both CPU and I/O cost, we develop optimal loading and processing strategies.
7EB07208	International Conference on Data Mining	sigal sahar	2002	On incorporating subjective interestingness into the mining process	databases + domain knowledge + association rule + pattern classification + ancestor item set classification + association rule discovery + subjective interestingness + data mining + association rules + zirconium + database management systems + heart	AuthorProvided Keywords Not Found	Subjective interestingness is at the heart of the successful discovery of association rules. To determine what is subjectively interesting, users' domain knowledge must be applied. The author (1999) introduced an approach that requires very little domain knowledge and interaction to eliminate the majority of the rules that are subjectively not interesting. In this paper we investigate how this approach can be incorporated into the mining process, the benefits and disadvantages of doing so, and examine the results of its application to real databases.
815C3E5D	International Conference on Data Mining	geoffrey i webb + zhihai wang	2002	Comparison of lazy Bayesian rule, and tree-augmented Bayesian learning	bayesian network + pattern classification + bayesian learning + information technology + lazy Bayesian rule + probability + data mining + accuracy + Weka system + machine learning + naive bayes classifier + tree-augmented Bayesian learning + bayesian methods + learning artificial intelligence + naive Bayes classifier + decision trees + belief networks + learning (artificial intelligence) + prediction accuracy + Bayesian network	AuthorProvided Keywords Not Found	The naive Bayes classifier is widely used in interactive applications due to its computational efficiency, direct theoretical base, and competitive accuracy. However its attribute independence assumption can result in sub-optimal accuracy. A number of techniques have explored simple relaxations of the attribute independence assumption in order to increase accuracy. Among these, the lazy Bayesian rule (LBR) and the tree-augmented naive Bayes (TAN) have demonstrated strong prediction accuracy. However their relative performance has never been evaluated. The paper compares and contrasts these two techniques, finding that they have comparable accuracy and hence should be selected according to computational profile. LBR is desirable when small numbers of objects are to be classified while TAN is desirable when large numbers of objects are to be classified.
747A62F2	International Conference on Data Mining	qi li + chandra kambhamettu + shenghuo zhu + tao li	2002	Improving medical/biological data classification performance by wavelet preprocessing	classification algorithms + pattern classification + noise measurement + wavelet transforms + biological data + learning algorithms + data mining + wavelet denoising + wavelet preprocessing + datasets + minimax techniques + learning artificial intelligence + decision tree + medical data + data classification + noise + noise reduction + biomedical imaging + learning (artificial intelligence) + minimax threshold + medical computing	AuthorProvided Keywords Not Found	Many real-world datasets contain noise which could degrade the performances of learning algorithms. Motivated from the success of wavelet denoising techniques in image data, we explore a general solution to alleviate the effect of noisy data by wavelet preprocessing for medical/biological data classification. Our experiments are divided into two categories: one is of different classification algorithms on a specific database, and the other is of a specific classification algorithm (decision tree) on different databases. The experiment results show that the wavelet denoising of noisy data is able to improve the accuracies of those classification methods, if the localities of the attributes are strong enough.
7F46C034	International Conference on Data Mining	jie cheng + qiang yang + tielin chen + charles x ling	2002	Mining optimal actions for profitable CRM	profitability + computer science + business + technology management + data mining + cost function + data mining tools + optimal actions mining + customer relations + customer relationship management + Proactive Solution	AuthorProvided Keywords Not Found	Data mining has been applied to CRM (Customer Relationship Management) in many industries with a limited success. Most data mining tools can only discover customer models or profiles (such as customers who are likely attritors and customers who are loyal), but not actions that would improve customer relationship (such as changing attritors to loyal customers). We describe a novel algorithm that suggests actions to change customers from an undesired status (such as attritors) to a desired one (such as loyal). Our algorithm takes into account the cost of actions, and further it attempts to maximize the expected net profit. To our best knowledge, no data mining algorithms or tools today can accomplish this important task in CRM. The algorithm is implemented, with many advanced features, in a specialized and highly effective data mining software called Proactive Solution.
7E39EF0D	International Conference on Data Mining	ayhan demiriz	2002	webSPADE: a parallel sequence mining algorithm to analyze web log data	data warehouse + front end + webSPADE + data analysis + information technology + web mining + algorithm design and analysis + appropriate technology + data mining + web-based front-end + e commerce + relational databases + frequency + parallel sequence mining algorithm + raw web logs + enterprise-class web sites + service oriented architecture + data visualization + Web sites + data warehouses + sequence mining + Web log data	AuthorProvided Keywords Not Found	Enterprise-class web sites receive a large amount of traffic, from both registered and anonymous users. Data warehouses are built to store and help analyze the click streams within this traffic to provide companies with valuable insights into the behavior of their customers. This article proposes a parallel sequence mining algorithm, webSPADE, to analyze the click streams found in site web logs. In this process, raw web logs are first cleaned and inserted into a data warehouse. The click streams are then mined by webSPADE. An innovative web-based front-end is used to visualize and query the sequence mining results. The webSPADE algorithm is currently used by Verizon to analyze the daily traffic of the Verizon.com web site.
7E9084E4	International Conference on Data Mining	kwongsak leung + wingho shum + huidong jin + manleung wong	2002	A self-organizing map with expanding force for data clustering and visualization	expanding self-organizing map + quantization error + data analysis + exploratory phase + data mining + space exploration + data clustering + topology correspondence + network topology + data engineering + quantization errors + topological errors + expanding force + computer science + pattern clustering + self-organising feature maps + dimensional conflict + data visualisation + topology preservation + data visualization + information systems + quantization	AuthorProvided Keywords Not Found	The self-organizing map (SOM) is a powerful tool in the exploratory phase of data mining. However, due to the dimensional conflict, neighborhood preservation cannot always lead to perfect topology preservation. In this paper we establish an expanding SOM (ESOM) to detect and preserve better topology correspondence between the two spaces. Our experiment results demonstrate that the ESOM constructs better mappings than the classic SOM in terms of both topological and quantization errors. Furthermore, clustering results generated by the ESOM are more accurate than those of the SOM.
80213671	International Conference on Data Mining	rengang yang + philip s yu + wen wang	2002	InfoMiner+: mining partial periodic patterns with gap penalties	information gain + InfoMinergap penalties + data mining + association rules + time series + pattern occurrences + sequences + DNA sequence repeat location + frequency + scattering + biology computing + partial periodic pattern mining + dna + time measurement + DNA + generalized information gain + information gain measure + random replacement + subsequences + imperfection	AuthorProvided Keywords Not Found	In this paper we focus on mining periodic patterns allowing some degree of imperfection in the form of random replacement from a perfect periodic pattern. Information gain was proposed to identify patterns with events of vastly different occurrence frequencies and adjust for deviation from a pattern. However, it does not involve a penalty if there exists some gap between pattern occurrences. In many applications, e.g., bioinformatics, it is important to identify subsequences that a pattern repeats perfectly (or near perfectly). As a solution, we extend the information gain measure to include a penalty for gaps between pattern occurrences. We call this measure generalized information gain. Furthermore, we need to find a subsequence S' such that for a pattern P, the generalized information gain of P in S' is high. This is particularly useful in locating repeats in DNA sequences. In this paper, we developed an effective mining algorithm, InfoMiner+, to simultaneously mine significant patterns and associated subsequences.
8116D882	International Conference on Data Mining	yabo xu + jeffrey xu yu + guimei liu + hongjun lu	2002	From path tree to frequent patterns: a framework for mining frequent patterns	transaction processing + depth-first frequent pattern discovery algorithm + data mining + trees (mathematics) + large transactional databases + data structure + coded prefix-path tree + set theory + frequent patterns mining + loading algorithms + memory-based prefix-path tree + PP-Mine + assembly + data structures + tree data structures + disk-based prefix-path tree	AuthorProvided Keywords Not Found	We propose a framework for mining frequent patterns from large transactional databases. The core of the framework is a coded prefix-path tree with two representations, namely, a memory-based prefix-path tree and a disk-based prefix-path tree. The disk-based prefix-path tree is simple in its data structure yet rich in information contained, and is small in size. The memory-based prefix-path tree is simple and compact. Based on the memory-based prefix-path tree, a new depth-first frequent pattern discovery algorithm, called PP-Mine, is proposed that outperforms FP-growth significantly. The memory-based prefix-path tree can be stored on disk using a disk-based prefix-path tree with assistance of the new coding scheme. We present loading algorithms to load the minimal required disk-based prefix-path tree into main memory. Our technique is to push constraints into the loading process, which has not been well studied yet.
706D6A05	International Conference on Data Mining	mohamed s kamel + khaled m hammouda	2002	Phrase-based document similarity based on an index graph model	data model + text analysis + system analysis and design + indexing + web mining + data mining + functional analysis + vector space model + document clustering + document structure capture + indexation + document data set + data engineering + phrase representation + data models + phrase-based document similarity + single term weights + document clustering techniques + directed graphs + matching phrases weights + single term analysis + Web documents + Web sites + document index graph	AuthorProvided Keywords Not Found	Document clustering techniques mostly rely on single term analysis of the document data set, such as the vector space model. To better capture the structure of documents, the underlying data model should be able to represent the phrases in the document as well as single terms. We present a novel data model, the document index graph, which indexes web documents based on phrases, rather than single terms only. The semi-structured web documents help in identifying potential phrases that when matched with other documents indicate strong similarity between the documents. The document index graph captures this information, and finding significant matching phrases between documents becomes easy and efficient with such model. The similarity between documents is based on both single term weights and matching phrases weights. The combined similarities are used with standard document clustering techniques to test their effect on the clustering quality. Experimental results show that our phrase-based similarity, combined with single-term similarity measures, enhances web document clustering quality significantly.
62CE4CA6	International Conference on Data Mining	zhongfei zhang	2002	Mining surveillance video for independent motion detection	databases + data mining + compressed surveillance video + information retrieval + surveillance video mining + automatic independent motion detection + homeland defense + image motion analysis + layout + linear system + video compression + linear system consistency analysis + independent motion detection + real time + real-time mining performance	AuthorProvided Keywords Not Found	This paper addresses the special applications of data mining techniques in homeland defense. The problem targeted, which is frequently encountered in military/intelligence surveillance, is to mine a massive surveillance video database automatically collected to retrieve the shots containing independently moving targets. A novel solution to this problem is presented in this paper, which offers a completely qualitative approach to solving for the automatic independent motion detection problem directly from the compressed surveillance video in a faster than real-time mining performance. This approach is based on the linear system consistency analysis, and consequently is called QLS. Since the QLS approach only focuses on what exactly is necessary to compute a solution, it saves the computation to a minimum and achieves the efficacy to the maximum. Evaluations from real data show that QLS delivers effective mining performance at the achieved efficiency.
80BE25AD	International Conference on Data Mining	xiaofeng he + chris ding	2002	Cluster merging and splitting in hierarchical clustering algorithms	binary trees + agglomerative clustering + selection methods + merging + couplings + cluster merging + cluster splitting + testing + cluster balance + minmax linkage + helium + objective function saturation + pattern clustering + clustering algorithms + hierarchical clustering algorithms + clustering target distance + hierarchical clustering + divisive clustering	AuthorProvided Keywords Not Found	Hierarchical clustering constructs a hierarchy of clusters by either repeatedly merging two smaller clusters into a larger one or splitting a larger cluster into smaller ones. The crucial step is how to best select the next cluster(s) to split or merge. We provide a comprehensive analysis of selection methods and propose several new methods. We perform extensive clustering experiments to test 8 selection methods, and find that the average similarity is the best method in divisive clustering and the minmax linkage is the best in agglomerative clustering. Cluster balance is a key factor to achieve good performance. We also introduce the concept of objective function saturation and clustering target distance to effectively assess the quality of clustering.
80624035	International Conference on Data Mining	huan liu + manoranjan dash + peter scheuermann + kiseok choi	2002	Feature selection for clustering - a filter solution	entropy measure + histograms + data mining + degradation + dimensionality reduction technique + noisy feature removal + filter method + unsupervised learning + knowledge discovery in databases + entropy + pattern clustering + pre-processing method + feature extraction + clustering algorithms + noise reduction + clustering + point-to-point distance histogram + feature selection + point to point	AuthorProvided Keywords Not Found	Processing applications with a large number of dimensions has been a challenge for the KDD community. Feature selection, an effective dimensionality reduction technique, is an essential pre-processing method to remove noisy features. In the literature only a few methods have been proposed for feature selection for clustering, and almost all these methods are 'wrapper' techniques that require a clustering algorithm to evaluate candidate feature subsets. The wrapper approach is largely unsuitable in real-world applications due to its heavy reliance on clustering algorithms that require parameters such as the number of clusters, and the lack of suitable clustering criteria to evaluate clustering in different subspaces. In this paper we propose a 'filter' method that is independent of any clustering algorithm. The proposed method is based on the observation that data with clusters has a very different point-to-point distance histogram to that of data without clusters. By exploiting this we propose an entropy measure that is low if data has distinct clusters and high if it does not. The entropy measure is suitable for selecting the most important subset of features because it is invariant with the number of dimensions, and is affected only by the quality of clustering. Extensive performance evaluation over synthetic, benchmark, and real datasets shows its effectiveness.
7E529E9E	International Conference on Data Mining	jian pei + jiawei han + wei zou + guozhu dong	2002	On computing condensed frequent pattern bases	pattern analysis + pattern compression + data mining + condensed frequent pattern bases computing + information analysis + database management systems + large databases + pattern recognition + frequent pattern mining	AuthorProvided Keywords Not Found	Frequent pattern mining has been studied extensively. However, the effectiveness and efficiency of this mining is often limited, since the number of frequent patterns generated is often too large. In many applications it is sufficient to generate and examine only frequent patterns with support frequency in close-enough approximation instead of in full precision. Such a compact but close-enough frequent pattern base is called a condensed frequent patterns-base. In this paper we propose and examine several alternatives at the design, representation, and implementation of such condensed frequent pattern-bases. A few algorithms for computing such pattern-bases are proposed. Their effectiveness at pattern compression and their efficient computation methods are investigated. A systematic performance study is conducted on different kinds of databases, which demonstrates the effectiveness and efficiency of our approach at handling frequent pattern mining in large databases.
7EBD8088	International Conference on Data Mining	denis clot	2002	Using functional PCA for cardiac motion exploration	biomedical MRI + multifunctional data + karhunen loeve + MRI + graphics + variability + space charge + functional data + multivariate data analysis + hilbert space + medical image processing + image processing + meteorology + mri + random variables + information analysis + continuous functions + bounded domain + cardiac motion analysis + cardiology + image motion analysis + Karhunen-Loeve decomposition + curves + thyristors + functional principal component analysis + principal component analysis + symmetric matrices	AuthorProvided Keywords Not Found	Principal component analysis (PCA) is a major tool in multivariate data analysis. Its paradigms are also used in Karhunen-Loeve decomposition, a standard tool in image processing. Extensions of PCA to the framework of functional data have been proposed. The analysis provided by functional PCA seems to be a powerful tool for finding principal sources of variability in curves or images, but fails to provide easy interpretations in the case of multifunctional data. Guidelines aiming at spot information from the outputs of PCA applied to functionals with values in the space of continuous functions upon a bounded domain are proposed. An application to cardiac motion analysis illustrates the complexity of the multifunctional framework and the results provided by functional PCA.
80B0FC58	International Conference on Data Mining	ben choi + xiaogang peng	2002	Automatic web page classification in a dynamic and hierarchical way	classification algorithms + web pages + tree structure + information retrieval + dynamic-category expansion technique + frequency + learning artificial intelligence + computer science + automatic web page classification + satisfiability + Internet + learning (artificial intelligence) + internet	AuthorProvided Keywords Not Found	Automatic classification of web pages is an effective way to deal with the difficulty of retrieving information from the Internet. Although there are many automatic classification algorithms and systems that have been proposed, most of them ignore the conflict between the fixed number of categories and the growing number of web pages going into the system. They also require searching through all existing categories to make any classification. We propose a dynamic and hierarchical classification system that is capable of adding new categories as required, organizing the web pages into a tree structure, and classifying web pages by searching through only one path of the tree structure. Our test results show that our proposed single-path search technique reduces the search complexity and increases the accuracy by 6% comparing to related algorithms. Our dynamic-category expansion technique also achieves satisfying results on adding new categories into our system as required.
81688724	International Conference on Data Mining	bing liu + gao cong	2002	Speed-up iterative frequent itemset mining with constraint changes	iterative frequent itemset mining speedup + tree projection + satisfiability + data mining + trees (mathematics) + constraint changes + association rules + FP-tree + tree boundary + frequency + interactive iterative process	AuthorProvided Keywords Not Found	Mining of frequent itemsets is a fundamental data mining task. Past research has proposed many efficient algorithms for this purpose. Recent work also highlighted the importance of using constraints to focus the mining process to mine only those relevant itemsets. In practice, data mining is often an interactive and iterative process. The user typically changes constraints and runs the mining algorithm many times before being satisfied with the final results. This interactive process is very time consuming. Existing mining algorithms are unable to take advantage of this iterative process to use previous mining results to speed up the current mining process. This results in an enormous waste of time and computation. In this paper, we propose an efficient technique to utilize previous mining results to improve the efficiency of current mining when constraints are changed. We first introduce the concept of tree boundary to summarize useful information available from previous mining. We then show that the tree boundary provides an effective and efficient framework for the new mining. The proposed technique has been implemented in the context of two existing frequent itemset mining algorithms, FP-tree and tree projection. Experiment results on both synthetic and real-life datasets show that the proposed approach achieves a dramatic saving of computation.
814BF280	International Conference on Data Mining	kotagin ramamohanarao + laurence a e park + marimuthu palaniswami	2002	A new implementation technique for fast spectral based document retrieval systems	spatial data + discrete cosine transforms + search engines + spectral text retrieval + data mining + information retrieval + indexation + query time + visual databases + data engineering + gold + spectral method + discrete cosine transform + navigation + vector space document ranking methods + document retrieval + spatial resolution + text mining + vector space + spectral based document retrieval systems	AuthorProvided Keywords Not Found	The traditional methods of spectral text retrieval (FDS,CDS) create an index of spatial data and convert the data to its spectral form at query time. We present a new method of implementing and querying an index containing spectral data which will conserve the high precision performance of the spectral methods, reduce the time needed to resolve the query, and maintain an acceptable size for the index. This is done by taking advantage of the properties of the discrete cosine transform and by applying ideas from vector space document ranking methods.
7E06E710	International Conference on Data Mining	o de vel + tholath emilia abraham	2002	Investigative profiling with computer forensic log data and association rules	application software + association rule + computer logs + web pages + computer networks + data mining + association rules + profiling system + computer perpetrators + forensics + collaboration + computer crime + computer forensics + investigative profiling	AuthorProvided Keywords Not Found	Investigative profiling is an important activity in computer forensics that can narrow the search for one or more computer perpetrators. Data mining is a technique that has produced good results in providing insight into large volumes of data. This paper describes how the association rule data mining technique may be employed to generate profiles from log data and the methodology used for the interpretation of the resulting rule sets. The process relies on background knowledge in the form of concept hierarchies and beliefs, commonly available from, or attainable by, the computer forensic investigative team. Results obtained with the profiling system has identified irregularities in computer logs.
8162A692	International Conference on Data Mining	jiawei han + xifeng yan	2002	gSpan: graph-based substructure pattern mining	lexicographic order + frequent connected subgraph mining + gSpan + kernel + data mining + testing + graph datasets + graphics + tree searching + graph-based substructure pattern mining + tree graphs + performance study + frequent graph-based pattern mining + unique minimum DFS code + computer science + canonical label + data structures + depth-first search strategy + algorithm + frequent substructure discovery	AuthorProvided Keywords Not Found	We investigate new approaches for frequent graph-based pattern mining in graph datasets and propose a novel algorithm called gSpan (graph-based substructure pattern mining), which discovers frequent substructures without candidate generation. gSpan builds a new lexicographic order among graphs, and maps each graph to a unique minimum DFS code as its canonical label. Based on this lexicographic order gSpan adopts the depth-first search strategy to mine frequent connected subgraphs efficiently. Our performance study shows that gSpan substantially outperforms previous algorithms, sometimes by an order of magnitude.
7F4E78A5	International Conference on Data Mining	alexander k seewald	2002	Exploring the parameter state space of stacking	meta data + parameter space + state space + boosting + learning algorithms + probability + data mining + bagging + linear regression + meta-data + machine learning + artificial intelligence + ensemble learning + parameter state space + learning artificial intelligence + confidences + probability distribution + learning (artificial intelligence) + stacking + state-space methods	AuthorProvided Keywords Not Found	Ensemble learning schemes are a new field in data mining. While current research concentrates mainly on improving the performance of single learning algorithms, an alternative is to combine learners with different biases. Stacking is the best-known such scheme which tries to combine learners' predictions or confidences via another learning algorithm. However, the adoption of stacking into the data mining community is hampered by its large parameter space, consisting mainly of other learning algorithms: (1) the set of learning algorithms to combine, (2) the meta-learner responsible for the combining; and (3) the type of meta-data to use - confidences or predictions. None of these parameters are obvious choices. Furthermore, little is known about the relation between the parameter settings and performance of stacking. By exploring all of stacking's parameter settings and their interdependencies, we attempt to make stacking a suitable choice for mainstream data mining applications.
8058C4ED	International Conference on Data Mining	solomon eyal shimony + natalia vanetik + ehud gudes	2002	Computing frequent graph patterns from semistructured data	complexity + databases + semistructured data + frequent labels + sub-graph isomorphism + indexing + frequent graph pattern computation + topology + data mining + graph data + association rules + pattern discovery + compact source information representation + information source querying + information source browsing + empirical evidence + common topologies + tree graphs + frequency + graphs + structured data + computer science + xml + graph isomorphism	AuthorProvided Keywords Not Found	Whereas data mining in structured data focuses on frequent data values, in semistructured and graph data the emphasis is on frequent labels and common topologies. Here, the structure of the data is just as important as its content. We study the problem of discovering typical patterns of graph data. The discovered patterns can be useful for many applications, including: compact representation of source information and a road-map for browsing and querying information sources. Difficulties arise in the discovery task from the complexity of some of the required sub-tasks, such as sub-graph isomorphism. This paper proposes a new algorithm for mining graph data, based on a novel definition of support. Empirical evidence shows practical, as well as theoretical, advantages of our approach.
800EA3EC	International Conference on Data Mining	n duntsch + gunther gediga	2002	Modal-style operators in qualitative data analysis	qualitative data analysis + rough set approximation operator generalization + approximation theory + modal-style operators + data analysis + modal possibility operator + qualitative data + modal analysis + formal concept analysis + dual necessity operator + computer science + concept analysis + rough set + Morse data set + logic + multidimensional scaling + rough set theory	AuthorProvided Keywords Not Found	We explore the usage of the modal possibility operator (and its dual necessity operator) in qualitative data analysis, and show that it-quite literally-complements the derivation operator of formal concept analysis; we also propose a new generalization of the rough set approximation operators. As an example for the applicability of the concepts we investigate the Morse data set which has been frequently studied in multidimensional scaling procedures.
81520EE8	International Conference on Data Mining	prabhakar raghavan + panayiotis tsaparas	2002	Mining significant associations in large scale text corpora	databases + text analysis + algorithm design and analysis + large-scale text corpora mining + data mining + co-occurring word pair distribution + shortened documents + association rules + statistical distributions + co-occurring word triplet distribution + quantitative measure + computer science + key theme extraction + algorithmic problem + pruning algorithms + text mining + significant association mining + matrix mining	AuthorProvided Keywords Not Found	Mining large-scale text corpora is an essential step in extracting the key themes in a corpus. We motivate a quantitative measure for significant associations through the distributions of pairs and triplets of co-occurring words. We consider the algorithmic problem of efficiently enumerating such significant associations and present pruning algorithms for these problems, with theoretical as well as empirical analyses. Our algorithms make use of two novel mining methods: (1) matrix mining, and (2) shortened documents. We present evidence from a diverse set of documents that our measure does in fact elicit interesting co-occurrences.
814BCA95	International Conference on Data Mining	osmar r zaiane + chihoon lee	2002	Clustering spatial data when facing physical constraints	satellites + spatial data + databases + data mining + testing + visual databases + geographic information systems + DBCluC algorithm + medical information systems + image analysis + hidden patterns + clustering algorithms + satellite imagery + biomedical imaging + geographic information system + spatial data clustering + search space + physical constraints + medical image analysis	AuthorProvided Keywords Not Found	Clustering spatial data is a well-known problem that has been extensively studied to find hidden patterns or meaningful sub-groups and has many applications such as satellite imagery, geographic information systems, medical image analysis, etc. Although many methods have been proposed in the literature, very few have considered constraints such that physical obstacles and bridges linking clusters may have significant consequences on the effectiveness of the clustering. Taking into account these constraints during the clustering process is costly, and the effective modeling of the constraints is of paramount importance for good performance. In this paper we define the clustering problem in the presence of constraints - obstacles and crossings - and investigate its efficiency and effectiveness for large databases. In addition, we introduce a new approach to model these constraints to prune the search space and reduce the number of polygons to test during clustering. The algorithm DBCluC we present detects clusters of arbitrary shape and is insensitive to noise and the input order Its average running complexity is O(NlogN) where N is the number of data objects.
7F4BADE0	International Conference on Data Mining	laurentiu cristofor + dan a simovici	2002	Generating an informative cover for association rules	association rule + Guigues-Duquenne-Luxenburger basis + inference + algorithm design and analysis + data mining + dense databases + association rules + mining + inference mechanisms + artificial intelligence + Mushroom database + computer science + terminology	AuthorProvided Keywords Not Found	Mining association rules may generate a large numbers of rules making the results hard to analyze manually. Pasquier et al. have discussed the generation of Guigues-Duquenne-Luxenburger basis (GD-L basis). Using a similar approach, we introduce a new rule of inference and define the notion of association rules cover as a minimal set of rules that are non-redundant with respect to this new rule of inference. Our experimental results (obtained using both synthetic and real data sets) show that our covers are smaller than the GD-L basis and they are computed in time that is comparable to the classic Apriori algorithm for generating rules.
7EB870A8	International Conference on Data Mining	brent heeringa + paul cohen + niall m adams	2002	Unsupervised segmentation of categorical time series into episodes	document handling + languages + mathematics + unsupervised segmentation algorithm + data mining + categorical time series + VOTING-EXPERTS algorithm + words + time series + robot sensor data + sequences + text segmentation + frequency + unsupervised learning + entropy + expert methods + computer science + dna + writing + ngrams + subsequences + boundary entropy + episodes + statistics	AuthorProvided Keywords Not Found	"This paper describes an unsupervised algorithm for segmenting categorical time series into episodes. The VOTING-EXPERTS algorithm first collects statistics about the frequency and boundary entropy of ngrams, then passes a window over the series and has two ""expert methods"" decide where in the window boundaries should be drawn. The algorithm successfully segments text into words in four languages. The algorithm also segments time series of robot sensor data into subsequences that represent episodes in the life of the robot. We claim that VOTING-EXPERTS finds meaningful episodes in categorical time series because it exploits two statistical characteristics of meaningful episodes."
7E946E29	International Conference on Data Mining	shuilung chuang + leefeng chien	2002	Towards automatic generation of query taxonomy: a hierarchical query clustering approach	thesauri + search engines + automatic query taxonomy generation + domain specific vocabulary + search engine + information retrieval + taxonomy + highly ranked Web documents + cluster partition technique + terminology + clustering algorithms + thesaurus information + hierarchical query clustering approach + domain-specific vocabulary + user search interests + information needs + information science + hierarchical agglomerative clustering algorithm	AuthorProvided Keywords Not Found	Most previous work on automatic query clustering generated a flat, un-nested partition of query terms. In this work, we discuss the organization of query terms into a hierarchical structure and construct a query taxonomy in an automatic way. The proposed approach is designed based on a hierarchical agglomerative clustering algorithm to hierarchically group similar queries and generate cluster hierarchies using a novel cluster partition technique. The search processes of real-world search engines are combined to obtain highly ranked Web documents as the feature source for each query term. Preliminary experiments show that the proposed approach is effective for obtaining thesaurus information for query terms, and is also feasible for constructing a query taxonomy which provides a basis for in-depth analysis of users' search interests and domain-specific vocabulary on a larger scale.
8064CB12	International Conference on Data Mining	hong yao + cory j butz + howard j hamilton	2002	FD_Mine: discovering functional dependencies in a database using equivalences	independent component analysis + computer science + relational databases + functional dependency + databases + data mining + sorting + pruning + lattices		"
The discovery of FDs from databases has recently become a significant research problem. In this paper, we propose a new algorithm, called FD_Mine. FD_Mine takes advantage of the rich theory of FDs to reduce both the size of the dataset and the number of FDs to be checked by using discovered equivalences. We show that the pruning does not lead to loss of information. Experiments on 15 UCI datasets show that FD_Mine can prune more candidates than previous methods.
"
7ECB62FF	International Conference on Data Mining	osmar r zaiane + andrew foss	2002	A parameterless method for efficiently discovering clusters of arbitrary shape in large datasets	shape + data mining + efficient clustering algorithm + scalable clustering algorithm + noise shaping + unsupervised classification + scalability + arbitrarily shaped cluster discovery + large datasets + parameterless method + intra-group similarity maximization + fast clustering algorithm + grouped data + pattern clustering + clustering algorithms + gravity + clustering + inter-group similarity minimization + minimisation	AuthorProvided Keywords Not Found	Clustering is the problem of grouping data based on similarity and consists of maximizing the intra-group similarity while minimizing the inter-group similarity. The problem Of clustering data sets is also known as unsupervised classification, since no class labels are given. However, all existing clustering algorithms require some parameters to steer the clustering process, such as the famous k for the number of expected clusters, which constitutes a supervision of a sort. We present in this paper a new, efficient, fast and scalable clustering algorithm that clusters over a range of resolutions and finds a potential optimum clustering without requiring any parameter input. Our experiments show that our algorithm outperforms most existing clustering algorithms in quality and speed for large data sets.
7DD5C003	International Conference on Data Mining	lifang gu + hongxing he + rohan baxter + graham j williams + simon hawkins	2002	A comparative study of RNN for outlier detection in data mining	databases + data mining datasets + data mining + testing + neural networks + helium + outlier detection + neural network + scalability + recurrent neural networks + very large databases + intelligent networks + statistical databases + statistical datasets + neural nets + replicator neural networks	replicator neural network + outlier detection + empirical comparison + clustering + mixture modelling	We have proposed replicator neural networks (RNNs) for outlier detection. We compare RNN for outlier detection with three other methods using both publicly available statistical datasets (generally small) and data mining datasets (generally much larger and generally real data). The smaller datasets provide insights into the relative strengths and weaknesses of RNNs. The larger datasets in particular test scalability and practicality of application.
7F303DAB	International Conference on Data Mining	ben kao + minghua zhang + chilap yip	2002	A comparison study on algorithms for incremental update of frequent sequences	sequence database + GSP + data mining + intrusion detection + availability + database management systems + sequences + mining frequent sequences + incremental algorithm + sequence + relative performance + SPADE + computer science + concurrency control + mining problem + information systems + MFS + frequent sequences + incremental update	AuthorProvided Keywords Not Found	The problem of mining frequent sequences is to extract frequently occurring subsequences in a sequence database. Algorithms on this mining problem include GSP, MFS, and SPADE. The problem of incremental update of frequent sequences is to keep track of the set of frequent sequences as the underlying database changes. Previous studies have extended the traditional algorithms to efficiently solve the update problem. These incremental algorithms include ISM, GSP+ and MFS+. Each incremental algorithm has its own characteristics and they have been studied and evaluated separately under different scenarios. This paper presents a comprehensive study on the relative performance of the incremental algorithms as well as their non-incremental counterparts. Our goal is to provide guidelines on the choice of an algorithm for solving the incremental update problem given the various characteristics of a sequence database.
7E9C9A1C	International Conference on Data Mining	eamonn keogh + jessica lin + pranav m patel + stefano lonardi	2002	Mining motifs in massive time series databases	computational biology + association rule + computation biology + prototypes + convergence + data mining + association rules + time series + knowledge discovery + database management systems + classification + query by content + data engineering + massive time series databases + motifs mining + computer science + clustering algorithms + data visualization + real world datasets	AuthorProvided Keywords Not Found	"The problem of efficiently locating previously known patterns in a time series database (i.e., query by content) has received much attention and may now largely be regarded as a solved problem. However, from a knowledge discovery viewpoint, a more interesting problem is the enumeration of previously unknown, frequently occurring patterns. We call such patterns ""motifs"", because of their close analogy to their discrete counterparts in computation biology. An efficient motif discovery algorithm for time series would be useful as a tool for summarizing and visualizing massive time series databases. In addition it could be used as a subroutine in various other data mining tasks, including the discovery of association rules, clustering and classification. In this paper we carefully motivate, then introduce, a nontrivial definition of time series motifs. We propose an efficient algorithm to discover them, and we demonstrate the utility and efficiency of our approach on several real world datasets."
7E89C825	International Conference on Data Mining	geoffrey i webb + robin n shaw + j e pearce + brian j garner	2002	Experimentation and self learning in continuous database marketing	self learning + databases + prediction model + data mining + testing + experimental design principles + marketing data processing + marketing management + mining industry + learning artificial intelligence + predictive models + very large databases + mathematical model + experimental design + learning (artificial intelligence) + continuous database marketing	AuthorProvided Keywords Not Found	We present a method for continuous database marketing that identifies target customers for a number of marketing offers using predictive models. The algorithm then selects the appropriate offer for the customer. Experimental design principles are encapsulated to capture more information that will be used to monitor and refine the predictive models. The updated predictive models are then used for the next round of marketing offers.
80C0CD91	International Conference on Data Mining	tim oates	2002	PERUSE: An unsupervised algorithm for finding recurring patterns in time series	radio broadcasting + multivariate time series + supervised learning + data mining + testing + dynamic programming + pattern discovery problem + mobile robot + time series + natural language utterances + mobile robots + unsupervised learning + computer science + time measurement + natural languages + unsupervised algorithm + PERUSE + natural language + acoustic noise	AuthorProvided Keywords Not Found	This paper describes PERUSE, an unsupervised algorithm for finding recurring patterns in time series. It was initially developed and tested with sensor data from a mobile robot, i.e. noisy, real-valued, multivariate time series with variable intervals between observations. The pattern discovery problem is decomposed into two subproblems: (1) a supervised learning problem in which a teacher provides exemplars of patterns and labels time series according to whether they contain the patterns; (2) an unsupervised learning problem in which the time series are used to generate an approximation to the teacher. Experimental results show that PERUSE can discover patterns in audio data corresponding to recurring words in natural language utterances and patterns in the sensor data of a mobile robot corresponding to qualitatively distinct outcomes of taking actions.
7E4FA2CE	International Conference on Data Mining	michael r berthold + christian borgelt	2002	Mining molecular fragments: finding relevant substructures of molecules	pharmaceutical industry + data analysis + data mining + molecules + association rules + association rule mining + drug discovery + computer science + biology computing + biochemistry + bioinformatics + chemical structure + cancer + molecular biophysics + search strategy	AuthorProvided Keywords Not Found	We present an algorithm to find fragments in a set of molecules that help to discriminate between different classes of for instance, activity in a drug discovery context. Instead of carrying out a brute-force search, our method generates fragments by embedding them in all appropriate molecules in parallel and prunes the search tree based on a local order of the atoms and bonds, which results in substantially faster search by eliminating the need for frequent, computationally expensive reembeddings and by suppressing redundant search. We prove the usefulness of our algorithm by demonstrating the discovery of activity-related groups of chemical compounds in the well-known National Cancer Institute's HIV-screening dataset.
7F7F4CFC	International Conference on Data Mining	l de raedt + michael c jaeger + heikki mannila + sau dan lee	2002	A theory of inductive query answering	concept learning + information technology + data mining + inductive query answering theory + data structure + association rules + database management systems + monotonic predicates + frequency + query processing + decomposition theory + strings + a priori algorithm + anti-monotonic predicates + version space tree + boolean algebra + data structures + database languages + version space + pattern domain + history + Boolean algebra + machine learning + database theory + Boolean query reformulation + Boolean inductive query evaluation problem + sub-queries + database systems	AuthorProvided Keywords Not Found	We introduce the Boolean inductive query evaluation problem, which is concerned with answering inductive queries that are arbitrary Boolean expressions over monotonic and anti-monotonic predicates. Secondly, we develop a decomposition theory for inductive query evaluation in which a Boolean query Q is reformulated into k sub-queries Qi = QA ∧ QM that are the conjunction of a monotonic and an anti-monotonic predicate. The solution to each subquery can be represented using a version space. We investigate how the number of version spaces k needed to answer the query can be minimized. Thirdly, for the pattern domain of strings, we show how the version spaces can be represented using a novel data structure, called the version space tree, and can be computed using a variant of the famous a priori algorithm. Finally, we present experiments that validate the approach.
7F4C7D6D	International Conference on Data Mining	jason t l wang + michael m yin	2002	Mining genes in DNA using GeneScout	genomic dna + gene structures + gene prediction + data mining + acceptor sites + directed acyclic graph + knowledge discovery + sequences + hidden Markov models + GeneScout + hidden markov models + dynamic programming algorithm + proteins + dna + mRNA splicing junction donor + genomics + splicing + genes mining + gene structure + em algorithm + vertebrate gene prediction + expectation-maximization algorithm + algorithm design and analysis + dynamic programming + gene detection system + protein-translation start sites + gene finding + cross validation + DNA + bioinformatics + hidden markov model + expectation maximization + expectation maximization algorithm + medical computing + vertebrate genomic DNA	Bioinformatics + Gene finding + Hidden Markov models + Knowledge discovery + Data mining	In this paper we present a new system, called GeneScout, for predicting gene structures in vertebrate genomic DNA. The system contains specially designed hidden Markov models (HMMs) for detecting functional sites including protein-translation start sites, mRNA splicing junction donor and acceptor sites, etc. Our main hypothesis is that, given a vertebrate genomic DNA sequence S, it is always possible to construct a directed acyclic graph G such that the path for the actual coding region of S is in the set of all paths on G. Thus, the gene detection problem is reduced to that of analyzing the paths in the graph G. A dynamic programming algorithm is used to find the optimal path in G. The proposed system is trained using an expectation-maximization (EM) algorithm and its performance on vertebrate gene prediction is evaluated using the 10-way cross-validation method. Experimental results show the good performance of the proposed system and its complementarity to a widely used gene detection system.
7CF7E57D	International Conference on Data Mining	i v ramakrishnan + saikat mukherjee + hasan davulcu	2002	Extraction techniques for mining services from Web sources	databases + web pages + service provider + web mining + data mining + web sites + advertising + taxonomy + learning artificial intelligence + information extraction + computer science + extraction algorithms + learning (artificial intelligence) + mining service directories + ontologies + electronic commerce	AuthorProvided Keywords Not Found	The Web has established itself as the dominant medium for doing electronic commerce. Consequently the number of service providers, both large and small, advertising their services on the web continues to proliferate. In this paper we describe new extraction algorithms for mining service directories from web pages. We develop a novel propagation technique for identifying and accumulating all of the attributes related to a service entity in a web page. We provide experimental results of the effectiveness of our extraction techniques by mining a database of veterinarian service providers from web sources.
59FE75DB	International Conference on Data Mining	faisal m khan + todd a fisher + tianhao wu + william m pottenger + lori a shuler	2002	Posting Act Tagging Using Transformation- Based Learning	regular expression		"
In this article we present the application of transformation-based learning (TBL) [1] to the task of assigning tags to postings in online chat conversations. We define a list of posting tags that have proven useful in chat-conversation analysis. We describe the templates used for posting act tagging in the context of template selection. We extend traditional approaches used in part-of-speech tagging and dialogue act tagging by incorporating regular expressions into our templates. We close with a presentation of results that compare favorably with the application of TBL in dialogue act tagging.
"
7E78EB41	International Conference on Data Mining	joseph a kogan + inderjit s dhillon + yuqiang guan	2002	Iterative clustering of high dimensional text data augmented by local search	text analysis + incremental data point movement + mathematics + data mining + sparse text data clustering + cosine similarity + local search + refining + objective function value + frequency + spherical k-means algorithm + k means algorithm + clustering algorithms + first variation + local maximum + k means + high dimensional text data + search problems + objective function + k means clustering + information retrieval + euclidean distance + document collection clustering + iterative clustering + pattern clustering + ping-pong strategy + statistics	AuthorProvided Keywords Not Found	"The k-means algorithm with cosine similarity, also known as the spherical k-means algorithm, is a popular method for clustering document collections. However spherical k-means can often yield qualitatively poor results, especially when cluster sizes are small, say 25-30 documents per cluster, where it tends to get stuck at a local maximum far away from the optimal solution. In this paper, we present a local search procedure, which we call 'first-variation"" that refines a given clustering by incrementally moving data points between clusters, thus achieving a higher objective function value. An enhancement of first variation allows a chain of such moves in a Kernighan-Lin fashion and leads to a better local maximum. Combining the enhanced first-variation with spherical k-means yields a powerful ""ping-pong"" strategy that often qualitatively improves k-means clustering and is computationally efficient. We present several experimental results to highlight the improvement achieved by our proposed algorithm in clustering high-dimensional and sparse text data."
7ED79632	International Conference on Data Mining	zhong zhang + qiang yang + yidong shen	2002	Objective-oriented utility-based association mining	association rule + model specification + business + object oriented + data mining + enterprise + probability + association rules + association pattern discovery + association pattern modeling + frequency + computer science + a priori algorithm + pruning strategy + semantic information + objective-oriented utility-based association mining + pattern recognition	AuthorProvided Keywords Not Found	The necessity of developing methods for discovering association patterns to increase business utility of an enterprise has long been recognized in the data mining community. This requires modeling specific association patterns that are both statistically (based on support and confidence) and semantically (based on objective utility) related to a given objective that a user wants to achieve or is interested in. However, no such general model has been reported in the literature. Traditional association mining focuses on deriving correlations among a set of items and their association rules; diaper → beer only tells us that a pattern like {diaper} is statistically related to an item like beer. In this paper we present a new approach, called objective-oriented utility-based association (OOA) mining, to modeling such association patterns that are explicitly related to a user's objective and its utility. Due to its focus on a user's objective and the use of objective utility as key semantic information to measure the usefulness of association patterns, OOA mining differs significantly from existing approaches such as existing constraint-based association mining. We formally define OOA mining and develop an algorithm for mining OOA rules. The algorithm is an enhancement of a priori with specific mechanisms for handling objective utility. We prove that the utility constraint is neither monotone nor anti-monotone, succinct or convertible and present a novel pruning strategy based on the utility constraint to improve the efficiency of OOA mining.
7E354FCC	International Conference on Data Mining	marialuiza antonie + osmar r zaiane	2002	Text document categorization by term association	text analysis + association rule + pattern classification + indexing + data mining + market basket analysis + information retrieval + text documents + association rules + text categorization + machine learning + association rule mining + automatic text categorization + learning artificial intelligence + text classifier + rule mining + automatic text classification + term association + learning (artificial intelligence)	AuthorProvided Keywords Not Found	A good text classifier is a classifier that efficiently categorizes large sets of text documents in a reasonable time frame and with an acceptable accuracy, and that provides classification rules that are human readable for possible fine-tuning. If the training of the classifier is also quick, this could become in some application domains a good asset for the classifier. Many techniques and algorithms for automatic text categorization have been devised. According to published literature, some are more accurate than others, and some provide more interpretable classification models than others. However, none can combine all the beneficial properties enumerated above. In this paper we present a novel approach for automatic text categorization that borrows from market basket analysis techniques using association rule mining in the data-mining field. We focus on two major problems: (1) finding the best term association rules in a textual database by generating and pruning; and (2) using the rules to build a text classifier. Our text categorization method proves to be efficient and effective, and experiments on well-known collections show that the classifier performs well. In addition, training as well as classification are both fast and the generated rules are human readable.
7FA9EC5E	International Conference on Data Mining	srinivasan parthasarathy + matt coatney	2002	Efficient discovery of common substructures in macromolecules	macromolecules + three dimensional + structure function + data mining + coordinate noise handling + sequences + search space reduction + protein structure + proteins + pharmacology + common substructures discovery + genomics + sequence analysis + search space + medical administrative data processing + structure-based frequent pattern discovery + molecular biophysics + chemicals + information science + biological macromolecules + chemical genomics	AuthorProvided Keywords Not Found	Biological macromolecules play a fundamental role in disease; therefore, they are of great interest to fields such as pharmacology and chemical genomics. Yet due to macromolecules' complexity, development of effective techniques for elucidating structure-function macromolecular relationships has been ill explored. Previous techniques have either focused on sequence analysis, which only approximates structure-function relationships, or on small coordinate datasets, which does not scale to large datasets or handle noise. We present a novel scalable approach to efficiently discover macromolecule substructures based on three-dimensional coordinate data, without domain-specific knowledge. The approach combines structure-based frequent pattern discovery with search space reduction and coordinate noise handling. We analyze computational performance compared to traditional approaches, validate that our approach can discover meaningful substructures in noisy macromolecule data by automated discovery of primary and secondary protein structures, and show that our technique is superior to sequence-based approaches at determining structural, and thus functional, similarity between proteins.
7FE70DFF	International Conference on Data Mining	robert l grossman + richard g larson	2002	An algebraic approach to data mining: some examples	pattern classification + erbium + control theory + state space + functions + convergence + data mining + large database + state space observations + algebra + encoding + algebraic approach + database theory + algebraic encoding + labeled sets of states + misclassification rate + predictive models + very large databases + classifier + data sets	AuthorProvided Keywords Not Found	We introduce an algebraic approach to the foundations of data mining. Our approach is based upon two algebras of functions defined over a common state space X and a pairing between them. One algebra is an algebra of state space observations, and the other is an algebra of labeled sets of states. We interpret H as the algebraic encoding of the data and the pairing as the misclassification rate when the classifier f is applied to the set of states X. We give a realization theorem giving conditions on formal series of data sets built from D that imply there is a realization involving a state space X, a classifier f ∈ R and a set of labeled states χ ∈ R0 that yield this series.
807BB64A	International Conference on Data Mining	fabrizio silvestri + raffaele perego + paolo palmerini + salvatore orlando	2002	Adaptive and resource-aware mining of frequent sets	data analysis + ParDCl + algorithm design and analysis + data mining + transactional databases + association rules + frequent sets + database management systems + DCl + multiple heuristics strategies + resource-aware mining + adaptive mining + large databases	AuthorProvided Keywords Not Found	The performance of an algorithm that mines frequent sets from transactional databases may severely depend on the specific features of the data being analyzed. Moreover, some architectural characteristics of the computational platform used - e.g. the available main memory - can dramatically change its runtime behavior. In this paper we present DCI (Direct Count & Intersect), an efficient algorithm for discovering frequent sets from large databases. Due to the multiple heuristics strategies adopted, DCI can adapt its behavior not only to the features of the specific computing platform, but also to the features of the dataset being mined, so that it results very effective in mining both short and long patterns from sparse and dense datasets. Finally we also discuss the parallelization strategies adopted in the design of ParDCI, a distributed and multi-threaded implementation of DCI.
5C87EBD8	International Conference on Data Mining	petra perner + g fiss	2002	Intelligent E-marketing with Web Mining, Personalization, and User-Adpated Interfaces	data mining + data analysis + web mining + e commerce	 + E-Commerce + Data Mining + User Profiling + Clickstream analysis + Recommendation + User-Adapted Interfaces	"
For many people the special attraction of E-commerce is linked to the idea of being able to choose and order products and services directly on-line from home. However, this is only one aspect of the new on-line sales model. As in real sales processes competent counselling, in accordance with the customer's necessities, and also after-sales assistance by help of the web play an important part for the customer faith. This requires precise knowledge of the customer's preferences who, however, in general does not like lengthy questioning and the use of other communication routes. Holders of E-shops have thus to gather the consumer's desires and preferences from his interactions and the data resulting from the sales process, which requires a profound data analysis. In this paper we describe what kind of data can be acquired in an eshop and how these data can be used to improve advertisement, marketing and selling. We describe what kind of data mining methods are necessary and how they can be applied to the data.
"
7DE742D6	International Conference on Data Mining	jiawei han + jianyong wang + ying lu + petre tzvetkov	2002	Mining top-k frequent closed patterns without minimum support	top down + efficient algorithm + fast hash-based closed pattern verification scheme + minimum support + data mining + trees (mathematics) + support threshold + association rules + descendant-sum method + closed frequent pattern discovery + support-raising + top-k frequent closed pattern mining + closed-node-count method + bottom up + FP-tree pruning + tfp + TFP	AuthorProvided Keywords Not Found	In this paper, we propose a new mining task: mining top-k frequent closed patterns of length no less than min_ℓ, where k is the desired number of frequent closed patterns to be mined, and min_ℓ is the minimal length of each pattern. An efficient algorithm, called TFP, is developed for mining such patterns without minimum support. Two methods, closed-node-count and descendant-sum are proposed to effectively raise support threshold and prune FP-tree both during and after the construction of FP-tree. During the mining process, a novel top-down and bottom-up combined FP-tree mining strategy is developed to speed-up support-raising and closed frequent pattern discovering. In addition, a fast hash-based closed pattern verification scheme has been employed to check efficiently if a potential closed pattern is really closed. Our performance study shows that in most cases, TFP outperforms CLOSET and CHARM, two efficient frequent closed pattern mining algorithms, even when both are running with the best tuned min-support. Furthermore, the method can be extended to generate association rules and to incorporate user-specified constraints.
7F29CE3D	International Conference on Data Mining	wei fan + chid apte + haixun wang + bianca zadrozny + edwin p d pednault + naoki abe	2002	Empirical comparison of various reinforcement learning strategies for sequential targeted marketing	profitability + history + reinforcement learning + degradation + learning artificial intelligence + data mining + direct method + sampling methods + marketing + decision theory + performance		"
We empirically evaluate the performance of various reinforcement learning methods in applications to sequential targeted marketing. In particular, we propose and evaluate a progression of reinforcement learning methods, ranging from the “direct” or “batch” methods to “indirect” or “simulation based” methods, and those that we call “semidirect” methods that fall between them. We conduct a number of controlled experiments to evaluate the performance of these competing methods. Our results indicate that while the indirect methods can perform better in a situation in which nearly perfect modeling is possible, under the more realistic situations in which the system's modeling parameters have restricted attention, the indirect methods' performance tend to degrade. We also show that semi-direct methods are effective in reducing the amount of computation necessary to attain a given level of performance, and often result in more profitable policies.
"
7D1D8AD6	International Conference on Data Mining	yimin xiong + dityan yeung	2002	Mixtures of ARMA models for model-based time series clustering	time series analysis + mixing coefficient learning + autoregressive moving average processes + data mining + knowledge discovery + mixture model + datasets + uncertainty + sequences + moving average + multidimensional systems + parameter learning + model-based time series clustering + bayesian methods + hidden markov models + computer science + predictive models + clustering algorithms + ARMA model mixtures + em algorithm + expectation-maximization algorithm + component model + time series + data pattern clustering + unsupervised learning + autoregressive moving average models + pattern clustering + arma model + expectation maximization + expectation maximization algorithm	AuthorProvided Keywords Not Found	Clustering problems are central to many knowledge discovery and data mining tasks. However, most existing clustering methods can only work with fixed-dimensional representations of data patterns. In this paper we study the clustering of data patterns that are represented as sequences or time series possibly of different lengths. We propose a model-based approach to this problem using mixtures of autoregressive moving average (ARMA) models. We derive an expectation-maximization (EM) algorithm for learning the mixing coefficients as well as the parameters of component models. Experiments were conducted on simulated and real datasets. Results show that our method compares favorably with another method recently proposed by others for similar time series clustering problems.
7EEFBC1A	International Conference on Data Mining	serena chan + simon fong	2002	Mining online users' access records for web business intelligence	databases + website + data mining + information retrieval + access-control architectural model + business intelligence + software agents + intelligent agent + e-CRM + computer architecture + online users access records mining + access control + service oriented architecture + Web sites + internet + Web business intelligence + bismuth	AuthorProvided Keywords Not Found	"This paper discusses about how business intelligence on a website could be obtained from users' access records instead of web logs of ""hits"". Users' access records are captured by implementing an Access-Control (AC) architectural model on the website. This model requires users to register their profiles in an exchange of a password; and thereafter they have to login before gaining access to certain resources on the website. The links to the resources on the website have been modified such that a record of information about the access would be recorded in the database when clicked. This way, datamining can be performed on a relatively clean set of access records about the users. Hence, a good deal of business intelligence about the users' behaviors, preferences and about the popularities of the resources (products) on the website can be gained. In this paper, we also discussed how the business intelligence acquired, in turn, can be used to provide e-CRM for the users."
7F9E680E	International Conference on Data Mining	horst d simon + hongyuan zha + xiaofeng he + chris ding	2002	Adaptive dimension reduction for clustering high dimensional data	data mining + dimension reduction + image analysis + local minimum + gaussian processes + high dimensional data + clustering algorithms + k means algorithm + cluster analysis + k means + adaptive dimension reduction + image processing + em algorithm + algorithm design and analysis + highly overlapped Gaussians + information analysis + reduced dimensional subspace + adaptive systems + DNA gene expression profiles + Internet newsgroups + K-means algorithm + cluster membership + high dimensional data clustering + pattern clustering + EM algorithm + gene expression + principal component analysis	AuthorProvided Keywords Not Found	It is well-known that for high dimensional data clustering, standard algorithms such as EM and K-means are often trapped in a local minimum. Many initialization methods have been proposed to tackle this problem, with only limited success. In this paper we propose a new approach to resolve this problem by repeated dimension reductions such that K-means or EM are performed only in very low dimensions. Cluster membership is utilized as a bridge between the reduced dimensional subspace and the original space, providing flexibility and ease of implementation. Clustering analysis performed on highly overlapped Gaussians, DNA gene expression profiles and Internet newsgroups demonstrate the effectiveness of the proposed algorithm.
63A6095F	International Conference on Data Mining	rayid ghani + andrew fano	2002	Using text mining to infer semantic attributes for retail data mining	knowledge base + semantic attribute inference + text learning techniques + text analysis + retail data mining + data mining + neural networks + association rules + competitive intelligence + knowledge based systems + apparel products + text mining + semantic features + retailer Web sites + retail data processing + data analysis + retailer Websites + product semantics + byfeature construction + inference mechanisms + data engineering + semantic feature extraction + recommender system + recommender systems + decision trees + competitive intelligence tools	AuthorProvided Keywords Not Found	"Current data mining techniques usually do not have a mechanism to automatically infer semantic features inherent in the data being ""mined"". The semantics are either injected in the initial stages (by feature construction) or by interpreting the results produced by the algorithms. Both of these techniques have proved effective but require a lot of human effort. In many domains, semantic information is implicitly available and can be extracted automatically to improve data mining systems. In this paper we present a case study of a system that is trained to extract semantic features for apparel products and populate a knowledge base with these products and features. We show that semantic features of these items can be successfully extracted by applying text learning techniques to the descriptions obtained from websites of retailers. We also describe several applications of such a knowledge base of product semantics that we have built including recommender systems and competitive intelligence tools and provide evidence that our approach can successfully build a knowledge base with accurate facts which can then be used to create profiles of individual customers, groups of customers, or entire retail stores."
62F8BC4D	International Conference on Data Mining	kien a hua + ning jiang + simon sheu	2002	Considering both intra-pattern and inter-pattern anomalies for intrusion detection	Unix + application software + pattern matching + experimental results + data mining + testing + inter-pattern anomalies + intrusion detection + pattern extraction algorithm + windows + UNIX + pattern matching module + false alarm rate + security of data + intra-pattern anomalies + computer science + very large databases + data sets + system calls + maximal patterns + unix	AuthorProvided Keywords Not Found	Various approaches have been proposed to discover patterns from system call trails of UNIX processes to better model application behavior. However, these techniques only consider the relationship between system calls (or system audit events). We first refine the definition of maximal patterns given in (Wespi et al., 2000) and provide a pattern extraction algorithm to identify such maximal patterns. We then add one additional dimension to the problem domain by also taking into consideration the overlap relationship between patterns. We argue that an execution path of an application is usually not an arbitrary combination of various patterns; but rather, they overlap each other in some specific order. Such overlap relationship characterizes the normal behavior of the application. Finally, a novel pattern matching module is proposed to detect intrusions based on both intra-pattern and inter-pattern anomalies. We test this idea using the data sets obtained from the University of New Mexico. The experimental results indicate that our scheme detects significantly more anomalies than the scheme presented in (Wespi et al., 2000) while maintaining a very low false alarm rate.
7CF0487D	International Conference on Data Mining	ricardo vilalta + sheng ma	2002	Predicting rare events in temporal domains	time series analysis + financial institutions + data mining + discrimination power + rule-based model + temporal patterns extraction + set theory + computer attacks + class-imbalance problem + frequent eventsets + speech recognition + computer science + categorical features + predictive techniques + knowledge based systems + rare events prediction + temporal domains + host networks + testing + fraudulent transactions + rule based + uneven inter-arrival times + experimental analysis + minority class + temporal data mining	AuthorProvided Keywords Not Found	Temporal data mining aims at finding patterns in historical data. Our work proposes an approach to extract temporal patterns from data to predict the occurrence of target events, such as computer attacks on host networks, or fraudulent transactions in financial institutions. Our problem formulation exhibits two major challenges: 1) we assume events being characterized by categorical features and displaying uneven inter-arrival times; such an assumption falls outside the scope of classical time-series analysis, 2) we assume target events are highly infrequent; predictive techniques must deal with the class-imbalance problem. We propose an efficient algorithm that tackles the challenges above by transforming the event prediction problem into a search for all frequent eventsets preceding target events. The class imbalance problem is overcome by a search for patterns on the minority class exclusively; the discrimination power of patterns is then validated against other classes. Patterns are then combined into a rule-based model for prediction. Our experimental analysis indicates the types of event sequences where target events can be accurately predicted.
5A75E451	International Conference on Data Mining	d ph + april kontostathis + william m pottenger	2002	Detecting Patterns in the LSI Term-Term Matrix	singular value decomposition + text mining + higher order		"
Higher order co-occurrences play a key role in the effectiveness of systems used for text mining. A wide variety of applications use techniques that explicitly or implicitly employ a limited degree of transitivity in the cooccurrence relation. In this work we show use of higher orders of co-occurrence in the Singular Value Decomposition (SVD) algorithm and, by inference, on the systems that rely on SVD, such as LSI. Our empirical and mathematical studies prove that term co-occurrence plays a crucial role in LSI. This work is the first to study the values produced in the truncated term-term matrix, and we have discovered an explanation for why certain term pairs receive a high similarity value, while others receive low (and even negative) values. Thus we have discovered the basis for the claim that is frequently made for LSI: LSI emphasizes important semantic distinctions (latent semantics) while reducing noise in the data data.
"
5BFC2061	International Conference on Data Mining	tsay young lin	2002	Attribute (feature) completion - the theory of attributes from data mining prospect	data model + data mining + large database + canonical model + relational database + relational databases + isomorphism + database theory + data models + very large databases + abstract relation + feature selection + attribute completion	attributes + feature + data mining + granular + data model	"A ""correct"" selection of attributes (features) is vital in data mining. As a first step, this paper constructs all possible attributes of a given relation. The results are based on the observations that each relation is isomorphic to a unique abstract relation, called a canonical model. The complete set of attributes of the canonical model is, then, constructed. Any attribute of a relation can be interpreted (via isomorphism) from such a complete set."
7FB3FAB0	International Conference on Data Mining	chinghuang yun + mingsyan chen + kunta chuang	2002	Using category-based adherence to cluster market-basket data	information gain + market-basket data + marketing strategy + data analysis + marketing strategies + data mining + information retrieval + association rules + data clustering + taxonomy + machine learning + data engineering + marketing + entropy + category-based adherence + pattern clustering + clustering algorithms + tellurium + transactions clustering + category node	AuthorProvided Keywords Not Found	We devise an efficient algorithm for clustering market-basket data. Different from those of the traditional data, the features of market-basket data are known to be of high dimensionality, sparsity, and with massive outliers. Without explicitly considering the presence of the taxonomy, most prior efforts on clustering market-basket data can be viewed as dealing with items in the leaf level of the taxonomy tree. Clustering transactions across different levels of the taxonomy is of great importance for marketing strategies as well as for the result representation of the clustering techniques for market-basket data. In view of the features of market-basket data, we devise a measurement, called the category-based adherence, and utilize this measurement to perform the clustering. The distance of an item to a given cluster is defined as the number of links between this item and its nearest large node in the taxonomy tree where a large node is an item or a category node whose occurrence count exceeds a given threshold. The category-based adherence of a transaction to a cluster is then defined as the average distance of the items in this transaction to that cluster With this category-based adherence measurement, we develop an efficient clustering algorithm, called algorithm CBA, for market-basket data with the objective to minimize the category-based adherence. A validation model based on information gain is also devised to assess the quality of clustering for market-basket data. As validated by both real and synthetic datasets, it is shown by our experimental results, with the taxonomy information, algorithm CBA significantly outperforms the prior works in both the execution efficiency and the clustering quality for market-basket data.
7D4237E7	International Conference on Data Mining	hao huang + richard relue + xindong wu	2002	Association analysis with one scan of databases	association rule + algorithms + occurrence frequency checking + data mining + large database + support threshold + data structure + association rules + frequency + candidate generation + computer science + very large databases + data structures + tree data structures + data bases + pattern recognition + Pattern Tree + P-tree data structure + information retrieval + FP-tree + performance + database scan + association analysis + Apriori-like algorithms + frequent pattern mining	AuthorProvided Keywords Not Found	Mining frequent patterns with an FP-tree avoids costly candidate generation and repeatedly occurrence frequency checking against the support threshold. It therefore achieves better performance and efficiency than Apriori-like algorithms. However the database still needs to be scanned twice to get the FP-tree. This can be very time-consuming when new data are added to an existing database because two scans may be needed for not only the new data but also the existing data. This paper presents a new data structure P-tree, Pattern Tree, and a new technique, which can get the P-tree through only one scan of the database and can obtain the corresponding FP-tree with a specified support threshold. Updating a P-tree with new data needs one scan of the new data only, and the existing data do not need to be re-scanned.
70919635	International Conference on Data Mining	xiangji huang + aijun an	2002	Discovery of interesting association rules from Livelink web log data	data preprocessing + association rule + information management + data mining + information retrieval + association rules + web usage patterns mining + Livelink Web log data + association rules discovery + technology management + extranets + computer science + rule interestingness measures + Internet + internet + rules mining	AuthorProvided Keywords Not Found	We present our experience in mining web usage patterns from a large collection of Livelink log data. Livelink is a web-based product of Open Text, which provides automatic management and retrieval of different types of information objects over an intranet or extranet. We report our experience in preprocessing raw log data and post-processing the mining results for finding interesting rules. In particular we compare and evaluate a number of rule interestingness measures and find that two of the measures that have not been used in association rule learning work very well.
7EEBA357	International Conference on Data Mining	limsoon wong + jinyan li	2002	Solving the fragmentation problem of decision trees by discovering boundary emerging patterns	support vector machines + information technology + minor rules + data mining + gene expression datasets + neural networks + testing + rule discovery + fragmentation problem + emerging pattern + decision tree + training data + decision trees + gene expression	AuthorProvided Keywords Not Found	The single coverage constraint discourages a decision tree to contain many significant rules. The loss of significant rules leads to a loss in accuracy. On the other hand, the fragmentation problem causes a decision tree to contain too many minor rules. The presence of minor rules decreases the accuracy. We propose to use emerging patterns to solve these problems. In our approach, many globally significant rules can be discovered. Extensive expert. mental results on gene expression datasets show that our approach are more accurate than single C4.5 trees, and are also better than bagged or boosted C4.5 trees.
80B3DDA5	International Conference on Data Mining	sung young jung + j hong + taeksoo kim	2002	A formal model for user preference	positive preference + decision theory + data mining + noise effects + machine intelligence + user modelling + user preference model + personalization + navigation + training data + noise reduction + e-commerce + rare events + electronic commerce + information resources + dynamic weighting + pareto distribution + data sparseness + e commerce + history + recommendation systems + recommender system + Pareto distribution + formal model + negative preference + collaboration + random occurrence + random occurrence probability	AuthorProvided Keywords Not Found	Personalization and recommendation systems require a formalized model for user preference. We present the formal model of preference including positive preference and negative preference. For rare events, we apply the probability of random occurrence in order to reduce noise effects caused by data sparseness. Pareto distribution is adopted for the random occurrence probability. We also present the method for combining information of joint feature variables in different sizes by dynamic weighting using random occurrence probability.
7FA947EB	International Conference on Data Mining	colin fyfe + emilio corchado	2002	Optimal projections of high dimensional data	artificial neural network + projection pursuit + Exploratory Projection Pursuit + data mining + neural networks + neural network + negative feedback + lower dimensional manifolds + computational intelligence + artificial neural networks + nonlinear equations + learning artificial intelligence + high dimensional data + data structures + statistical analysis + learning (artificial intelligence) + Principal Component Analysis + neural nets + principal component analysis	AuthorProvided Keywords Not Found	In this paper, we compare two artificial neural network algorithms for performing Exploratory Projection Pursuit, a statistical technique for investigating data by projecting it onto lower dimensional manifolds. The neural networks are extensions of a network which performs Principal Component Analysis. We illustrate the technique on artificial data before applying it to real data.
7DB41CA4	International Conference on Data Mining	balaji padmanabhan + zhiqiang zheng	2002	On active learning for data acquisition	learning artificial intelligence + active learning + information management + data mining + UCI datasets + naturally incomplete data + data acquisition + web usage data + learning (artificial intelligence) + active learn	AuthorProvided Keywords Not Found	"Many applications are characterized by having naturally incomplete data on customers - where data on only some fixed set of local variables is gathered However, having a more complete picture can help build better models. The naive solution to this problem - acquiring complete data for all customers s often impractical due to the costs of doing so. A possible alternative is to acquire complete data for ""some"" customers and to use this to improve the models built. The data acquisition problem is determining how many, and which, customers to acquire additional data from. In this paper we suggest using active learning based approaches for the data acquisition problem. In particular, we present initial methods for data acquisition and evaluate these methods experimentally on web usage data and UCI datasets. Results show that the methods perform well and indicate that active learning based methods for data acquisition can be a promising area for data mining research."
7E740E4C	International Conference on Data Mining	jugen paetz	2002	Intersection based generalization rules for the analysis of symbolic septic shock patient data	septic shock patient data + pattern classification + rule generation + data analysis + data mining + association rules + robustness + heuristic + generalisation (artificial intelligence) + intensive care units + set-based intersections + optimisation + generalization rules + rule classification + medical computing	AuthorProvided Keywords Not Found	In intensive care units much data is irregularly recorded. Here, we consider the analysis of symbolic septic shock patient data. We show that it could be worth considering the generalization paradigm (individual cases generalized to more general rules) instead of the association paradigm (combining single attributes) when considering very individual cases (e.g. patients) and when expecting longer rules than shorter ones. We present an algorithm for rule generation and classification based on heuristically generated set-based intersections. We demonstrate the usefulness of our algorithm by analysing our septic shock patient data.
80A42B08	International Conference on Data Mining	srinivasan parthasarathy	2002	Efficient progressive sampling for association rules	association rule + databases + sampling methods + progressive sampling + data mining + association rules + fractals + association rule mining + pressing + rule mining + equivalence classes + sample size + information science + dataset + learning curve	AuthorProvided Keywords Not Found	In data mining, sampling has often been suggested as an effective tool to reduce the size of the dataset operated at some cost to accuracy. However this loss to accuracy is often difficult to measure and characterize since the exact nature of the learning curve (accuracy vs. sample size) is parameter and data dependent, i.e., we do not know a priori what sample size is needed to achieve a desired accuracy on a particular dataset for a particular set of parameters. In this article we propose the use of progressive sampling, to determine the required sample size for association rule mining. We first show that a naive application of progressive sampling is not very efficient for association rule mining. We then present a refinement based on equivalence classes, that seems to work extremely well in practice and is able to converge to the desired sample size very quickly and very accurately. An additional novelty of our approach is the definition of a support-sensitive, interactive measure of accuracy across progressive samples.
7E8A7848	International Conference on Data Mining	constantin f aliferis + ioannis tsamardinos + alexander statnikov + l frey + douglas fisher	2003	Identifying Markov blankets with decision tree induction	bayesian network + learning artificial intelligence + markov processes + decision tree induction + decision trees + Markov processes + Bayesian networks + belief networks + learning (artificial intelligence) + feature selection + Markov blanket identification + decision rule	AuthorProvided Keywords Not Found	The Markov blanket of a target variable is the minimum conditioning set of variables that makes the target independent of all other variables. Markov blankets inform feature selection, aid in causal discovery and serve as a basis for scalable methods of constructing Bayesian networks. We apply decision tree induction to the task of Markov blanket identification. Notably, we compare (a) C5.0, a widely used algorithm for decision rule induction, (b) C5C, which post-processes C5.0 's rule set to retain the most frequently referenced variables and (c) PC, a standard method for Bayesian network induction. C5C performs as well as or better than C5.0 and PC across a number of data sets. Our modest variation of an inexpensive, accurate, off-the-shelf induction engine mitigates the need for specialized procedures, and establishes baseline performance against which specialized algorithms can be compared.
7FB869A3	International Conference on Data Mining	hisashi kashima + akihiro inokuchi	2003	Mining significant pairs of patterns from graph structures with class labels	association rule + pattern mining + significant pair mining + graph theory + data mining + statistical metric + unordered trees + upper bound + transactional data + association rule mining + ordered trees + transaction data + knowledge representation + class labels + graph structure + labeled graph + computational complexity	AuthorProvided Keywords Not Found	In recent years, the problem of mining association rules over frequent itemsets in transactional data has been frequently studied and yielded several algorithms that can find association rules within a limited amount of time. Also more complex patterns have been considered such as ordered trees, unordered trees, or labeled graphs. Although some approaches can efficiently derive all frequent subgraphs from a massive dataset of graphs, a subgraph or subtree that is mathematically defined is not necessarily a better knowledge representation. We propose an efficient approach to discover significant rules to classify positive and negative graph examples by estimating a tight upper bound on the statistical metric. This approach abandons unimportant rules earlier in the computations, and thereby accelerates the overall performance. The performance has been evaluated using real world datasets, and the efficiency and effect of our approach has been confirmed with respect to the amount of data and the computation time.
808A4A18	International Conference on Data Mining	tomoyuki shibata + takekazu kato + toshikazu wada	2003	K-d decision tree: an accelerated and memory efficient nearest neighbor classifier	search algorithm + K-d decision tree + nearest neighbor classifier + tree searching + Voronoi condensed prototypes + memory consuming + storage management + decision tree + learning artificial intelligence + nearest neighbor + NN search algorithms + decision trees + learning (artificial intelligence)	AuthorProvided Keywords Not Found	Most nearest neighbor (NN) classifiers employ NN search algorithms for the acceleration. However, NN classification does not always require the NN search. Based on this idea, we propose a novel algorithm named k-d decision tree (KDDT). Since KDDT uses Voronoi condensed prototypes, it is less memory consuming than naive NN classifiers. We have confirmed that KDDT is much faster than NN search based classifiers through the comparative experiment (from 9 to 369 times faster).
80363939	International Conference on Data Mining	terumasa aoki + juan d velasquez + hiroshi yasuda	2003	Combining the Web content and usage mining to understand the visitor behavior in a Web site	content mining + clustering algorithm + visitor behavior analysis + data mining + information retrieval + Web log file + Web usage + Web content + navigation sequence + content management + self-organising feature maps + Web sites + Web site	AuthorProvided Keywords Not Found	A Web site is a semi structured collection of different kinds of data, whose motivation is to show relevant information to a visitor and in this way capture her/his attention. Understanding the specific preferences that define the visitor behavior in a Web site is a complex task. An approximation is supposed that depends on the content, navigation sequence and time spent in each page visited. These variables can be extracted from the Web log files and the Web site itself, using Web usage and content mining respectively. Combining the described variables, a similarity measure among visitor sessions is introduced and used in a clustering algorithm, which identifies groups of similar sessions, allowing the analysis of visitor behavior. In order to prove the methodology's effectiveness, it was applied in a certain Web site, showing the benefits of the described approach.
5EA18965	International Conference on Data Mining	hwanjo yu	2003	General MC: estimating boundary of positive class from small positive data	pattern classification + positive data set + feature space + support vector machines + character recognition + empirical analyses + learning artificial intelligence + classification boundary + unlabeled data + statistical analysis + learning (artificial intelligence) + general MC + single-class classification	AuthorProvided Keywords Not Found	Single-class classification (SCC) seeks to distinguish one class of data from the universal set of multiple classes. We propose a SCC method called general MC that estimates an accurate classification boundary of positive class from small positive data using the distribution of unlabeled data. Our theoretical and empirical analyses show that, as long as the distribution of unlabeled data is not highly skewed in the feature space, general MC significantly outperforms other recent SCC methods when the positive data set is highly under-sampled.
7FAC8BEA	International Conference on Data Mining	l de raedt + sau dan lee	2003	An algebra for inductive query evaluation	query processing + Boolean expression + inductive query evaluation + antimonotonic constraint + constraint theory + data mining + monotonic constraint + algebraic operation + boolean algebra + query plan optimization + Boolean algebra	AuthorProvided Keywords Not Found	Inductive queries are queries that generate pattern sets. We study properties of Boolean inductive queries, i.e. queries that are Boolean expressions over monotonic and antimonotonic constraints. More specifically, we introduce and study algebraic operations on the answer sets of such queries and show how these can be used for constructing and optimizing query plans. Special attention is devoted to the dimension of the queries, i.e. the minimum number of version spaces needed to represent the answer sets. The framework has been implemented for the pattern domain of strings and experimentally validated.
7DAE1C0A	International Conference on Data Mining	choh man teng	2003	Applying noise handling techniques to genomic data: a case study	Osteogenesis Imperfecta phenotype + data mining + diseases + information filters + genetic collagenous disease + noise handling technique + robust algorithm + genetics + amino acid sequence + proteins + noise + genomic data + medical computing + filtering + point mutation	AuthorProvided Keywords Not Found	Osteogenesis Imperfecta (OI) is a genetic collagenous disease associated with mutations in one or both of the genes COLIA1 and COLIA2. There are at least four known phenotypes of OI, of which type II is the severest and often lethal. We identified three approaches to noise handling, namely, robust algorithms, filtering, and polishing, and evaluated their effectiveness when applied to the problem of classifying the disease OI based on a data set of amino acid sequences and associated information of point mutations of COLIA1. Preliminary results suggest that each noise handling mechanism is useful under different circumstances. Filtering is stable across all cases. Pruning with robust c4.5 increased the classification accuracy in some cases, and polishing gave rise to some additional improvement in classifying the lethal OI phenotype.
5BCD511B	International Conference on Data Mining	haohsiang chung + hanshen huang + chunnan hsu	2003	The hybrid Poisson aspect model for personalized shopping recommendation	customer likelihood prediction + hybrid Poisson aspect model + personalized shopping recommendation + collaborative filtering + association rule + IBM SmartPad recommenders + purchasing + data mining + poisson distribution + retail supermarket + Poisson distribution + information filters + association rule mining + GroupLens recommenders + marketing + transaction data processing + transaction data + customers shopping + retail data processing	AuthorProvided Keywords Not Found	Predicting an individual customer's likelihood of purchasing a specific item forms the basis of many marketing activities, such as personalized shopping recommendation. Collaborative filtering and association rule mining can be applied to this problem, but in retail supermarkets, the problem becomes particularly challenging because of the sparsity and skewness of transaction data. We present HyPAM (hybrid Poisson aspect model), a new probabilistic graphical model that combines a Poisson mixture with a latent aspect class model to model customers' shopping behavior. We empirically compare HyPAM with two well-known recommenders, GroupLens (a correlation-based method), and IBM SmartPad (association rules and cosine similarity). Experimental results show that HyPAM outperforms the other recommenders by a large margin for two real-world retail supermarkets, ranking most of actual purchases in the top ten percent of the most likely purchased items. We also present a new visualization method, rank plot, to evaluate the quality of recommendations.
7F8898BB	International Conference on Data Mining	charis ermopoulos + tassos argyros	2003	Efficient subsequence matching in time series databases under time and amplitude transformations	query processing + similarity criterion + amplitude transformations + temporal databases + very large databases + time transformations + variable-length subsequence matching + time series + time series databases	AuthorProvided Keywords Not Found	Subsequence matching in large time series databases has attracted a lot of interest and many methods have been proposed that cope with this problem in an adequate extend. However, locating subsequence matches of arbitrary length, under time and amplitude transformations, has received far less attention and is still an open problem. We present an efficient algorithm for variable-length subsequence matching under transformations that guarantees no false dismissals. Further, this algorithm uses a novel similarity criterion for determining similarity under amplitude transformations in a most efficient way. Finally, our algorithm has been tested in various experiments on real data, resulting in a running time improvement of one order of magnitude compared to the naive approach.
7F3A0A73	International Conference on Data Mining	bing liu + xiaoli li + yang dai + wee sun lee + philip s yu	2003	Building text classifiers using positive and unlabeled examples	text analysis + pattern classification + text classifier + support vector machines + positive example + unlabeled example + Bayes methods + SVM + belief networks	AuthorProvided Keywords Not Found	We study the problem of building text classifiers using positive and unlabeled examples. The key feature of this problem is that there is no negative example for learning. Recently, a few techniques for solving this problem were proposed in the literature. These techniques are based on the same idea, which builds a classifier in two steps. Each existing technique uses a different method for each step. We first introduce some new methods for the two steps, and perform a comprehensive evaluation of all possible combinations of methods of the two steps. We then propose a more principled approach to solving the problem based on a biased formulation of SVM, and show experimentally that it is more accurate than the existing techniques.
7E2231A2	International Conference on Data Mining	chinghuang yun + mingsyan chen + kunta chuang	2003	Clustering item data sets with association-taxonomy similarity	real dataset + validation index + association-taxonomy similarity + data mining + indexation + data clustering + item data clustering + statistical analysis + association-taxonomy algorithm	AuthorProvided Keywords Not Found	We explore here the efficient clustering of item data. Different from those of the traditional data, the features of item data are known to be of high dimensionality and sparsity. In view of the features of item data, we devise here a novel measurement, called the association-taxonomy similarity, and utilize this measurement to perform the clustering. With this association-taxonomy similarity measurement, we develop an efficient clustering algorithm, called algorithm AT (standing for association-taxonomy), for item data. Two validation indexes based on association and taxonomy properties are also devised to assess the quality of clustering for item data. As validated by the real dataset, it is shown by our experimental results that algorithm AT devised here significantly outperforms the prior works in the clustering quality as measured by the validation indexes, indicating the usefulness of association-taxonomy similarity in item data clustering.
NE246	International Conference on Data Mining	T. Mielikainen	2003	Change profiles	pattern classification + data mining + pattern discovery + stability estimation + change profile + frequency estimation	AuthorProvided Keywords Not Found	We introduce a generalization of association rules: change profiles. We analyze their properties, describe their relationship to other structures in pattern discovery and sketch their possible applications. We study how the frequent patterns can be clustered based on their change profiles and propose methods for approximating the frequencies of the patterns from the approximate change profiles and bounding the intervals where the frequencies of the patterns are guaranteed to be. We evaluate empirically the methods for estimating the frequencies and the stability of their frequency estimates under different kinds of noise.
7F0AD8A9	International Conference on Data Mining	shoude lin + hans chalupsky	2003	Unsupervised link discovery in multi-relational data via rarity analysis	data analysis + data mining + information retrieval + knowledge discovery + relational databases + multirelational datasets + unsupervised learning + relational data + satisfiability + distributed databases + unsupervised link discovery method + data patterns + real-world bibliographic dataset + pattern recognition	AuthorProvided Keywords Not Found	"A significant portion of knowledge discovery and data mining research focuses on finding patterns of interest in data. Once a pattern is found, it can be used to recognize satisfying instances. The new area of link discovery requires a complementary approach, since patterns of interest might not yet be known or might have too few examples to be learnable. We present an unsupervised link discovery method aimed at discovering unusual, interestingly linked entities in multi-relational datasets. Various notions of rarity are introduced to measure the ""interestingness"" of sets of paths and entities. These measurements have been implemented and applied to a real-world bibliographic dataset where they give very promising results."
813E489A	International Conference on Data Mining	david bell + d y liu + j w guan	2003	The rough set approach to association rule mining	transaction processing + association rule + data mining + information retrieval + rough set + knowledge discovery + maximal association rule mining + rough set theory + association rule mining	AuthorProvided Keywords Not Found	In transaction processing, an association is said to exist between two sets of items when a transaction containing one set is likely to also contain the other. In information retrieval, an association between two sets of keywords occurs when they cooccur in a document. Similarly, in data mining, an association occurs when one attribute set occurs together with another. As the number of such associations may be large, maximal association rules are sought, e.g., Feldman et al. (1997, 1998). Rough set theory is a successful tool for data mining. By using this theory, rules similar to maximal associations can be found. However, we show that the rough set approach to discovering knowledge is much simpler than the maximal association method.
7D92B456	International Conference on Data Mining	amihood amir + nathan s netanyahu + reuven kashi + markus wawryniuk + daniel a keim	2003	Analyzing high-dimensional data by subspace validity	statistical tests + subspace validity + high dimensional data + feature extraction + image segmentation + statistical test + arbitrary shaped projected clusters + visual databases + real data sets + statistical testing + high-dimensional data analysis + noise levels	AuthorProvided Keywords Not Found	We are proposing a novel method that makes it possible to analyze high-dimensional data with arbitrary shaped projected clusters and high noise levels. At the core of our method lies the idea of subspace validity. We map the data in a way that allows us to test the quality of subspaces using statistical tests. Experimental results, both on synthetic and real data sets, demonstrate the potential of our method.
7D67A534	International Conference on Data Mining	qiang yang + hong cheng	2003	Mining plans for customer-class transformation	AUPlan algorithm + high frequency + data mining + empirical study + AI planning + Markov decision process algorithms + planning (artificial intelligence) + learning artificial intelligence + ai planning + customer-class transformation + markov processes + decision making + high-utility plan data mining + Markov processes + Apriori algorithm + learning (artificial intelligence)	AuthorProvided Keywords Not Found	We consider the problem of mining high-utility plans from historical plan databases that can be used to transform customers from one class to other, more desirable classes. Traditional data mining algorithms are focused on finding frequent sequences. But high frequency may not imply low costs and high benefits. Traditional Markov decision process (MDP) algorithms are designed to address this issue by bringing in the concept of utility, but these algorithms are also known to be expensive to execute. We present a novel algorithm AUPlan, which automatically generates sequential plans with high utility by combining data mining and AI planning. These high-utility plans could be used to convert groups of customers from less desirable states to more desirable ones. Our algorithm adapts the Apriori algorithm by considering the concepts of plans and utilities. We show through empirical studies that planning using our integrated algorithm produces high-utility plans efficiently.
59C4DCF3	International Conference on Data Mining	andrew w moore + jeremy kubica	2003	Probabilistic noise identification and data cleaning	corruption process + data model + probability + data mining + probabilistic noise identification + conformance testing + probabilistic model + gaussian noise + Gaussian noise + data cleaning + corrupted field identifying + noise value + generative model	AuthorProvided Keywords Not Found	Real world data is never as perfect as we would like it to be and can often suffer from corruptions that may impact interpretations of the data, models created from the data, and decisions made based on the data. One approach to this problem is to identify and remove records that contain corruptions. Unfortunately, if only certain fields in a record have been corrupted then usable, uncorrupted data will be lost. We present LENS, an approach for identifying corrupted fields and using the remaining noncorrupted fields for subsequent modeling and analysis. Our approach uses the data to learn a probabilistic model containing three components: a generative model of the clean records, a generative model of the noise values, and a probabilistic model of the corruption process. We provide an algorithm for the unsupervised discovery of such models and empirically evaluate both its performance at detecting corrupted fields and, as one example application, the resulting improvement this gives to a classifier.
7EC8396C	International Conference on Data Mining	ping chen + yves simon + chenyi hu + wei ding + heloise lynn	2003	Icon-based visualization of large high-dimensional datasets	graphical user interfaces + high dimensional data + icon visual properties + very large databases + data visualisation + knowledge acquisition + data analysts + high dimensional data record + icon-based visualization + summary icons + rendering (computer graphics) + high dimensional data visualization	AuthorProvided Keywords Not Found	High dimensional data visualization is critical to data analysts since it gives a direct view of original data. We present a method to visualize large amount of high dimensional data. We divide dimensions of data into several groups. Then, we use one icon to represent each group, and associate visual properties of each icon with dimensions in each group. A high dimensional data record will be represented by multiple different types of icons located in the same position. Furthermore, we use summary icons to display local details of viewer's interests and the whole data set at meantime. We show its effectiveness and efficiency through a case study on a real large data set.
80297F62	International Conference on Data Mining	kadri hacioglu + sameer pradhan + daniel jurafsky + wayne h ward + james h martin	2003	Semantic role parsing: adding semantic structure to unstructured text	classification problem + text analysis + pattern classification + unstructured text data + learning artificial intelligence + support vector machines + grammars + hand-labeled training set + computational linguistics + feature enhancements + shallow semantic parsing + learning (artificial intelligence)	AuthorProvided Keywords Not Found	There is an ever-growing need to add structure in the form of semantic markup to the huge amounts of unstructured text data now available. We present the technique of shallow semantic parsing, the process of assigning a simple WHO did WHAT to WHOM, etc., structure to sentences in text, as a useful tool in achieving this goal. We formulate the semantic parsing problem as a classification problem using support vector machines. Using a hand-labeled training set and a set of features drawn from earlier work together with some feature enhancements, we demonstrate a system that performs better than all other published results on shallow semantic parsing.
7FE6D3A9	International Conference on Data Mining	byunghoon park + gongxin yu + andrey a gorin + george ostrouchov + al geist + nagiza f samatova	2003	Inference of protein-protein interactions by unlikely profile pair	protein-profile pairs + protein protein interaction + bootstrapping approach + biology computing + protein interaction database + proteins + data mining + confidence level + InterPro profile pairs + statistical simulation + statistical analysis + protein-protein interactions	AuthorProvided Keywords Not Found	"We note that a set of statistically ""unusual"" protein-profile pairs in experimentally determined database of protein-protein interactions can typify protein-protein interactions, and propose a novel method called PICUPP that sifts such protein-profile pairs using a statistical simulation. It is demonstrated that unusual Pfam and InterPro profile pairs can be extracted from the DIP database using a bootstrapping approach. We particularly illustrate that such protein-profile pairs can be used for predicting putative pairs of interacting proteins. Their prediction accuracies are around 86% and 90% when InterPro and Pfam profiles are used, respectively at 75% confidence level."
7FAECD10	International Conference on Data Mining	dmitry pavlov	2003	Sequence modeling with mixtures of conditional maximum entropy distributions	first order + em algorithm + natural language processing + higher order + maximum entropy + mixture model + Markov model + maxent model + maximum entropy model + probabilistic model + hidden Markov models + conditional maximum entropy distribution + hidden markov models + learning artificial intelligence + optimisation + NLP + sequence modelling + global probabilistic model + markov model + natural languages + maximum entropy methods + learning (artificial intelligence) + EM algorithm + natural language	AuthorProvided Keywords Not Found	"We present a novel approach to modeling sequences using mixtures of conditional maximum entropy (maxent) distributions. Our method generalizes the mixture of first-order Markov models by including the ""long-term"" dependencies in model components. The ""long-term"" dependencies are represented by the frequently used in the natural language processing (NLP) domain probabilistic triggers or rules (such as ""A occurred k positions back""→""the current symbol is B"" with probability P). The maxent framework is then used to create a coherent global probabilistic model from all selected triggers. We enhance this formalism by using probabilistic mixtures with maxent models as components, thus representing hidden or unobserved effects in the data. We demonstrate how our mixture of conditional maxent models can be learned from data using the generalized EM algorithm that scales linearly in the dimensions of the data and the number of mixture components. We present empirical results on the simulated and real-world data sets and demonstrate that the proposed approach enables us to create better quality models than the mixtures of first-order Markov models and resist overfitting and curse of dimensionality that would inevitably present themselves for the higher order Markov models."
NE324	International Conference on Data Mining	B. Zhang	2003	Regression clustering	data mining + regression analysis + K-harmonic means clustering algorithm + complex distribution + real-world data + regression functions + statistical distributions + input variable selection + optimisation + pattern clustering + guiding function + regression clustering algorithm + response variables + statistical analysis + error statistics + regression residue error	AuthorProvided Keywords Not Found	Complex distribution in real-world data is often modeled by a mixture of simpler distributions. Clustering is one of the tools to reveal the structure of this mixture. The same is true to the datasets with chosen response variables that people run regression on. Without separating the clusters with very different response properties, the residue error of the regression is large. Input variable selection could also be misguided to a higher complexity by the mixture. In regression clustering (RC), K (>1) regression functions are applied to the dataset simultaneously which guide the clustering of the dataset into K subsets each with a simpler distribution matching its guiding function. Each function is regressed on its own subset of data with a much smaller residue error. Both the regressions and the clustering optimize a common objective function. We present a RC algorithm based on K-harmonic means clustering algorithm and compare it with other existing RC algorithms based on K-means and EM.
809FD559	International Conference on Data Mining	kevin w bowyer + robert e banfield + w p kegelmeyer + steven eschrich + divya bhadoria + lawrence o hall	2003	Comparing pure parallel ensemble creation techniques against bagging	pattern classification + statistical significance + training datasets + boosting + random processes + bagging + learning artificial intelligence + decision tree + decision-tree classifier + parallel ensemble creation techniques + randomization + decision trees + learning (artificial intelligence) + statistical testing	AuthorProvided Keywords Not Found	We experimentally evaluate randomization-based approaches to creating an ensemble of decision-tree classifiers. Unlike methods related to boosting, all of the eight approaches considered here create each classifier in an ensemble independently of the other classifiers. Experiments were performed on 28 publicly available datasets, using C4.5 release 8 as the base classifier. While each of the other seven approaches has some strengths, we find that none of them is consistently more accurate than standard bagging when tested for statistical significance.
7DF1EB07	International Conference on Data Mining	iftekhar ahmad + ruhul a sarker + joarder kamruzzaman	2003	SVM based models for predicting foreign currency exchange rates	splines (mathematics) + support vector machines + SVM based model + support vector machine + ARIMA based model + foreign currency exchange rate prediction + time series + economic forecasting + neural network + neural nets	AuthorProvided Keywords Not Found	Support vector machine (SVM) has appeared as a powerful tool for forecasting forex market and demonstrated better performance over other methods, e.g., neural network or ARIMA based model. SVM-based forecasting model necessitates the selection of appropriate kernel function and values of free parameters: regularization parameter and ε-insensitive loss function. We investigate the effect of different kernel functions, namely, linear, polynomial, radial basis and spline on prediction error measured by several widely used performance metrics. The effect of regularization parameter is also studied. The prediction of six different foreign currency exchange rates against Australian dollar has been performed and analyzed. Some interesting results are presented.
7F7EDA00	International Conference on Data Mining	shoji hirano + shusaku tsumoto	2003	Visualization of rule's similarity using multidimensional scaling	domain knowledge + data mining + data point + medical data set + rule induction method + knowledge discovery + medical information systems + rule based + medical expert systems + very large databases + data visualisation + large dataset + multidimensional scaling + two-dimensional cartesian coordinate + rule similarity visualization	AuthorProvided Keywords Not Found	One of the most important problems with rule induction methods is that it is very difficult for domain experts to check millions of rules generated from large datasets. The discovery from these rules requires deep interpretation from domain knowledge. Although several solutions have been proposed in the studies on data mining and knowledge discovery, these studies are not focused on similarities between rules obtained. When one rule r1 has reasonable features and the other rule r2 with high similarity to r1 includes unexpected factors, the relations between these rules will become a trigger to the discovery of knowledge. We propose a visualization approach to show the similar relations between rules based on multidimensional scaling, which assign a two-dimensional cartesian coordinate to each data point from the information about similarities between this data and others data. We evaluated this method on two medical data sets, whose experimental results show that knowledge useful for domain experts could be found.
7D8D5D57	International Conference on Data Mining	shakil ahmed + frans coenen + paul leng	2003	T-trees, vertical partitioning and distributed association rule mining	DATA-VP technique + distributed Apriori-T algorithm vertical partitioning + data mining + data structure + distributed processing + parallel association rule mining + tree data structures + tree data structure + distributed association rule mining + association rule mining	AuthorProvided Keywords Not Found	We consider a technique (DATA-VP) for distributed (and parallel) association rule mining that makes use of a vertical partitioning technique to distribute the input data, amongst processors. The proposed vertical partitioning is facilitated by a novel compressed set enumeration tree data structure (the T-tree), and an associated mining algorithm (Apriori-T), that allows for computationally effective distributed/parallel ARM when compared with existing approaches.
0B3AC1E9	International Conference on Data Mining	kewei chen + hongbin guo	2003	Clustering for three dimensional Kinetic PET Data	three dimensional + kinetics + hierarchical clustering		"

"
80006F63	International Conference on Data Mining	mitsunori ogihara + shenghuo zhu + tao li	2003	Using discriminant analysis for multi-class classification	pattern classification + discriminant analysis + support vector machines + SVM + machine learning problem + learning artificial intelligence + support vector machine + multiclass classification + benchmark dataset collection + multi class classification + discriminative feature transformation + statistical databases + learning (artificial intelligence) + pattern recognition + computational complexity	AuthorProvided Keywords Not Found	Discriminant analysis is known to learn discriminative feature transformations. We study its use in multiclass classification problems. The performance is tested on a large collection of benchmark datasets.
5EAB867F	International Conference on Data Mining	qinghua guo + maggi kelly + catherine h graham	2003	Predicting distribution of a new forest disease using one-class SVMs	ecological analysis + geographical information systems + support vector machines + oak trees + one-class SVM + geographic information systems + statistical distributions + data collection + cross-validation approach + ecology + predictive distribution + support vector machine + cross validation + California forest disease + oak + virulent pathogen + geographic information system + logistic regression + decision maker + potential distribution + forestry	AuthorProvided Keywords Not Found	In California, a newly discovered virulent pathogen (Phytophthora ramorum) has killed thousands of native oak trees. Mapping the potential distribution of the pathogen is essential for decision makers to assess the risk of the pathogen and aid in preventing its further spread. Most methods used to map potential ranges of species (e.g. multivariate or logistic regression) require both presence and absence data, the latter of which is not always feasibly collected. We present the one-class support vector machine (SVM) to predict the potential distribution of sudden oak death in California. The model was developed using presence data collected throughout the state, and tested for accuracy using a 5-fold cross-validation approach. The model performed well, and provided 91% predicted accuracy. We believe one-class SVM when coupled with geographical information systems (GIS) become a very useful method to deal with presence-only data in ecological analysis over a range of scales.
NE316	International Conference on Data Mining	D. A. Keim+C. Panse+M. Sips+North SC	2003	PixelMaps: a new visual data mining approach for analyzing large spatial data sets	spatial data set analysis + approximation theory + pixel-oriented display + data mining + visual databases + fast-PixelMap approximation + PixelMap algorithm + spatial data structures + quadtree synthesis + data visualisation + gridfile data structure + pixel-oriented visual data mining technique + kernel-density-based clustering + visual data mining + quadtrees	AuthorProvided Keywords Not Found	PixelMaps are a new pixel-oriented visual data mining technique for large spatial datasets. They combine kernel-density-based clustering with pixel-oriented displays to emphasize clusters while avoiding overlap in locally dense point sets on maps. Because a full evaluation of density functions is prohibitively expensive, we also propose an efficient approximation, Fast-PixelMap, based on a synthesis of the quadtree and gridfile data structures.
7EDA7309	International Conference on Data Mining	ahhwee tan + kanagasabai rajaraman	2003	Mining semantic networks for knowledge discovery	knowledge base + text analysis + rule-based algorithm + frame based representation + data mining + text documents + knowledge discovery + semantic network + content mining algorithms + rule based + networked knowledge base + knowledge based systems + semantic networks + semantic networks mining + text mining + concept frame graphs	AuthorProvided Keywords Not Found	We address the problem of mining a class of semantic networks, called concept frame graphs (CFG's), for knowledge discovery from text. This new representation is motivated by the need to capture richer text content so that nontrivial mining tasks can be performed. We first define the CFG representation and then describe a rule-based algorithm for constructing a CFG from text documents. Treating the CFG as a networked knowledge base, we propose new methods for text mining. On a specific task of discovering the top companies in an area, we observe that our approach leads to simpler content mining algorithms, once the CFG has been constructed. Moreover, exploiting the network structure of CFG results in significant improvements in precision and recall.
7EE041DD	International Conference on Data Mining	xingsen li + x sun + maria e orlowska	2003	Introducing uncertainty into pattern discovery in temporal event sequences	sequence database + precise support + temporal databases + telecommunication networks + data mining + telecommunication network fault analysis + pattern discovery + uncertainty handling + inaccurate event + uncertainty model + temporal event sequence + computational complexity	AuthorProvided Keywords Not Found	Pattern discovery in temporal event sequences is of great importance in many application domains, such as telecommunication network fault analysis. In reality, not every type of event has an accurate timestamp. Some of them, defined as inaccurate events may only have an interval as possible time of occurrence. The existence of inaccurate events may cause uncertainty in event ordering. The traditional support model cannot deal with this uncertainty, which would cause some interesting patterns to be missing. A new concept, precise support, is introduced to evaluate the probability of a pattern contained in a sequence. Based on this new metric, we define the uncertainty model and present an algorithm to discover interesting patterns in the sequence database that has one type of inaccurate event. In our model, the number of types of inaccurate events can be extended to k readily, however, at a cost of increasing computational complexity.
7F0A339D	International Conference on Data Mining	horianicolai teodorescu + lucian iulian fira	2003	A hybrid data-mining approach in genomics and text structures	data-mining approach + decision network + data mining + fuzzy neural nets + text structures + neuro fuzzy + genetic sequence identifier + neural network + hierarchical system + neuro-fuzzy predictors + genetics + biology computing + classic neural networks + decision making + fuzzy neural networks + genome sequence	AuthorProvided Keywords Not Found	We introduce a genetic sequence identifier based on a hierarchical system using fuzzy and classic (crisp) neural networks. The system is based on a set of predictors and on a decision network. The prediction of the structure of the genes is addressed using a new method and tools, involving the sequence of distances between bases and neuro-fuzzy predictors. The method and system have been successful in predicting genomic sequences and text structures.
7DFB87E1	International Conference on Data Mining	mikhail j atallah + wojciech szpankowski + robert gwadera	2003	Reliable detection of episodes in event sequences	event sequence + false alarm rate + pattern matching + security of data + monitoring system + probability + probabilistic + data mining + reliability + subsequence pattern detection + alarm threshold	AuthorProvided Keywords Not Found	"Suppose one wants to detect ""bad"" or ""suspicious"" subsequences in event sequences. Whether an observed pattern of activity (in the form of a particular subsequence) is significant and should be a cause for alarm, depends on how likely it is to occur fortuitously. A long enough sequence of observed events will almost certainly contain any subsequence, and setting thresholds for alarm is an important issue in a monitoring system that seeks to avoid false alarms. Suppose a long sequence T of observed events contains a suspicious subsequence pattern S within it, where the suspicious subsequence S consists of m events and spans a window of size w within T. We address the fundamental problem: is a certain number of occurrences of a particular subsequence unlikely to be fortuitous (i.e., indicative of suspicious activity)? If the probability of fortuitous occurrences is high and an automated monitoring system flags it as suspicious anyway, then such a system will suffer from generating too many false alarms. We quantify the probability of such an S occurring in T within a window of size w, the number of distinct windows containing S as a subsequence, the expected number of such occurrences, its variance, and establishes its limiting distribution that allows to set up an alarm threshold so that the probability of false alarms is very small. We report on experiments confirming the theory and showing that we can detect bad subsequences with low false alarm rate."
7FA47369	International Conference on Data Mining	fosca giannotti + francesco bonchi + dino pedreschi + alessio mazzanti	2003	ExAMiner: optimized level-wise frequent pattern mining with monotone constraints	optimized level-wise frequent pattern mining + frequency antimonotone constraint + optimisation + monotone constraints + pattern mining + constraint theory + very large databases + data mining + Apriori algorithm + search space + ExAMiner algorithm + ExAnte preprocessing algorithm	AuthorProvided Keywords Not Found	The key point is that, in frequent pattern mining, the most appropriate way of exploiting monotone constraints in conjunction with frequency is to use them in order to reduce the problem input together with the search space. Following this intuition, we introduce ExAMiner, a level-wise algorithm which exploits the real synergy of antimonotone and monotone constraints: the total benefit is greater than the sum of the two individual benefits. ExAMiner generalizes the basic idea of the preprocessing algorithm ExAnte [F. Bonchi et al., (2003)], embedding such ideas at all levels of an Apriori-like computation. The resulting algorithm is the generalization of the Apriori algorithm when a conjunction of monotone constraints is conjoined to the frequency antimonotone constraint. Experimental results confirm that this is, so far, the most efficient way of attacking the computational problem in analysis.
7E3AC263	International Conference on Data Mining	guizhen yang + i v ramakrishnan + saikat mukherjee	2003	On precision and recall of multi-attribute data extraction from semistructured sources	semistructured sources + learning artificial intelligence + data mining + multiattribute data extraction + complexity-theoretic aspects + Internet + machine learning + learning (artificial intelligence) + machine learning algorithms + internet + computational complexity	AuthorProvided Keywords Not Found	Machine learning techniques for data extraction from semistructured sources exhibit different precision and recall characteristics. However to date the formal relationship between learning algorithms and their impact on these two metrics remains unexplored. We propose a formalization of precision and recall of extraction and investigates the complexity-theoretic aspects of learning algorithms for multiattribute data extraction based on this formalism. We show that there is a tradeoff between precision/recall of extraction and computational efficiency and present experimental results to demonstrate the practical utility of these concepts in designing scalable data extraction algorithms for improving recall without compromising on precision.
7F1680E5	International Conference on Data Mining	shoji hirano + shusaku tsumoto	2003	Pattern discovery based on rule induction and taxonomy generation	medical expert systems + decision attribute characterization + data mining + expert decision process + pattern discovery + medical information systems + taxonomy generation + rough set theory + rule induction	AuthorProvided Keywords Not Found	One of the most important problems with rule induction methods is that they cannot extract rules, which plausibly represent expert's decision processes. Here, the characteristics of expert's rules are closely examined and a new approach to extract plausible rules is introduced, which consists of the following three procedures. First, the characterization of decision attributes (given classes) is extracted from databases and the concept hierarchy for given classes is calculated. Second, based on the hierarchy, rules for each hierarchical level are induced from data. Then, for each given class, rules for all the hierarchical levels are integrated into one rule.
8104AC4D	International Conference on Data Mining	mehmet kaya + reda alhajj	2003	Integrating fuzziness into OLAP for multidimensional fuzzy association rules mining	multidimensional fuzzy association rules mining + data mining + fuzzy set theory + fuzzy data cube + OLAP + knowledge discovery + data warehouses + association rule mining	AuthorProvided Keywords Not Found	We contribute to the ongoing research on multidimensional online association rules mining by proposing a general architecture that utilizes a fuzzy data cube for knowledge discovery. Three different methods are introduced to mine fuzzy association rules in the constructed fuzzy data cube, namely single dimension, multidimensional and hybrid association rules mining. Experimental results obtained for each of the three methods on the adult data of the United States census in 2000 show their effectiveness and applicability.
7D5A47FE	International Conference on Data Mining	kai ming ting + regina jing ying quek	2003	Model stability: a key factor in determining whether an algorithm produces an optimal model from a matching distribution	pattern classification + learning algorithm + learning artificial intelligence + test class distribution + matching distribution + optimal model + training class distribution + decision trees + Bayes methods + learning (artificial intelligence) + model stability	AuthorProvided Keywords Not Found	We investigate the factors leading to producing suboptimal models when training and test class distributions (or misclassification costs) are matched. Our result shows that model stability plays a key role in determining whether the algorithm produces an optimal model from a matching distribution (cost). The performance difference between a model trained from the matching distribution (cost) and the optimal model generally increases as the degree of model stability decreases. The practical implication of our result is that one should only follow the conventional wisdom of using a training class distribution (cost) that matches the test class distribution (cost) to train a classifier if the learning algorithm is known to be stable.
7EFD3E94	International Conference on Data Mining	yinghui yang + balaji padmanabhan	2003	Segmenting customer transactions using a pattern-based clustering approach	transaction processing + YACA technique + data mining + mixture model + customer relationship management + marketing + user-centric Web usage data + pattern-based clustering + transaction data + pattern clustering + customer loyalty + Internet + internet + customer transactions segmentation	AuthorProvided Keywords Not Found	"Grouping customer transactions into categories helps understand customers better. The marketing literature has concentrated on identifying important segmentation variables (e.g. customer loyalty) and on using clustering and mixture models for segmentation. The data mining literature has provided various clustering algorithms for segmentation. We investigate using ""pattern-based"" clustering approaches to grouping customer transactions. We argue that there are clusters in transaction data based on natural behavioral patterns, and present a new technique, YACA, that groups transactions such that itemsets generated from each cluster, while similar to each other, are different from ones generated from others. We present experimental results from user-centric Web usage data that demonstrates that YACA generates a highly effective clustering of transactions."
7F6841D5	International Conference on Data Mining	jin huang + jingjing lu + charles x ling	2003	Comparing naive Bayes, decision trees, and SVM with AUC and accuracy	support vector machines + receiver operating characteristics + sensitivity analysis + data mining + ROC + performance evaluation + SVM + receiver operating characteristic curve + data mining algorithm + decision tree + learning artificial intelligence + support vector machine + Naive Bayes method + naive bayes + accuracy prediction + decision trees + Bayes methods + learning (artificial intelligence)	AuthorProvided Keywords Not Found	Predictive accuracy has often been used as the main and often only evaluation criterion for the predictive performance of classification or data mining algorithms. In recent years, the area under the ROC (receiver operating characteristics) curve, or simply AUC, has been proposed as an alternative single-number measure for evaluating performance of learning algorithms. We proved that AUC is, in general, a better measure (defined precisely) than accuracy. Many popular data mining algorithms should then be reevaluated in terms of AUC. For example, it is well accepted that Naive Bayes and decision trees are very similar in accuracy. How do they compare in AUC? Also, how does the recently developed SVM (support vector machine) compare to traditional learning algorithms in accuracy and AUC? We will answer these questions. Our conclusions will provide important guidelines in data mining applications on real-world datasets.
5D2748CE	International Conference on Data Mining	mukaigaito takeya + hanaki miyoshi + kawamae noriaki	2003	Semantic log analysis based on a user query behavior model	thesauri + search engines + natural language processing + search engine + semantic Web + semantic web + data mining + thesaurus + behavior modeling + word processing + semantic log analysis + semantic word relation + Web search logs + Internet + user query behavior model + information needs + information need + query formulation + internet + ontology	AuthorProvided Keywords Not Found	We propose a novel log analysis method to capture the semantic relations among words appearing in Web search logs. Our method focuses on the reciprocal relations among a user's intentions, stages of information need, and query behavior in seeking information via a search engine. The approach works because it is based on the assumption that a user's intentions in each query can be derived as a model on the basis of his stage of information need and query behavior, through multiple empirical observations of search logs. The user's intentions drive user to change the words in each successive queries and can thus be used to clarify the semantic relations among words. As a result, this method has the advantage of capturing the semantic relations among words without requiring either manual or natural language processing. Our experimental results indicate that semantic relations could successfully be derived from search logs, confirming that an ontology and thesaurus could be constructed automatically.
810139CF	International Conference on Data Mining	hillol kargupta + souptik datta + k sivakumar + qi wang	2003	On the privacy preserving properties of random data perturbation techniques	random matrix + perturbation techniques + data perturbation technique + randomized data distortion technique + privacy-preserving data mining technique + data mining + matrix-based spectral filtering technique + random noise + data privacy + multiplicative noise + colored noise + random objects	AuthorProvided Keywords Not Found	"Privacy is becoming an increasingly important issue in many data mining applications. This has triggered the development of many privacy-preserving data mining techniques. A large fraction of them use randomized data distortion techniques to mask the data for preserving the privacy of sensitive data. This methodology attempts to hide the sensitive data by randomly modifying the data values often using additive noise. We question the utility of the random value distortion technique in privacy preservation. We note that random objects (particularly random matrices) have ""predictable"" structures in the spectral domain and it develops a random matrix-based spectral filtering technique to retrieve original data from the dataset distorted by adding random values. We present the theoretical foundation of this filtering method and extensive experimental results to demonstrate that in many cases random data distortion preserve very little data privacy. We also point out possible avenues for the development of new privacy-preserving data mining techniques like exploiting multiplicative and colored noise for preserving privacy in data mining applications."
7F903A1D	International Conference on Data Mining	j f yao + yongqiao xiao	2003	Efficient data mining for maximal frequent subtrees	FST-Forest data structure + PathJoin algorithm + tree structure + data mining + data structure + maximal frequent subtrees + candidate subtree generation + unordered labeled trees database + directed graphs + synthetic data + tree data structures + tree mining + synthetic data sets	AuthorProvided Keywords Not Found	A new type of tree mining is defined, which uncovers maximal frequent induced subtrees from a database of unordered labeled trees. A novel algorithm, PathJoin, is proposed. The algorithm uses a compact data structure, FST-Forest, which compresses the trees and still keeps the original tree structure. PathJoin generates candidate subtrees by joining the frequent paths in FST-Forest. Such candidate subtree generation is localized and thus substantially reduces the number of candidate subtrees. Experiments with synthetic data sets show that the algorithm is effective and efficient.
7E301C3B	International Conference on Data Mining	fabio a gonzalez + cesar cardona uribe + carlos rojas coronel + olfa nasraoui	2003	TECNO-STREAMS: tracking evolving clusters in noisy data streams with a scalable immune system learning model	user profile + TECNO-STREAMS approach + Web clickstream data + data mining + network theory + AIS + machine learning + associative memory + unsupervised learning + long term memory + somatic hypermutation + pattern clustering + artificial immune system model + immune system + cluster detection + dynamic environment + noisy data set + artificial immune system + pattern recognition	AuthorProvided Keywords Not Found	Artificial immune system (AIS) models hold many promises in the field of unsupervised learning. However, existing models are not scalable, which makes them of limited use in data mining. We propose a new AIS based clustering approach (TECNO-STREAMS) that addresses the weaknesses of current AIS models. Compared to existing AIS based techniques, our approach exhibits superior learning abilities, while at the same time, requiring low memory and computational costs. Like the natural immune system, the strongest advantage of immune based learning compared to other approaches is expected to be its ease of adaptation to the dynamic environment that characterizes several applications, particularly in mining data streams. We illustrate the ability of the proposed approach in detecting clusters in noisy data sets, and in mining evolving user profiles from Web clickstream data in a single pass. TECNO-STREAMS adheres to all the requirements of clustering data streams: compactness of representation, fast incremental processing of new data points, and clear and fast identification of outliers.
6C77F919	International Conference on Data Mining	jerome aze + michele sebag + noel lucas	2003	Impact studies and sensitivity analysis in medical data mining with ROC-based genetic learning	Atherosclerosis Identification problem + sensitivity analysis + data mining + medical information systems + genetic algorithms + machine learning + genetic algorithm + learning artificial intelligence + genetics + medical expert systems + ROC-based genetic learning + roc curve + learning (artificial intelligence) + machine learning algorithms + medical data mining	AuthorProvided Keywords Not Found	ROC curves have been used for a fair comparison of machine learning algorithms since the late 90's. Accordingly, the area under the ROC curve (AUC) is nowadays considered a relevant learning criterion, accommodating imbalanced data, misclassification costs and noisy data. We show how a genetic algorithm-based optimization of the AUC criterion can be exploited for impact studies and sensitivity analysis. The approach is illustrated on the Atherosclerosis Identification problem, PKDD 2002 Challenge.
7EACA813	International Conference on Data Mining	carlotta domeniconi + jing peng + peng zhang	2003	Dimensionality reduction using kernel pooled local discriminant information	pattern classification + learning artificial intelligence + dimensionality reduction + nearest neighbor + subspace representation + knowledge representation + nearest-neighbor rule + Fisher discriminant analysis + learning (artificial intelligence) + kernel principal component analysis + principal component analysis + kernel pooled local discriminant information	AuthorProvided Keywords Not Found	We study the use of kernel subspace methods for learning low-dimensional representations for classification. We propose a kernel pooled local discriminant subspace method and compare it against several competing techniques: generalized Fisher discriminant analysis (GDA) and kernel principal components analysis (KPCA) in classification problems. We evaluate the classification performance of the nearest-neighbor rule with each subspace representation. The experimental results demonstrate the efficacy of the kernel pooled local subspace method and the potential for substantial improvements over competing methods such as KPCA in some classification problems.
7FF29C7D	International Conference on Data Mining	kotagiri ramamohanarao + james bailey + thomas manoukian	2003	A fast algorithm for computing hypergraph transversals and its application in mining emerging patterns	computer science + graph theory + very large databases + data mining + minimisation + minimal hypergraph transversals + computational complexity + emerging patterns	AuthorProvided Keywords Not Found	Computing the minimal transversals of a hypergraph is an important problem in computer science that has significant applications in data mining. We present a new algorithm for computing hypergraph transversals and highlight their close connection to an important class of patterns known as emerging patterns. We evaluate our technique on a number of large datasets and show that it outperforms previous approaches by a factor of 9-29 times.
813A0754	International Conference on Data Mining	d v pavlov + c l giles + eren manavoglu	2003	Probabilistic user behavior models	Web users + Markov mixture models + prediction model + data mining + maximum entropy + probabilistic user behavior models + mixture model + CiteSeer data + user modelling + global model + behavior modeling + markov processes + online digital library + Markov processes + maximum entropy methods + Internet + statistical analysis + internet	AuthorProvided Keywords Not Found	We present a mixture model based approach for learning individualized behavior models for the Web users. We investigate the use of maximum entropy and Markov mixture models for generating probabilistic behavior models. We first build a global behavior model for the entire population and then personalize this global model for the existing users by assigning each user individual component weights for the mixture model. We then use these individual weights to group the users into behavior model clusters. We show that the clusters generated in this manner are interpretable and able to represent dominant behavior patterns. We conduct offline experiments on around two months worth of data from CiteSeer, an online digital library for computer science research papers currently storing more than 470,000 documents. We show that both maximum entropy and Markov based personal user behavior models are strong predictive models. We also show that maximum entropy based mixture model outperforms Markov mixture models in recognizing complex user behavior patterns.
7D053F8A	International Conference on Data Mining	haesun park + cheong hee park	2003	Efficient nonlinear dimension reduction for clustered data using kernel functions	support vector machines + feature space + data analysis + feature extraction + self-organising feature maps + data cluster + nonlinear dimension reduction method + kernel function + linear discriminant analysis + dimension reduction + principal component analysis + linear mapping	AuthorProvided Keywords Not Found	We propose a nonlinear feature extraction method which is based on centroids and kernel functions. The dimension reducing nonlinear transformation is obtained by implicitly mapping the input data into a feature space using a kernel function, and then finding a linear mapping based on an orthonormal basis of centroids in the feature space that maximally separates the between-class relationship. The proposed method utilizes an efficient algorithm to compute an orthonormal basis of centroids in the feature space transformed by a kernel function and achieves dramatic computational savings. The experimental results demonstrate that our method is capable of extracting nonlinear features effectively so that competitive performance of classification can be obtained in the reduced dimensional space.
80CF1BB3	International Conference on Data Mining	levon lloyd + steven skiena	2003	Parsing without a grammar: making sense of unknown file formats	text analysis + application program + whitespace character + bracketing delimiter symbol + symbol manipulation + structured file format + self delimiter character + hypermedia markup languages + word processing	AuthorProvided Keywords Not Found	The thousands of specialized structured file formats in use today present a substantial barrier to freely exchanging information between applications programs. We consider the problem of deducing such basic features as the whitespace characters, bracketing delimiter symbols, and self-delimiter characters of a given file format from one or more example files. We demonstrate that for sufficiently large example files, we can typically identify the basic features of interest.
7D182C84	International Conference on Data Mining	carlotta domeniconi + ning kang + daniel barbara	2003	Mining relevant text from unlabelled documents	document handling + search engines + sampling methods + document searching + search engine + data mining + information retrieval + relevant text + classification + information filters + unlabelled document classification + association rule mining + forensics + document filtering + class labels	AuthorProvided Keywords Not Found	Automatic classification of documents is an important area of research with many applications in the fields of document searching, forensics and others. Methods to perform classification of text rely on the existence of a sample of documents whose class labels are known. However, in many situations, obtaining this sample may not be an easy (or even possible) task. We focus on the classification of unlabelled documents into two classes: relevant and irrelevant, given a topic of interest. By dividing the set of documents into buckets (for instance, answers returned by different search engines), and using association rule mining to find common sets of words among the buckets, we can efficiently obtain a sample of documents that has a large percentage of relevant ones. This sample can be used to train models to classify the entire set of documents. We prove, via experimentation, that our method is capable of filtering relevant documents even in adverse conditions where the percentage of irrelevant documents in the buckets is relatively high.
7E8C0EB6	International Conference on Data Mining	stanley r m oliveira + osmar r zaiane	2003	Protecting sensitive knowledge by data sanitization	transaction processing + data sanitization + associative processing + very large databases + data mining + transactional databases + sensitive knowledge privacy protection + data privacy + strategic decisions + one-scan algorithm + association rule mining	AuthorProvided Keywords Not Found	We address the problem of protecting some sensitive knowledge in transactional databases. The challenge is on protecting actionable knowledge for strategic decisions, but at the same time not losing the great benefit of association rule mining. To accomplish that, we introduce a new, efficient one-scan algorithm that meets privacy protection and accuracy in association rule mining, without putting at risk the effectiveness of the data mining per se.
80C8ADB2	International Conference on Data Mining	einoshin suzuki + takeshi watanabe + hideto yokoi + katsuhiko takabayashi	2003	Detecting interesting exceptions from medical test data with visual summarization	chronic hepatitis data + probabilistic mixture model + irregular multidimensional time-series data + data mining + time series + mixture model + PrototypeLines display summarized information + probabilistic prototype sequence + interesting exception detection + medical test data + medical expert systems + visual summarization + data visualisation + iterative analysis + time series data	AuthorProvided Keywords Not Found	We propose a method which visualizes irregular multidimensional time-series data as a sequence of probabilistic prototypes for detecting exceptions from medical test data. Conventional visualization methods often require iterative analysis and considerable skill thus are not totally supported by a wide range of medical experts. Our PrototypeLines displays summarized information based on a probabilistic mixture model by using hue only thus is considered to exhibit novelty. The effectiveness of the summarization is pursued mainly through use of a novel information criterion. We report our endeavor with chronic hepatitis data, especially discoveries of interesting exceptions by a nonexpert and an untrained expert.
804392FF	International Conference on Data Mining	k h lee + tu minh phuong + doheon lee	2003	Regulatory element discovery using tree-structured models	regression tree + gene transcription + regression tree models + cellular process + tree structure + DNA sequences + Saccharomyces cerevisiae yeast + data mining + trees (mathematics) + regression analysis + putative motifs + dna sequence + genetics + biology computing + dna + DNA + predictor variables + regulatory element discovery + structural relationship + gene expression	AuthorProvided Keywords Not Found	Computational discovery of transcriptional regulatory regions in DNA sequences provides an efficient way to broaden our understanding of how cellular processes are controlled. We formulate the regulatory element discovery problem in the regression framework with regulatory regions treated as predictor variables and gene expression levels as responses. We use regression tree models to identify structural relationships between predictors and responses. The regression tree methodology is extended to handle multiple responses from different experiments by modifying the split function. We apply this method to two data sets of the yeast Saccharomyces cerevisiae. The method successfully identifies most of regulatory motifs that are known to control gene transcription under the given experimental conditions. Our method also suggests several putative motifs that present novel regulatory motifs.
670E0EB6	International Conference on Data Mining	jiawei han + wonyoung kim + youngkoo lee + y dora cai	2003	CoMine: efficient mining of correlated patterns	correlated pattern mining + data mining + disclose genuine correlation relationship + Apriori-based counterpart algorithm + pattern-growth methodology + statistical analysis + correlation methods + CoMine algorithm + association rule mining	AuthorProvided Keywords Not Found	Association rule mining often generates a huge number of rules, but a majority of them either are redundant or do not reflect the true correlation relationship among data objects. We re-examine this problem and show that two interesting measures, all-confidence (denoted as α) and coherence (denoted as γ), both disclose genuine correlation relationships and can be computed efficiently. Moreover, we propose two interesting algorithms, CoMine(α) and CoMine(γ), based on extensions of a pattern-growth methodology. Our performance study shows that the CoMine algorithms have high performance in comparison with their Apriori-based counterpart algorithms.
7E1AD97A	International Conference on Data Mining	jutta kreyss + steve selvaggio + michael shane white + zach zakharian	2003	Text mining for a clear picture of defect reports: a praxis report	document handling + quality management + software product review + data mining + quality improvement + portals + software quality category set + text mining + software quality + problem record categorization + IBM Enterprise Information Portal V8.1	AuthorProvided Keywords Not Found	We applied the text mining categorization technology, in the publicly available, IBM Enterprise Information Portal V8.1 to more than 15,000 customer reported, product problem records. We used a proven software quality category set to categorize these problem records into different areas of interest. Our intent was to develop a clear picture of potential areas for quality improvement in each of the software products reviewed, and to provide this information to development's management. We present the benefits that can be gained from categorizing problem records, as well as the limitations.
7DFE4257	International Conference on Data Mining	ravi janardan + jieping ye + haesun park + cheong hee park	2003	A new optimization criterion for generalized discriminant analysis on undersampled problems	GSVD algorithm + approximation theory + linear generalized discriminant analysis + discriminant analysis + data mining + undersampled problems + optimization criterion + structure-preserving dimension reduction + dimension reduction + optimisation + pattern clustering + generalized discriminant analysis + approximation algorithm + generalized singular value decomposition + statistical analysis + sample size + singular value decomposition + LDA algorithm + computational complexity	AuthorProvided Keywords Not Found	A new optimization criterion for discriminant analysis is presented. The new criterion extends the optimization criteria of the classical linear discriminant analysis (LDA) by introducing the pseudo-inverse when the scatter matrices are singular. It is applicable regardless of the relative sizes of the data dimension and sample size, overcoming a limitation of the classical LDA. Recently, a new algorithm called LDA/GSVD for structure-preserving dimension reduction has been introduced, which extends the classical LDA to very high-dimensional undersampled problems by using the generalized singular value decomposition (GSVD). The solution from the LDA/GSVD algorithm is a special case of the solution for our generalized criterion, which is also based on GSVD. We also present an approximate solution for our GSVD-based solution, which reduces computational complexity by finding subclusters of each cluster, and using their centroids to capture the structure of each cluster. This reduced problem yields much smaller matrices of which the GSVD can be applied efficiently. Experiments on text data, with up to 7000 dimensions, show that the approximation algorithm produces results that are close to those produced by the exact algorithm.
80FA8112	International Conference on Data Mining	man lung yiu + nikos mamoulis	2003	Frequent-pattern based iterative projected clustering	pattern clustering + hidden subspace + real data + data mining + synthetic data + projected cluster discovery + projected clustering algorithm + statistical analysis + frequent itemset mining	AuthorProvided Keywords Not Found	Irrelevant attributes add noise to high dimensional clusters and make traditional clustering techniques inappropriate. Projected clustering algorithms have been proposed to find the clusters in hidden subspaces. We realize the analogy between mining frequent itemsets and discovering the relevant subspace for a given cluster. We propose a methodology for finding projected clusters by mining frequent itemsets and present heuristics that improve its quality. Our techniques are evaluated with synthetic and real data; they are scalable and discover projected clusters accurately.
7DD18D43	International Conference on Data Mining	joseph m elble + cinda heeren + leonard pitt	2003	Optimized disjunctive association rules via sampling	association rule + sampling methods + cumulant + data mining + sampling + random sampling + performance degradation + polynomial time algorithm + optimisation + very large databases + cumulative confidence threshold + sample size + optimized disjunctive association rules	AuthorProvided Keywords Not Found	The problem of finding optimized support association rules for a single numerical attribute, where the optimized region is a union of k disjoint intervals from the range of the attribute, is investigated. The first polynomial time algorithm for the problem of finding such a region maximizing support and meeting a minimum cumulative confidence threshold is given. Because the algorithm is not practical, an ostensibly easier, more constrained version of the problem is considered. Experiments demonstrate that the best extant algorithm for the constrained version has significant performance degradation on both a synthetic model of patterned data and on real world data sets. Running the algorithm on a small random sample is proposed as a means of obtaining near optimal results with high probability. Theoretical bounds on sufficient sample size to achieve a given performance level are proved, and rapid convergence on synthetic and real-world data is validated experimentally.
806266CD	International Conference on Data Mining	ning zhong + yuefeng li	2003	Interpretations of association rules by granular computing	set theory + decision tables + granular computing + data mining + decision rule + association rule		"
This paper presents interpretations for association rules. It first introduces Pawlak's method, and the corresponding algorithm of finding decision rules (a kind of association rules). It then uses extended random sets to present a new algorithm of finding interesting rules. It proves that the new algorithm is faster than Pawlak's algorithm. The extended random sets are easily to include more than one criterion for determining interesting rules. They also provide two measures for dealing with uncertainties in association rules.
"
803E6C09	International Conference on Data Mining	c h lin + c f chang + h y chen + jyhjong tsay	2003	Enhancing techniques for efficient topic hierarchy integration	document handling + data sources + support vector machines + data set + world wide web + document integration + information sources + support vector machine + Naive Bayes method + World-Wide Web + naive bayes + Bayes methods + categorization information + Web sites	AuthorProvided Keywords Not Found	Here, we study the problem of integrating documents from different sources into a comprehensive topic hierarchy. Our objective is to develop efficient techniques that improve the accuracy of traditional categorization methods by incorporating categorization information provided by data sources into categorization process. Notice that in the World-Wide Web, categorization information is often available from information sources. We present several enhancing techniques that use categorization information to enhance traditional methods such as naive Bayes and support vector machines. Experiment on collections from Openfind and Yam, and Google and Yahoo!, well-known popular Web sites in Taiwan and USA, respectively, shows that our techniques significantly improve the classification accuracy from, for example, 55% to 66% for Naive Bayes, and from 57% to 67% for SVM for the data set collected from Yam and Openfind.
7F4EB02D	International Conference on Data Mining	jennifer neville + brian gallagher + david jensen	2003	Simple estimators for relational Bayesian classifiers	INDEPVAL + estimation theory + prediction model + estimation technique + relational Bayesian classifiers + relational databases + multiset information + relational data + learning artificial intelligence + relational data sets + bayesian classifier + belief networks + learning (artificial intelligence)	AuthorProvided Keywords Not Found	We present the relational Bayesian classifier (RBC), a modification of the simple Bayesian classifier (SBC) for relational data. There exist several Bayesian classifiers that learn predictive models of relational data, but each uses a different estimation technique for modelling heterogeneous sets of attribute values. The effects of data characteristics on estimation have not been explored. We consider four simple estimation techniques and evaluate them on three real-world data sets. The estimator that assumes each multiset value is independently drawn from the same distribution (INDEPVAL) achieves the best empirical results. We examine bias and variance tradeoffs over a range of data sets and show that INDEPVAL's ability to model more multiset information results in lower bias estimates and contributes to its superior performance.
7D695CDB	International Conference on Data Mining	yuchang lu + hongwei zhang + fengzhan tian	2003	Learning Bayesian networks from incomplete data based on EMI method	bayesian network + dependency analysis based learning algorithm + estimation theory + Alarm network + EM-EA algorithm + convex combination + data mining + missing data + SEM algorithm + general-duty method + variable set + point estimation + learning artificial intelligence + conditional mutual information estimation + joint probability + mutual information + real world data mining application + belief networks + learning (artificial intelligence) + EMI method + point estimates + probability + extreme point + interval estimation + Bayesian network learning + directed graphs + dependence analysis + search & scoring based algorithm + incomplete data	AuthorProvided Keywords Not Found	Currently, there are few efficient methods in practice for learning Bayesian networks from incomplete data, which affects their use in real world data mining applications. We present a general-duty method that estimates the (conditional) mutual information directly from incomplete datasets, EMI. EMI starts by computing the interval estimates of a joint probability of a variable set, which are obtained from the possible completions of the incomplete dataset. And then computes a point estimate via a convex combination of the extreme points, with weights depending on the assumed pattern of missing data. Finally, based on these point estimates, EMI gets the estimated (conditional) mutual information. We also apply EMI to the dependency analysis based learning algorithm by J. Cheng so as to efficiently learn BNs with incomplete data. The experimental results on Asia and Alarm networks show that EMI based algorithm is much more efficient than two search & scoring based algorithms, SEM and EM-EA algorithms. In terms of accuracy, EMI based algorithm is more accurate than SEM algorithm, and comparable with EM-EA algorithm.
7D2742D8	International Conference on Data Mining	j m petit + f de marchi	2003	Zigzag: a new algorithm for mining large inclusion dependencies in databases	query processing + Zigzag algorithm + data semantics + satisfiability + data mining + relational model + relational databases + inclusion dependencies + maximal frequent itemsets mining	AuthorProvided Keywords Not Found	In the relational model, inclusion dependencies (INDs) convey many information on data semantics. They generalize foreign keys, which are very popular constraints in practice. However, one seldom knows the set of satisfied INDs in a database. The IND discovery problem in existing databases can be formulated as a data-mining problem. We underline that the exploration of IND expressions from most general (smallest) INDs to most specific (largest) INDs does not succeed whenever large INDs have to be discovered. To cope with this problem, we introduce a new algorithm, called Zigzag, which combines the strength of levelwise algorithms (to find out some smallest INDs) with an optimistic criteria to jump more or less to largest INDs. Preliminary tests, on synthetic databases, are presented and commented on. It is worth noting that the main result is general enough to be applied to other data-mining problems, such as maximal frequent itemsets mining.
8008B21C	International Conference on Data Mining	tobias scheffer + marka krogel	2003	Effectiveness of information extraction, multi-relational, and semi-supervised learning for predicting functional properties of genes	semi supervised learning + semisupervised learning + data mining + information retrieval + relational databases + relational data + learning artificial intelligence + information extraction + multirelational data + yeast genome + propositionalization approach + relational gene interaction data + co-training + gene functional property prediction + unlabeled data + learning (artificial intelligence)	AuthorProvided Keywords Not Found	We focus on the problem of predicting functional properties of the proteins corresponding to genes in the yeast genome. Our goal is to study the effectiveness of approaches that utilize all data sources that are available in this problem setting, including unlabeled and relational data, and abstracts of research papers. We study transduction and co-training for using unlabeled data. We investigate a propositionalization approach which uses relational gene interaction data. We study the benefit of information extraction for utilizing a collection of scientific abstracts. The studied tasks are KDD Cup tasks of 2001 and 2002. The solutions which we describe achieved the highest score for task 2 in 2001, the fourth rank for task 3 in 2001, the highest score for one of the two subtasks and the third place for the overall task 2 in 2002.
7D206B3E	International Conference on Data Mining	raz tamir + reinhard rapp	2003	Mining the Web to discover the meanings of an ambiguous word	text analysis + web pages + computational linguistics + data mining + information retrieval + ambiguous word meanings + word co-occurrence + contemporary word meanings + confidence gain approach + Web pages + word sense induction + natural languages + text mining + Internet + internet	AuthorProvided Keywords Not Found	In information retrieval and text mining, information on word senses is usually taken from dictionaries or lexical databases that have been prepared by lexicographers. We propose an automatic method for word sense induction, i.e. for the discovery of a set of sense descriptors to a given ambiguous word. The approach is based on the statistics of word co-occurrence as derived from Web pages. The underlying assumption is that the senses of an ambiguous word are best described by terms that, although bearing a strong association to this word, are mutually exclusive, i.e. whose association strength within the retrieved Web pages is as weak as possible. Measuring association strength is based upon a novel confidence gain approach that relates the observed co-occurrence frequency for two sense descriptor candidates to an average co-occurrence frequency for pairs of arbitrary words. The proposed approach is fully unsupervised and takes into account the contemporary meanings of words, as reflected in texts from the Internet. Our results are evaluated using a list of ambiguous words commonly referred to in the literature.
7E946CC8	International Conference on Data Mining	pei sun + sanjay chawla + robert munro	2003	Complex spatial relationships	spatial data + complex relationship + multifeature colocation + data mining + visual databases + one-to-many relationship + spatial relationships + statistical analysis + weak monotonic property + self colocation	AuthorProvided Keywords Not Found	We describe the need for mining complex relationships in spatial data. Complex relationships are defined as those involving two or more of: multifeature colocation, self-colocation, one-to-many relationships, self-exclusion and multifeature exclusion. We demonstrate that even in the mining of simple relationships, knowledge of complex relationships is necessary to accurately calculate the significance of results. We implement a representation of spatial data such that it contains known 'weak-monotonic' properties, which are exploited for the efficient mining of complex relationships, and discuss the strengths and limitations of this representation.
814F5323	International Conference on Data Mining	olli virmajoki + pasi franti + ville hautamaki	2003	Fast PNN-based clustering using k-nearest neighbor graph	pairwise nearest neighbor + graph theory + search problem + k-nearest neighbor graph + nearest neighbor graph + vector quantisation + PNN + agglomerative clustering algorithm + nearest neighbor + k nearest neighbor + vector quantization + statistical analysis + search problems	AuthorProvided Keywords Not Found	Search for nearest neighbor is the main source of computation in most clustering algorithms. We propose the use of nearest neighbor graph for reducing the number of candidates. The number of distance calculations per search can be reduced from O(N) to O(k) or where N is the number of clusters, and k is the number of neighbors in the graph. We apply the proposed scheme within agglomerative clustering algorithm known as the PNN algorithm.
805270FD	International Conference on Data Mining	hongjun lu + zheng chen + weiying ma + xuanhui wang + huajun zeng	2003	CBC: clustering based text classification requiring minimal labeled data	semi supervised learning + clustering based text classification + pattern classification + minimal labeled data + learning artificial intelligence + support vector machines + pattern clustering + semisupervised learning + transductive support vector machines + discriminative classifiers + learning (artificial intelligence) + maximum likelihood estimation	AuthorProvided Keywords Not Found	Semisupervised learning methods construct classifiers using both labeled and unlabeled training data samples. While unlabeled data samples can help to improve the accuracy of trained models to certain extent, existing methods still face difficulties when labeled data is not sufficient and biased against the underlying data distribution. We present a clustering based classification (CBC) approach. Using this approach, training data, including both the labeled and unlabeled data, is first clustered with the guidance of the labeled data. Some of unlabeled data samples are then labeled based on the clusters obtained. Discriminative classifiers can subsequently be trained with the expanded labeled dataset. The effectiveness of the proposed method is justified analytically. Our experimental results demonstrated that CBC outperforms existing algorithms when the size of labeled dataset is very small.
7FD0020D	International Conference on Data Mining	z sun + ronald miller + george bebis	2003	Evolutionary Gabor filter optimization with application to vehicle detection	optimization problem + parameter space + average filter + gray-scale image + object detection + EGFO + SVM + filter bank + genetic algorithm + incremental clustering approach + image segmentation + feature extraction + GA + genetic operator + pattern classification + support vector machines + filtering theory + genetic algorithms + filter design + global optimization approach + global optimization + vehicle detection + redundant filter elimination + support vector machine + Gabor filter optimization + computer vision + traditional filter bank + automated highways + application-oriented fitness criterion	AuthorProvided Keywords Not Found	Despite the considerable amount of research work on the application of Gabor filters in pattern classification, their design and selection have been mostly done on a trial and error basis. Existing techniques are either only suitable for a small number of filters or less problem-oriented. A systematic and general evolutionary Gabor filter optimization (EGFO) approach that yields a more optimal, problem-specific, set of filters is proposed in this study. The EGFO approach unifies filter design with filter selection by integrating genetic algorithms (GAs) with an incremental clustering approach. Specifically, filter design is performed using GAs, a global optimization approach that encodes the parameters of the Gabor filters in a chromosome and uses genetic operators to optimize them. Filter selection is performed by grouping together filters having similar characteristics (i.e., similar parameters) using incremental clustering in the parameter space. Each group of filters is represented by a single filter whose parameters correspond to the average parameters of the filters in the group. This step eliminates redundant filters, leading to a compact, optimized set of filters. The average filters are evaluated using an application-oriented fitness criterion based on support vector machines (SVMs). To demonstrate the effectiveness of the proposed framework, we have considered the challenging problem of vehicle detection from gray-scale images. Our experimental results illustrate that the set of Gabor filters, specifically optimized for the problem of vehicle detection, yield better performance than using traditional filter banks.
806F1462	International Conference on Data Mining	otman basir + hongwei zhu	2003	A K-NN associated fuzzy evidential reasoning classifier with adaptive neighbor selection	adaptive neighbor selection + pattern classification + fuzzy set + Dempster-Shafer evidence theory + case based reasoning + evidential reasoning + fuzzy set theory + K-nearest neighbor algorithm + training sample space + uncertainty handling + contextual information + fuzzy evidential reasoning classifier + learning artificial intelligence + nearest neighbor + k nearest neighbor + dempster shafer + case-based reasoning + learning (artificial intelligence) + feature selection + multichannel remote sensing images	AuthorProvided Keywords Not Found	We present a fuzzy evidential reasoning algorithm in light of the Dempster-Shafer evidence theory and the K-nearest neighbor algorithm for pattern classification. Given an input pattern to be classified, each of its K nearest neighbors is viewed as an evidence source, in terms of a fuzzy evidence structure. The distance between the input pattern and each of its K nearest neighbors is used for mass determination while the contextual information of the nearest neighbor in the training sample space is formulated by a fuzzy set in determining a fuzzy focal element. Therefore, pooling evidence provided by neighbors is realized by a fuzzy evidential reasoning, where feature selection is further considered through ranking and adaptive combination of neighbors. A fast implementation scheme of the fuzzy evidential reasoning is also developed. Experimental results of classifying multichannel remote sensing images have shown that the proposed approach outperforms the K-nearest neighbor (K-NN) algorithm [T.M. Cover et al. (1967)], the fuzzy K-nearest neighbor (F-KNN) algorithm [J.M. Keller et al. (1985)], the evidence-theoretic K-nearest neighbor (E-KNN) algorithm [T. Denoex (1995)], and the fuzzy extended version of E-KNN (FE-KNN) [L.M. Zouhal et al. (1997)], in terms of the classification accuracy and insensitivity to the number K of nearest neighbors.
7DA56EAB	International Conference on Data Mining	mike sips + christian panse + daniel a keim + stephen c north	2003	PixelMaps: a new visual data mining approach for analyzing large spatial data sets	approximation theory + data visualisation + spatial data + kernel density + data structure + data mining		"
PixelMaps are a new pixel-oriented visual data mining technique for large spatial datasets. They combine kerneldensity-based clustering with pixel-oriented displays to emphasize clusters while avoiding overlap in locally dense point sets on maps. Because a full evaluation of density functions is prohibitively expensive, we also propose an efficient approximation, Fast-PixelMap, based on a synthesis of the quadtree and gridfile data structures.
"
7DAF4FF2	International Conference on Data Mining	lemuel r waitman + paul h king + douglas fisher	2003	Bootstrapping rule induction	data mining + domain expert + perioperative data + rule induction + point estimation + learning artificial intelligence + computer bootstrapping + accuracy-point estimate + training data + continuous attribute decision boundary + rule learning system + learning (artificial intelligence) + multiple bootstrap replication	AuthorProvided Keywords Not Found	Most rule learning systems posit hard decision boundaries for continuous attributes and point estimates of rule accuracy, with no measures of variance, which may seem arbitrary to a domain expert. These hard boundaries/points change with small perturbations to the training data. Moreover, rule induction typically produces a large number of rules that must be filtered and interpreted by an analyst. We describe a method of combining rules over multiple bootstrap replications of rule induction so as to reduce the total number of rules presented to an analyst and to provide measures of variance to continuous attribute decision boundaries and accuracy-point estimates. The method is illustrated with perioperative data.
7CF3C13F	International Conference on Data Mining	rohini k srihari + zhaohui zheng + sargur n srihari	2003	A feature selection framework for text filtering	chi-square metric + text analysis + data mining + feature set + text filtering + feature selection method + feature extraction + odd ratio + statistical analysis + GSS coefficient + correlation coefficient + feature selection + correlation methods	AuthorProvided Keywords Not Found	We present a new framework for local feature selection in text filtering. In this framework, a feature set is constructed per category by first selecting a set of terms highly indicative of membership (positive set) and another set of terms highly indicative of nonmembership (negative set), and then combining these two sets. This feature selection framework not only unifies several standard feature selection methods, but also facilitates the proposal of a new method that optimally combines the positive and negative sets. The experimental comparison between the proposed method and standard methods was conducted on six feature selection metrics: chi-square, correlation coefficient, odds ratio, GSS coefficient and two proposed variants of odds ratio and GSS coefficient: OR-square and GSS-square respectively. The results show that the proposed feature selection method improves text filtering performance.
5B624317	International Conference on Data Mining	einat neumann + saharon rosset	2003	Integrating customer value considerations into predictive modeling	data analysis + prediction model + customer value data + data mining + regression analysis + telecommunication + telecommunication computing + customer relationship management + telecommunications + learning artificial intelligence + optimisation + customer value consideration integration + predictive modeling + learning (artificial intelligence) + churn modelling + nondecayed customer value data	AuthorProvided Keywords Not Found	"The success of prediction models for business purposes should not be measured by their accuracy only. Their evaluation should also take into account the higher importance of precise prediction for ""valuable"" customers. We illustrate this idea through the example of churn modelling in telecommunications, where it is obviously much more important to identify potential churn among valuable customers. We discuss, both theoretically and empirically, the optimal use of ""customer value"" data in the model training, model evaluation and scoring stages. Our main conclusion is that a nontrivial approach of using ""decayed"" value-weights for training is usually preferable to the two obvious approaches of either using nondecayed customer values as weights or ignoring them."
7E780DF0	International Conference on Data Mining	p krishna reddy + rajat kumar gupta + b v l narayana + g rama murthy + y v r reddy + c l l gowda + g v ranga rao	2003	Understanding Helicoverpa armigera pest population dynamics related to chickpea crop using neural networks	pest surveillance data set + chickpea crop + data mining + Helicoverpa armigera pest population dynamics + neural networks + crops + pest management + population dynamic + neural network + pest attack incidence + pest control + statistical analysis + neural nets + Pod borer	AuthorProvided Keywords Not Found	Insect pests are a major cause of crop loss globally. Pest management will be effective and efficient if we can predict the occurrence of peak activities of a given pest. Research efforts are going on to understand the pest dynamics by applying analytical and other techniques on pest surveillance data sets. We make an effort to understand pest population dynamics using neural networks by analyzing pest surveillance data set of Helicoverpa armigera or Pod borer on chickpea (Cicer arietinum L.) crop. The results show that neural network method successfully predicts the pest attack incidences for one week in advance.
7EC5384F	International Conference on Data Mining	jeonghee yi + wayne niblack + tetsuya nasukawa + razvan bunescu	2003	Sentiment analyzer: extracting sentiments about a given topic using natural language processing techniques	text analysis + feature term extraction + natural language processing + sentiment analysis + computational linguistics + sentiment pattern database + feature extraction + natural languages + sentiment extraction + Internet + sentiment lexicon + internet + online text documents + sentiment analyzer	AuthorProvided Keywords Not Found	"We present sentiment analyzer (SA) that extracts sentiment (or opinion) about a subject from online text documents. Instead of classifying the sentiment of an entire document about a subject, SA detects all references to the given subject, and determines sentiment in each of the references using natural language processing (NLP) techniques. Our sentiment analysis consists of 1) a topic specific feature term extraction, 2) sentiment extraction, and 3) (subject, sentiment) association by relationship analysis. SA utilizes two linguistic resources for the analysis: the sentiment lexicon and the sentiment pattern database. The performance of the algorithms was verified on online product review articles (""digital camera"" and ""music"" reviews), and more general documents including general Webpages and news articles."
7F346008	International Conference on Data Mining	chris h q ding + hanchuan peng	2003	Structure search and stability enhancement of Bayesian networks	bayesian network + structure perturbation + Bayesian network structure learning + data mining + candidate graph + cut-edge repairing + minimal likelihood loss + learning artificial intelligence + parent search method + very large databases + large-scale data sets + belief networks + learning (artificial intelligence) + stability enhancement method + search problems + computational complexity	AuthorProvided Keywords Not Found	Learning Bayesian network structure from large-scale data sets, without any expert-specified ordering of variables, remains a difficult problem. We propose systematic improvements to automatically learn Bayesian network structure from data. (1) We propose a linear parent search method to generate candidate graph. (2) We propose a comprehensive approach to eliminate cycles using minimal likelihood loss, a short cycle first heuristic, and a cut-edge repairing. (3) We propose structure perturbation to assess the stability of the network and a stability-improvement method to refine the network structure. The algorithms are easy to implement and efficient for large networks. Experimental results on two data sets show that our new approach outperforms existing methods.
7E77E6FC	International Conference on Data Mining	fabrice guillet + julien blanchard + henri briand	2003	A user-driven and quality-oriented visualization for mining association rules	association rule + knowledge validation + interactive rule subset focusing + data mining algorithms + data mining + association rule discovery process + information retrieval + rule rummaging task + user interfaces + quality-oriented visualization + association rule validation problem + very large databases + decision-making + data visualisation + decision making + human-centered visualization method + interactive systems + experimental prototype ARVis + rule interestingness measures + intelligibility	AuthorProvided Keywords Not Found	On account of the enormous amounts of rules that can be produced by data mining algorithms, knowledge validation is one of the most problematic steps in an association rule discovery process. In order to find relevant knowledge for decision-making, the user needs to really rummage through the rules. Visualization can be very beneficial to support him/her in this task by improving the intelligibility of the large rule sets and enabling the user to navigate inside them. We propose to answer the association rule validation problem by designing a human-centered visualization method for the rule rummaging task. This new approach based on a specific rummaging model relies on rule interestingness measures and on interactive rule subset focusing and mining. We have implemented our representation by developing a first experimental prototype called ARVis.
58E22613	International Conference on Data Mining	andrew w moore + jeff schneider + jeremy kubica	2003	Tractable group detection on large link data sets	probabilistic generative model + co-occurrence data + data mining + probability + maximum likelihood estimation + human resource + probabilistic model + k-group algorithm + learning artificial intelligence + very large databases + large link data set + group detection algorithm + k means + belief networks + learning (artificial intelligence) + linked data	AuthorProvided Keywords Not Found	Discovering underlying structure from co-occurrence data is an important task in a variety of fields, including: insurance, intelligence, criminal investigation, epidemiology, human resources, and marketing. Previously Kubica et al. presented the group detection algorithm (GDA) - an algorithm for finding underlying groupings of entities from co-occurrence data. This algorithm is based on a probabilistic generative model and produces coherent groups that are consistent with prior knowledge. Unfortunately, the optimization used in GDA is slow, potentially making it infeasible for many large data sets. To this end, we present k-groups - an algorithm that uses an approach similar to that of k-means to significantly accelerate the discovery of groups while retaining GDA's probabilistic model. We compare the performance of GDA and k-groups on a variety of data, showing that k-groups' sacrifice in solution quality is significantly offset by its increase in speed.
7F501253	International Conference on Data Mining	ishwar k sethi + mingkun li + shuo feng + jason luciow + keith wagner	2003	Mining production data with neural network & CART	machine reading + sensitivity analysis + production data mining + regression tree modelling + data mining + regression analysis + production engineering computing + variable analysi + glass industry + neural network + neural nets + coated glass manufacturing	AuthorProvided Keywords Not Found	We present the preliminary results of a data mining study of a production line involving hundreds of variables related to mechanical, chemical, electrical and magnetic processes involved in manufacturing coated glass. The study was performed using two nonlinear, nonparametric approaches, namely neural network and CART, to model the relationship between the qualities of the coating and machine readings. Furthermore, neural network sensitivity analysis and CART variable rankings were used to gain insight into the coating process. Our initial results show the promise of data mining techniques to improve the production.
7F193CE5	International Conference on Data Mining	kwongsak leung + manleung wong + huidong jin	2003	Scalable model-based clustering by working on data summaries	em algorithm + expectation-maximization algorithm + data mining + EM + data summarization procedures + covariance information + two-phase scalable model-based clustering + bEMADS + Gaussian mixture model + gEMADS + gaussian processes + clustering system + pattern clustering + very large databases + Gaussian processes + covariance analysis + expectation maximization + large databases + computational complexity	AuthorProvided Keywords Not Found	The scalability problem in data mining involves the development of methods for handling large databases with limited computational resources. We present a two-phase scalable model-based clustering framework: first, a large data set is summed up into subclusters; Then, clusters are directly generated from the summary statistics of subclusters by a specifically designed expectation-maximization (EM) algorithm. Taking example for Gaussian mixture models, we establish a provably convergent EM algorithm, EMADS, which embodies cardinality, mean, and covariance information of each subcluster explicitly. Combining with different data summarization procedures, EMADS is used to construct two clustering systems: gEMADS and bEMADS. The experimental results demonstrate that they run several orders of magnitude faster than the classic EM algorithm with little loss of accuracy. They generate significantly better results than other model-based clustering systems using similar computational resources.
594E3D67	International Conference on Data Mining	shakil m khan + aijun an + xiangji huang	2003	Objective and subjective algorithms for grouping association rules	association rule + automatically tagged semantic tree-structured network + tree structure + data mining + semantic networks + association rules + subjective grouping algorithm + tree data structures + objective grouping algorithm + computational complexity + association rule mining + semantic distance	AuthorProvided Keywords Not Found	We propose two algorithms for grouping and summarizing association rules. The first algorithm recursively groups rules according to the structure of the rules and generates a tree of clusters as a result. The second algorithm groups the rules according to the semantic distance between the rules by making use of an automatically tagged semantic tree-structured network of items. We provide a case study in which the proposed algorithms are evaluated. The results show that our grouping methods are effective and produce good grouping results.
7E5BC442	International Conference on Data Mining	stefan antonius schmitz + frank dellmann + holger wulff	2003	Findings from a practical project concerning Web usage mining	semantic Web + semantic web + data understanding + data mining + user interfaces + Web log files + practical project + web usage mining + Web usage mining + e-metrics + data preprocessing phase + statistical analysis + Web sites	AuthorProvided Keywords Not Found	In a practical project a statistical analysis of the Web log files of the domain www.volkswagen.de was carried out by using the CRISP-DM procedure. For the preprocessing phase, more profound findings could be gained than are usually described in many studies. Since the aim was to deduce significant statements while measuring the effect, tests of significance for e-metrics were used in addition to the commonly described procedure.
80288F46	International Conference on Data Mining	vipin kumar + pangning tan + hui xiong	2003	Mining strong affinity association patterns in data sets with skewed support distribution	pattern clustering + skewed support distribution + very large databases + h-confidence measure + data mining + hyperclique pattern clustering + support-based pruning strategy + search space + strong affinity association pattern mining + association rule mining	AuthorProvided Keywords Not Found	Existing association-rule mining algorithms often rely on the support-based pruning strategy to prune its combinatorial search space. This strategy is not quite effective for data sets with skewed support distributions because they tend to generate many spurious patterns involving items from different support levels or miss potentially interesting low-support patterns. To overcome these problems, we propose the concept of hyperclique pattern, which uses an objective measure called h-confidence to identify strong affinity patterns. We also introduce the novel concept of cross-support property for eliminating patterns involving items with substantially different support levels. Our experimental results demonstrate the effectiveness of this method for finding patterns in dense data sets even at very low support thresholds, where most of the existing algorithms would break down. Finally, hyperclique patterns also show great promise for clustering items in high dimensional space.
816B5E93	International Conference on Data Mining	moonjung cho + jian pei + xiaoling zhang + haixun wang + philip s yu	2003	MaPle: a fast algorithm for maximal pattern-based clustering	large database mining + MaPle mining algorithm + data analysis + divide and conquer methods + synthetic data set + real data set + data mining + redundant cluster + recommender system + optimisation + pattern clustering + very large databases + DNA micro-array data analysis + automatic recommendation system + synthetic data + divide-and-conquer search + target marketing system + divide and conquer + maximal pattern-based clustering + statistical analysis + search problems	AuthorProvided Keywords Not Found	Pattern-based clustering is important in many applications, such as DNA micro-array data analysis, automatic recommendation systems and target marketing systems. However, pattern-based clustering in large databases is challenging. On the one hand, there can be a huge number of clusters and many of them can be redundant and thus make the pattern-based clustering ineffective. On the other hand, the previous proposed methods may not be efficient or scalable in mining large databases. We study the problem of maximal pattern-based clustering. Redundant clusters are avoided completely by mining only the maximal pattern-based clusters. MaPle, an efficient and scalable mining algorithm is developed. It conducts a depth-first, divide-and-conquer search and prunes unnecessary branches smartly. Our extensive performance study on both synthetic data sets and real data sets shows that maximal pattern-based clustering is effective. It reduces the number of clusters substantially. Moreover, MaPle is more efficient and scalable than the previously proposed pattern-based clustering methods in mining large databases.
7CFA8762	International Conference on Data Mining	dechang chen + yufeng kou + changtien lu	2003	Algorithms for spatial outlier detection	iterative methods + data analysis + spatial outlier detection algorithm + visual databases + median algorithm + real-world census data set + statistical databases + iteration algorithm + outlier detection + spatial pattern + spatial data analysis	AuthorProvided Keywords Not Found	A spatial outlier is a spatially referenced object whose non-spatial attribute values are significantly different from the values of its neighborhood. Identification of spatial outliers can lead to the discovery of unexpected, interesting, and useful spatial patterns for further analysis. One drawback of existing methods is that normal objects tend to be falsely detected as spatial outliers when their neighborhood contains true spatial outliers. We propose a suite of spatial outlier detection algorithms to overcome this disadvantage. We formulate the spatial outlier detection problem in a general way and design algorithms which can accurately detect spatial outliers. In addition, using a real-world census data set, we demonstrate that our approaches can not only avoid detecting false spatial outliers but also find true spatial outliers ignored by existing methods.
0BA206D1	International Conference on Data Mining	aulia hardjasamudra + ian a cook + jing zhang	2003	Densityplot Matrix Display for Large Distributed Data	indexation		"
In this paper, a software application, Limn Matrix, is developed to interactively display a densityplot matrix for large, distributed data. A density plot is used to alleviate overplotting of points to more accurately represent the distribution of data points. To efficiently exchange large amounts of information through the network, we propose a hierarchical indexing system, by which the information volume transferring via network only depends on the number of plots and plot window size rather than data size. In addition, Limn Matrix provides several interactive features, including subset brushing and density transformation controls, to provide users extra insight about the large data set. An application on forest cover type data and future improvements of the software are also discussed. Scatter plots are widely used for data visualization. By plotting one variable against the other in a 2D space, the patterns of dependence and deviations from dependence between a variable pair can be easily identified. A scatter plot matrix is a neat layout of multiple scatter plots when there are more than two variables involved. The plots are arranged into a matrix format which actually matches the form of the correlation matrix. An N-dimensional data set will form a matrix of N*(N-1)/2 scatter plots. Laying out scatter plots of any two variables in a matrix helps to reveal the relationships between the variable pairs. In addition, user interactions, like brushing and subset coloring, provide users extra insights on the relationship between more than two variables (Becker and Cleveland 1987a). A scatterplot can display a small set of data without problems. However, viewing large data sets with scatterplots brings two major challenges:
"
7F78A39E	International Conference on Data Mining	jinze liu + wei wang	2003	OP-cluster: clustering by tendency in high dimensional space	environment stimuli + high dimensional space + biological data + data mining + cosine distance + euclidean distance + deterministic algorithms + gene regulatory network + biology computing + pattern clustering + Euclidean distance + OP cluster model + statistical analysis	AuthorProvided Keywords Not Found	Clustering is the process of grouping a set of objects into classes of similar objects. Because of unknownness of the hidden patterns in the data sets, the definition of similarity is very subtle. Until recently, similarity measures are typically based on distances, e.g Euclidean distance and cosine distance. We propose a flexible yet powerful clustering model, namely OP-cluster (Order Preserving Cluster). Under this new model, two objects are similar on a subset of dimensions if the values of these two objects induce the same relative order of those dimensions. Such a cluster might arise when the expression levels of (coregulated) genes can rise or fall synchronously in response to a sequence of environment stimuli. Hence, discovery of OP-Cluster is essential in revealing significant gene regulatory networks. A deterministic algorithm is designed and implemented to discover all the significant OP-Clusters. A set of extensive experiments has been done on several real biological data sets to demonstrate its effectiveness and efficiency in detecting coregulated patterns.
5CEF540E	International Conference on Data Mining	assaf schuster + ran wolff + dan trock	2003	A high-performance distributed algorithm for mining association rules	high-performance distributed algorithm + sequential algorithm + association rule + data mining + error probability + distributed association rule mining + association rule mining + distributed algorithm + distributed algorithms + very large databases + D-ARM algorithm + scale-up experiment + error statistics	AuthorProvided Keywords Not Found	We present a new distributed association rule mining (D-ARM) algorithm that demonstrates superlinear speedup with the number of computing nodes. The algorithm is the first D-ARM algorithm to perform a single scan over the database. As such, its performance is unmatched by any previous algorithm. Scale-up experiments over standard synthetic benchmarks demonstrate stable run time regardless of the number of computers. Theoretical analysis reveals a tighter bound on error probability than the one shown in the corresponding sequential algorithm.
7FE72799	International Conference on Data Mining	edwin o heierman + diane j cook	2003	Improving home automation by discovering regularly occurring device usage patterns	home automation + intelligent agent + prediction algorithm + data mining + pattern discovery + smart home + knowledge discovery + inhabitant-device interaction + cooperative systems + data mining technique + home automation system + data stream	AuthorProvided Keywords Not Found	The data stream captured by recording inhabitant-device interactions in an environment can be mined to discover significant patterns, which an intelligent agent could use to automate device interactions. However, this knowledge discovery problem is complicated by several challenges, such as excessive noise in the data, data that does not naturally exist as transactions, a need to operate in real time, and a domain where frequency may not be the best discriminator. We propose a novel data mining technique that addresses these challenges and discovers regularly-occurring interactions with a smart home. We also discuss a case study that shows the data mining technique can improve the accuracy of two prediction algorithms, thus demonstrating multiple uses for a home automation system. Finally, we present an analysis of the algorithm and results obtained using inhabitant interactions.
8038BAD9	International Conference on Data Mining	raymond chan + qiang yang + yidong shen	2003	Mining high utility itemsets	high utility itemset + top-K objective-directed data mining + antimonotone pruning strategy + statistical pattern + very large databases + probability + data mining + Apriori algorithm + association rule mining	High utility item-set + frequent item-set + candidate pruning + utility mining + UP Growth utility pattern + TWU Transaction weight utilizations + HUP High utility pattern + PHUIs Potential high utility items + RTU reorganized transaction	Traditional association rule mining algorithms only generate a large number of highly frequent rules, but these rules do not provide useful answers for what the high utility rules are. We develop a novel idea of top-K objective-directed data mining, which focuses on mining the top-K high utility closed patterns that directly support a given business objective. To association mining, we add the concept of utility to capture highly desirable statistical patterns and present a level-wise item-set mining algorithm. With both positive and negative utilities, the antimonotone pruning strategy in Apriori algorithm no longer holds. In response, we develop a new pruning strategy based on utilities that allow pruning of low utility itemsets to be done by means of a weaker but antimonotonic condition. Our experimental results show that our algorithm does not require a user specified minimum utility and hence is effective in practice.
802EBF82	International Conference on Data Mining	assaf schuster + ran wolff	2003	Association rule mining in peer-to-peer systems	data mining + association rule mining + grid computing + association rule + exact solution + network topology + distributed databases		"
We extend the problem of association rule mining  a key data mining problem  to systems in which the database is partitioned among a very large number of computers that are dispersed over a wide area. Such computing systems include GRID computing platforms, federated database systems, and peer-to-peer computing environments. The scale of these systems poses several dif culties, such as the impracticality of global communications and global synchronization, dynamic topology changes of the network, on-the- y data updates, the need to share resources with other applications, and the frequent failure and recovery of resources. We present an algorithm by which every node in the system can reach the exact solution, as if it were given the combined database. The algorithm is entirely asynchronous, imposes very little communication overhead, transparently tolerates network topology changes and node failures, and quickly adjusts to changes in the data as they occur. Simulation of up to 10,000 nodes show that the algorithm is local: all rules, except for those whose con dence is about equal to the con dence threshold, are discovered using information gathered from a very small vicinity, whose size is independent of the size of the system.
"
03E107F7	International Conference on Data Mining	ian davidson + ashwin satyanarayana	2003	Speeding up k-means Clustering by Bootstrap Averaging	 + k means clustering + monotone function + data mining + k means		"
K-means clustering is one of the most popular clustering algorithms used in data mining. However, clustering is a time consuming task, particularly with the large data sets found in data mining. In this paper we show how bootstrap averaging with k-means can produce results comparable to clustering all of the data but in much less time. The approach of bootstrap (sampling with replacement) averaging consists of running k-means clustering to convergence on small bootstrap samples of the training data and averaging similar cluster centroids to obtain a single model. We show why our approach should take less computation time and empirically illustrate its benefits. We show that the performance of our approach is a monotonic function of the size of the bootstrap sample. However, knowing the size of the bootstrap sample that yields as good results as clustering the entire data set remains an open and important question.
"
7FFB8C0B	International Conference on Data Mining	matthew v mahoney + philip k chan	2003	Learning rules for anomaly detection of hostile network traffic	TCP + hostile network traffic anomaly detection + time series + anomaly detection + intrusion detection + telecommunication computing + learning artificial intelligence + transport protocols + knowledge based systems + LERAD algorithm + learning (artificial intelligence) + network packet + telecommunication traffic	AuthorProvided Keywords Not Found	We introduce an algorithm called LERAD that learns rules for finding rare events in nominal time-series data with long range dependencies. We use LERAD to find anomalies in network packets and TCP sessions to detect novel intrusions. We evaluated LERAD on the 1999 DARPA/Lincoln Laboratory intrusion detection evaluation data set and on traffic collected in a university departmental server environment.
7E555CE5	International Conference on Data Mining	marco saerens + francois fouss + jeanmichel renders	2003	Links between Kleinberg's hubs and authorities, correspondence analysis, and Markov chains	Kleinberg hubs + correspondence analysis + data mining + markov chain model + relational database + Kleinberg authorities model + Web navigation + markov chain + Markov chain + markov processes + markov model + multivariate statistics + Markov processes + statistical analysis + Web sites + multivariate statistical technique	AuthorProvided Keywords Not Found	We show that Kleinberg's hubs and authorities model is closely related to both correspondence analysis, a well-known multivariate statistical technique, and a particular Markov chain model of navigation through the Web. The only difference between correspondence analysis and Kleinberg's method is the use of the average value of the hubs (authorities) scores for computing the authorities (hubs) scores, instead of the sum for Kleinberg's method. We also show that correspondence analysis and our Markov model are related to SALSA, a variant of Kleinberg's model.
7D3A7E0C	International Conference on Data Mining	rajagopal venugopal + steve horvath + marc sobel + longin jan latecki	2003	Tree-structured partitioning based on splitting histograms of distances	clustering algorithm + pattern clustering + tree structure + very large databases + data mining + tree diagram + classification tree + discrete curve evolution method + tree data structures + tree-structured partitioning + very large data set	AuthorProvided Keywords Not Found	"We propose a novel clustering algorithm that is similar in spirit to classification trees. The data is recursively split using a criterion that applies a discrete curve evolution method to the histogram of distances. The algorithm can be depicted through tree diagrams with triple splits. Leaf nodes represent either clusters or sets of observations that can not yet be clearly assigned to a cluster. After constructing the tree, unclassified data points are mapped to their closest clusters. The algorithm has several advantages. First, it deals effectively with observations that can not be unambiguously assigned to a cluster by allowing a ""margin of error"". Second, it automatically determines the number of clusters; apart from the margin of error the user only needs to specify the minimal cluster size but not the number of clusters. Third, it is linear with respect to the number of data points and thus suitable for very large data sets. Experiments involving both simulated and real data from different domains show that the proposed method is effective and efficient."
5C95FB90	International Conference on Data Mining	stefan wermter + chihli hung	2003	A dynamic adaptive self-organising hybrid model for text clustering	neural network + data structures + hierarchical clustering + data structure + statistical analysis + text clustering + data mining + text analysis		"
Clustering by document concepts is a powerful way of retrieving information from a large number of documents. This task in general does not make any assumption on the data distribution. In this paper, for this task we propose a new competitive Self-Organising (SOM) model, namely the Dynamic Adaptive Self-Organising Hybrid model (DASH). The features of DASH are a dynamic structure, hierarchical clustering, non-stationary data learning and parameter self-adjustment. All features are data-oriented: DASH adjusts its behaviour not only by modifying its parameters but also by an adaptive structure. The hierarchical growing architecture is a useful facility for such a competitive neural model which is designed for text clustering. In this paper, we have presented a new type of self-organising dynamic growing neural network which can deal with the non-uniform data distribution and the non-stationary data sets and represent the inner data structure by a hierarchical view.
"
807D6CAD	International Conference on Data Mining	keke chen + ling liu	2003	Validating and refining clusters via visual rendering	skewed datasets + domain knowledge + automatic clustering algorithms + arbitrarily shaped clusters + human factors + cluster validation + VISTA visual framework + computational geometry + information visualization + interactive feedbacks + scientific data + domain experts + visual rendering + error rate + data visualisation + cluster refining process + statistical indices + data visualization + statistical analysis + irregular shaped cluster + rendering (computer graphics)	Scientific Data Clustering + Information Visualization + Human Factor in Clustering	The automatic clustering algorithms are known to work well in dealing with clusters of regular shapes, e.g. compact spherical/elongated shapes, but may incur higher error rates when dealing with arbitrarily shaped clusters. Although some efforts have been devoted to addressing the problem of skewed datasets, the problem of handling clusters with irregular shapes is still in its infancy, especially in terms of dimensionality of the datasets and the precision of the clustering results considered. Not surprisingly, the statistical indices works ineffective in validating clusters of irregular shapes, too. We address the problem of clustering and validating arbitrarily shaped clusters with a visual framework (VISTA). The main idea of the VISTA approach is to capitalize on the power of visualization and interactive feedbacks to encourage domain experts to participate in the clustering revision and clustering validation process.
7D392FCE	International Conference on Data Mining	wagner meira + adriano veloso + matthew eric otey + c wang + srinivasan parthasarathy	2003	Mining frequent itemsets in distributed and dynamic databases	distributed database + query processing + parallel techniques + parallel algorithms + data mining + query response time + distributed databases + incremental techniques + dynamic databases + minimisation + communication overhead minimization + frequent itemsets mining	AuthorProvided Keywords Not Found	Traditional methods for frequent itemset mining typically assume that data is centralized and static. Such methods impose excessive communication overhead when data is distributed, and they waste computational resources when data is dynamic. We present what we believe to be the first unified approach that overcomes these assumptions. Our approach makes use of parallel and incremental techniques to generate frequent itemsets in the presence of data updates without examining the entire database, and imposes minimal communication overhead when mining distributed databases. Further, our approach is able to generate both local and global frequent itemsets. This ability permits our approach to identify high-contrast frequent itemsets, which allows one to examine how the data is skewed over different sites.
7E322348	International Conference on Data Mining	reda alhajj + mehmet kaya	2003	Facilitating fuzzy association rules mining by using multi-objective genetic algorithms for automated clustering	association rule + fuzzy set + pattern clustering + data mining + fuzzy set theory + CURE-based approach + automated clustering + genetic algorithms + multiobjective genetic algorithm + fuzzy association rule mining	AuthorProvided Keywords Not Found	We propose an automated clustering method based on multiobjective genetic algorithms (GA); the aim of this method is to automatically cluster values of a given quantitative attribute to obtain large number of large itemsets in low duration (time). We compare the proposed multi-objective GA-based approach with CURE-based approach. In addition to the autonomous specification of fuzzy sets, experimental results showed that the proposed automated clustering exhibits good performance over CURE-based approach in terms of runtime as well as the number of large itemsets and interesting association rules.
5B81BB30	International Conference on Data Mining	mukund deshpande + george karypis + michihiro kuramochi	2003	Frequent sub-structure-based approaches for classifying chemical compounds	pattern classification + support vector machines + subgraph discovery algorithm + virtual screening + indexing terms + graph theory + chemical compound dataset classification + geometric substructure + chemical structure + feature selection + substructure discovery process	AuthorProvided Keywords Not Found	We study the problem of classifying chemical compound datasets. We present a substructure-based classification algorithm that decouples the substructure discovery process from the classification model construction and uses frequent subgraph discovery algorithms to find all topological and geometric substructures present in the dataset. The advantage of our approach is that during classification model construction, all relevant substructures are available allowing the classifier to intelligently select the most discriminating ones. The computational scalability is ensured by the use of highly efficient frequent subgraph discovery algorithms coupled with aggressive feature selection. Our experimental evaluation on eight different classification problems shows that our approach is computationally scalable and on the average, outperforms existing schemes by 10% to 35%.
7D3494AA	International Conference on Data Mining	doina caragea + vasant honavar + dianne cook	2003	Towards simple, easy-to-understand, yet accurate classifiers	support vector machine + exploratory data analysis + support vector machines + data visualisation + probability + digital simulation + linear support vector machine classifiers + nonlinear support vector machine classifier + statistical analysis + random hyperplanes + weighted linear classifiers	AuthorProvided Keywords Not Found	We design a method for weighting linear support vector machine classifiers or random hyperplanes, to obtain classifiers whose accuracy is comparable to the accuracy of a nonlinear support vector machine classifier, and whose results can be readily visualized. We conduct a simulation study to examine how our weighted linear classifiers behave in the presence of known structure. The results show that the weighted linear classifiers might perform well compared to the nonlinear support vector machine classifiers, while they are more readily interpretable than the nonlinear classifiers.
8006BC05	International Conference on Data Mining	yun chi + yirong yang + richard r muntz	2003	Indexing and mining free trees	computational biology + canonical representation + tree structure + data mining + trees (mathematics) + indexation + canonical form + Internet multicast trees dataset + FreeTreeMiner algorithm + subtrees mining + rooted trees + database indexing + tree structures + synthetic data + free tree indexing technique + chemical compound dataset + tree data structures + pattern recognition	AuthorProvided Keywords Not Found	Tree structures are used extensively in domains such as computational biology, pattern recognition, computer networks, and so on. We present an indexing technique for free trees and apply this indexing technique to the problem of mining frequent subtrees. We first define a novel representation, the canonical form, for rooted trees and extend the definition to free trees. We also introduce another concept, the canonical string, as a simpler representation for free trees in their canonical forms. We then apply our tree indexing technique to the frequent subtree mining problem and present FreeTreeMiner, a computationally efficient algorithm that discovers all frequently occurring subtrees in a database of free trees. We study the performance and the scalability of our algorithms through extensive experiments based on both synthetic data and datasets from two real applications: a dataset of chemical compounds and a dataset of Internet multicast trees.
80401ABC	International Conference on Data Mining	alexandrin popescul + lyle h ungar + david m pennock + steve lawrence	2003	Statistical relational learning for document mining	decision theory + data mining + regression analysis + statistical model + learning artificial intelligence + real-world database + learning logic description + statistical modelling + search space + refinement graphs + logistic regression + learning (artificial intelligence) + feature selection + inductive logic programming + document handling + feature selection decision + statistical relational learning + model selection + relational database + relational databases + scientific paper + complex relational structure + relational data + data mining algorithm + classical flat feature + document mining	AuthorProvided Keywords Not Found	"A major obstacle to fully integrated deployment of many data mining algorithms is the assumption that data sits in a single table, even though most real-world databases have complex relational structures. We propose an integrated approach to statistical modelling from relational databases. We structure the search space based on ""refinement graphs"", which are widely used in inductive logic programming for learning logic descriptions. The use of statistics allows us to extend the search space to include richer set of features, including many which are not Boolean. Search and model selection are integrated into a single process, allowing information criteria native to the statistical model, for example logistic regression, to make feature selection decisions in a step-wise manner. We present experimental results for the task of predicting where scientific papers will be published based on relational data taken from CiteSeer. Our approach results in classification accuracies superior to those achieved when using classical ""flat"" features. The resulting classifier can be used to recommend where to publish articles."
7E65F40F	International Conference on Data Mining	raymond chiwing wong + ada waichee fu + ke wang	2003	MPIS: maximal-profit item selection with cross-selling considerations	profitability + association rule + quadratic programming problem + data mining + heuristic method + quadratic programming + association rule mining + cross-selling considerations + heuristic programming + NP-hard problem + maximal-profit item selection + association rule mining algorithms + quadratic program	AuthorProvided Keywords Not Found	In the literature of data mining, many different algorithms for association rule mining have been proposed. However, there is relatively little study on how association rules can aid in more specific targets. One of the applications for association rules - maximal-profit item selection with cross-selling effect (MPIS) problem - is investigated. The problem is about selecting a subset of items, which can give the maximal profit with the consideration of cross-selling. We prove that a simple version of this problem is NP-hard. We propose a new approach to the problem with the consideration of the loss rule - a kind of association rule to model the cross-selling effect. We show that the problem can be transformed to a quadratic programming problem. In case quadratic programming is not applicable, we also propose a heuristic approach. Experiments are conducted to show that both of the proposed methods are highly effective and efficient.
7E437383	International Conference on Data Mining	jan f prins + wei wang + jun huan	2003	Efficient mining of frequent subgraphs in the presence of isomorphism	data representation + graph theory + subgraph testing + data mining + gSpan mining algorithm + time complexity + visual databases + empirical study + isomorphism + FFSM + fast frequent subgraph mining + search problems + graph databases	AuthorProvided Keywords Not Found	Frequent subgraph mining is an active research topic in the data mining community. A graph is a general model to represent data and has been used in many domains like cheminformatics and bioinformatics. Mining patterns from graph databases is challenging since graph related operations, such as subgraph testing, generally have higher time complexity than the corresponding operations on itemsets, sequences, and trees, which have been studied extensively. We propose a novel frequent subgraph mining algorithm: FFSM, which employs a vertical search scheme within an algebraic graph framework we have developed to reduce the number of redundant candidates proposed. Our empirical study on synthetic and real datasets demonstrates that FFSM achieves a substantial performance gain over the current start-of-the-art subgraph mining algorithm gSpan.
7FB050E7	International Conference on Data Mining	john langford + bianca zadrozny + naoki abe	2003	Cost-sensitive learning by cost-proportionate example weighting	pattern classification + cost-sensitive learning algorithms + sampling methods + learning artificial intelligence + support vector machines + cost-proportionate example weighting + cost-proportionate rejection sampling + cost-benefit analysis + classification algorithm + empirical evidence + cost benefit analysis + learning (artificial intelligence)	AuthorProvided Keywords Not Found	We propose and evaluate a family of methods for converting classifier learning algorithms and classification theory into cost-sensitive algorithms and theory. The proposed conversion is based on cost-proportionate weighting of the training examples, which can be realized either by feeding the weights to the classification algorithm (as often done in boosting), or by careful subsampling. We give some theoretical performance guarantees on the proposed methods, as well as empirical evidence that they are practical alternatives to existing approaches. In particular, we propose costing, a method based on cost-proportionate rejection sampling and ensemble aggregation, which achieves excellent predictive performance on two publicly available datasets, while drastically reducing the computation required by other methods.
7EC8ECBE	International Conference on Data Mining	inderjit s dhillon + yuqiang guan	2003	Information theoretic clustering of sparse cooccurrence data	optimization problem + divisive clustering algorithm + supervised Naive Bayes algorithm + document clustering + sparse high-dimensional cooccurrence data + random variable + local search + loss function + local minima + learning artificial intelligence + optimisation + high dimensional data + pattern clustering + naive bayes + relative entropy + probability distribution + information theory + mutual information + Bayes methods + learning (artificial intelligence)	AuthorProvided Keywords Not Found	"A novel approach to clustering cooccurrence data poses it as an optimization problem in information theory which minimizes the resulting loss in mutual information. A divisive clustering algorithm that monotonically reduces this loss function was recently proposed. We show that sparse high-dimensional data presents special challenges which can result in the algorithm getting stuck at poor local minima. We propose two solutions to this problem: (a) a ""prior"" to overcome infinite relative entropy values as in the supervised Naive Bayes algorithm, and (b) local search to escape local minima. Finally, we combine these solutions to get a robust algorithm that is computationally efficient. We present experimental results to show that the proposed method is effective in clustering document collections and outperform previous information-theoretic clustering approaches."
814B1328	International Conference on Data Mining	kumar k tamma + chandrika kamath + ramdev kanapady + vipin kumar + aleksandar lazarevic	2003	Localized prediction of continuous target variables using hierarchical clustering	prediction model + clustering algorithm + partitioning step + classification model + learning artificial intelligence + localization step + very large databases + distributed databases + continuous target variables + localized prediction + hierarchical clustering + target variables + complex mechanical structures + statistical analysis + learning (artificial intelligence) + heterogeneous data sets + recursive partitioning	AuthorProvided Keywords Not Found	We propose a novel technique for the efficient prediction of multiple continuous target variables from high-dimensional and heterogeneous data sets using a hierarchical clustering approach. The proposed approach consists of three phases applied recursively: partitioning, localization and prediction. In the partitioning step, similar target variables are grouped together by a clustering algorithm. In the localization step, a classification model is used to predict which group of target variables is of particular interest. If the identified group of target variables still contains a large number of target variables, the partitioning and localization steps are repeated recursively and the identified group is further split into subgroups with more similar target variables. When the number of target variables per identified subgroup is sufficiently small, the third step predicts target variables using localized prediction models built from only those data records that correspond to the particular subgroup. Experiments performed on the problem of damage prediction in complex mechanical structures indicate that our proposed hierarchical approach is computationally more efficient and more accurate than straightforward methods of predicting each target variable individually or simultaneously using global prediction models.
7E3ED26A	International Conference on Data Mining	kaidi zhao + bing liu + andreas schaller + thomas m tirpak	2003	Detecting patterns of change using enhanced parallel coordinates visualization	edit distance + product test + change pattern detection + data mining + industrial application + product design + query tool + parallel coordinates visualization + data visualisation + parallel coordinates + edit-distance based technique + V-Miner system + design data + pattern recognition	change patterns + parallel coordinate visualization	Analyzing data to find trends, correlations, and stable patterns is an important problem for many industrial applications. We propose a new technique based on parallel coordinates visualization. Previous work on parallel coordinates method has shown that they are effective only when variables that are correlated and/or show similar patterns are displayed adjacently. Although current parallel coordinates tools allow the user to manually rearrange the order of variables, this process is very time-consuming when the number of variables is large. Automated assistance is needed. We propose an edit-distance based technique to rearrange variables so that interesting patterns can be easily detected. Our system, V-Miner, includes both automated methods for visualizing common patterns and a query tool that enables the user to describe specific target patterns to be mined/displayed by the system. Following an overview of the system, a case study is presented to explain how Motorola engineers have used V-Miner to identify significant patterns in their product test and design data.
7DBB70A9	International Conference on Data Mining	helge ritter + joerg ontrup + daniel wessling + jorg a walter	2003	Interactive visualization and navigation in large data collections using the hyperbolic space	tessellating grid + col + interactive visual data mining + large data collections + data mining + visual databases + multi dimensional scaling + interactive navigation + hyperbolic space + data collection + hyperbolic self-organizing maps + hierarchical data + self-organising feature maps + very large databases + data visualisation + batch precomputation + interactive systems + text mining + interactive visualization + data handling + Kohonen self-organizing map + multidimensional scaling + hyperbolic multidimensional scaling + computational complexity	AuthorProvided Keywords Not Found	We propose the combination of two recently introduced methods for the interactive visual data mining of large collections of data. Both hyperbolic multidimensional scaling (HMDS) and hyperbolic self-organizing maps (HSOM) employ the extraordinary advantages of the hyperbolic plane (H2): (i) the underlying space grows exponentially with its radius around each point deal for embedding high-dimensional (or hierarchical) data; (ii) the Poincare model of the IH2 exhibits a fish-eye perspective with a focus area and a context preserving surrounding; (in) the mouse binding of focus-transfer allows intuitive interactive navigation. The HMDS approach extends multidimensional scaling and generates a spatial embedding of the data representing their dissimilarity structure as faithfully as possible. It is very suitable for interactive browsing of data object collections, but calls for batch precomputation for larger collection sizes. The HSOM is an extension of Kohonen's self-organizing map and generates a partitioning of the data collection assigned to an IH2 tessellating grid. While the algorithm's complexity is linear in the collection size, the data browsing is rigidly bound to the underlying grid. By integrating the two approaches, we gain the synergetic effect of adding advantages of both. And the hybrid architecture uses consistently the IH2 visualization and navigation concept. We present the successfully application to a text mining example involving the Reuters-21578 text corpus.
7D189392	International Conference on Data Mining	hongbo xie + kang peng + zoran obradovic + slobodan vucetic + bo han	2003	Exploiting unlabeled data for improving accuracy of predictive data mining	one class classification + pattern classification + K-class labeled sample + probability + data mining + medical information systems + predictive data mining accuracy improvement + outlier detection + disordered protein database + learning artificial intelligence + very large databases + prediction problem + synthetic data + PubMed article ranking + real-life bioinformatics application + one-class classification + unlabeled data exploitation + learning (artificial intelligence) + density estimation + biased data + K contrast classifier learning	AuthorProvided Keywords Not Found	Predictive data mining typically relies on labeled data without exploiting a much larger amount of available unlabeled data. We show that using unlabeled data can be beneficial in a range of important prediction problems and therefore should be an integral part of the learning process. Given an unlabeled dataset representative of the underlying distribution and a K-class labeled sample that might be biased, our approach is to learn K contrast classifiers each trained to discriminate a certain class of labeled data from the unlabeled population. We illustrate that contrast classifiers can be useful in one-class classification, outlier detection, density estimation, and learning from biased data. The advantages of the proposed approach are demonstrated by an extensive evaluation on synthetic data followed by real-life bioinformatics applications for (1) ranking PubMed articles by their relevance to protein disorder and (2) cost-effective enlargement of a disordered protein database.
5B9D5DA0	International Conference on Data Mining	wagner truppel + eamonn keogh + jessica lin	2003	Clustering of time series subsequences is meaningless: implications for previous and future research	streaming time series + clustering algorithm + streaming data + online algorithm + data mining + complex data + indexation + time series + anomaly detection + rule discovery + many individual time series + sliding window + data mining algorithm + pattern clustering + satisfiability + single time series + clustering + time series data + time series clustering + computational complexity	eol>Time Series + Data Mining + Clustering + Rule Discovery	Time series data is perhaps the most frequently encountered type of data examined by the data mining community. Clustering is perhaps the most frequently used data mining algorithm, being useful in it's own right as an exploratory technique, and also as a subroutine in more complex data mining algorithms such as rule discovery, indexing, summarization, anomaly detection, and classification. Given these two facts, it is hardly surprising that time series clustering has attracted much attention. The data to be clustered can be in one of two formats: many individual time series, or a single time series, from which individual time series are extracted with a sliding window. Given the recent explosion of interest in streaming data and online algorithms, the latter case has received much attention. We make an amazing claim. Clustering of streaming time series is completely meaningless. More concretely, clusters extracted from streaming time series are forced to obey a certain constraint that is pathologically unlikely to be satisfied by any dataset, and because of this, the clusters extracted by any clustering algorithm are essentially random. While this constraint can be intuitively demonstrated with a simple illustration and is simple to prove, it has never appeared in the literature. We can justify calling our claim surprising, since it invalidates the contribution of dozens of previously published papers. We will justify our claim with a theorem, illustrative examples, and a comprehensive set of experiments on reimplementations of previous work.
7F21C7FC	International Conference on Data Mining	muralikrishna achari + ricardo vilalta + christoph f eick	2003	Class decomposition via clustering: a new framework for low-variance classifiers	training set + pattern classification + class decomposition + support vector machines + clustering algorithm + data mining + low-variance classifier + pattern discovery + learning artificial intelligence + optimisation + predictive accuracy + Bayes methods + statistical analysis + learning (artificial intelligence)	AuthorProvided Keywords Not Found	We propose a preprocessing step to classification that applies a clustering algorithm to the training set to discover local patterns in the attribute or input space. We demonstrate how this knowledge can be exploited to enhance the predictive accuracy of simple classifiers. Our focus is mainly on classifiers characterized by high bias but low variance (e.g., linear classifiers); these classifiers experience difficulty in delineating class boundaries over the input space when a class distributes in complex ways. Decomposing classes into clusters makes the new class distribution easier to approximate and provides a viable way to reduce bias while limiting the growth in variance. Experimental results on real-world domains show an advantage in predictive accuracy when clustering is used as a preprocessing step to classification.
7D99A65D	International Conference on Data Mining	joydeep ghosh + shi zhong	2003	Model-based clustering with soft balancing	 + probability + data mining + posterior probability + maximum likelihood estimation + computational complexity		"
Balanced clustering algorithms can be useful in a variety of applications and have recently attracted increasing research interest. Most recent work, however, addressed only hard balancing by constraining each cluster to have equal or a certain minimum number of data objects. This paper provides a soft balancing strategy built upon a soft mixtureof-models clustering framework. This strategy constrains the sum of posterior probabilities of object membership for each cluster to be equal and thus balances the expected number of data objects in each cluster. We first derive soft model-based clustering from an information-theoretic viewpoint and then show that the proposed balanced clustering can be parameterized by a temperature parameter that controls the softness of clustering as well as that of balancing. As the temperature decreases, the resulting partitioning becomes more and more balanced. In the limit, when temperature becomes zero, the balancing becomes hard and the actual partitioning becomes perfectly balanced. The effectiveness of the proposed soft balanced clustering algorithm is demonstrated on both synthetic and real text data.
"
5FC8CFAB	International Conference on Data Mining	frederic maire	2003	An algorithm for the exact computation of the centroid of higher dimensional polyhedra and its application to kernel machines	approximation theory + support vector machines + centre of mass + learning machine + polyhedra centroid computation + Gaussian kernel matrices + approximation algorithms + gaussian kernel + kernel machine + learning artificial intelligence + support vector machine + gaussian processes + analytic centre machines + Bayesian point machines + Gaussian processes + Bayes methods + learning (artificial intelligence)	AuthorProvided Keywords Not Found	The support vector machine (SVM) solution corresponds to the centre of the largest sphere inscribed in version space. Alternative approaches like Bayesian point machines (BPM) and analytic centre machines have suggested that the generalization performance can be further enhanced by considering other possible centres of version space like the centroid (centre of mass) or the analytic centre. We present an algorithm to compute exactly the centroid of higher dimensional polyhedra, then derive approximation algorithms to build a new learning machine whose performance is comparable to BPM. We also show that for regular kernel matrices (Gaussian kernels for example), the SVM solution can be obtained by solving a linear system of equalities.
7F8768C9	International Conference on Data Mining	william f punch + alexander topchy + anil k jain	2003	Combining multiple weak clusterings	component partition + random data split + data mining + data set + empirical study + consensus function + multiple weak clustering algorithm + intra-class variance criterion + learning artificial intelligence + pattern clustering + fusion method property + parameter setting + mutual information definition + learning dynamics + mutual information + statistical analysis + learning (artificial intelligence) + categorical clustering problem + data projection	AuthorProvided Keywords Not Found	A data set can be clustered in many ways depending on the clustering algorithm employed, parameter settings used and other factors. Can multiple clusterings be combined so that the final partitioning of data provides better clustering? The answer depends on the quality of clusterings to be combined as well as the properties of the fusion method. First, we introduce a unified representation for multiple clusterings and formulate the corresponding categorical clustering problem. As a result, we show that the consensus function is related to the classical intra-class variance criterion using the generalized mutual information definition. Second, we show the efficacy of combining partitions generated by weak clustering algorithms that use data projections and random data splits. A simple explanatory model is offered for the behavior of combinations of such weak clustering components. We analyze the combination accuracy as a function of parameters controlling the power and resolution of component partitions as well as the learning dynamics vs. the number of clusterings involved. Finally, some empirical studies compare the effectiveness of several consensus functions.
5A58EBC1	International Conference on Data Mining	qi li + chandra kambhamettu + jieping ye	2003	Spatial interest pixels (SIPs): useful low-level features of visual media data	face recognition + feature vector + principal component analysis + data structures + lucas kanade + computer graphics + comparative study		"
Visual media data such as an image is the raw data representation for many important applications. The biggest challenge in using visual media data comes from the extremely high dimensionality. We present a comparative study on spatial interest pixels (SIPs), including eight-way (a novel SIP miner), Harris, and Lucas-Kanade, whose extraction is considered as an important step in reducing the dimensionality of visual media data. With extensive case studies, we have shown the usefulness of SIPs as the lowlevel features of visual media data. A class-preserving dimension reduction algorithm (using GSVD) is applied to further reduce the dimension of feature vectors based on SIPs. The experiments showed its superiority over PCA.
"
7EA7B686	International Conference on Data Mining	paolo avesani + sriharsha veeramachaneni	2003	Active sampling for feature selection	heuristic algorithm + sampling methods + feature extraction + data mining + knowledge acquisition + active sampling + data acquisition + knowledge discovery + feature selection	AuthorProvided Keywords Not Found	In knowledge discovery applications, where new features are to be added, an acquisition policy can help select the features to be acquired based on their relevance and the cost of extraction. This can be posed as a feature selection problem where the feature values are not known in advance. We propose a technique to actively sample the feature values with the ultimate goal of choosing between alternative candidate features with minimum sampling cost. Our heuristic algorithm is based on extracting candidate features in a region of the instance space where the feature value is likely to alter our knowledge the most. An experimental evaluation on a standard database shows that it is possible outperform a random subsampling policy in terms of the accuracy in feature selection.
7FD5AC73	International Conference on Data Mining	srujana merugu + joydeep ghosh	2003	Privacy-preserving distributed clustering using generative models	perturbed data + markov chain monte carlo + distributed clustering + data mining + monte carlo methods + communication cost + Monte Carlo techniques + data type + unsupervised scenarios + Monte Carlo methods + markov processes + distributed databases + Markov Chain + local data site + Markov processes + data privacy + generative model + statistical analysis + semisupervised scenarios	AuthorProvided Keywords Not Found	"We present a framework for clustering distributed data in unsupervised and semisupervised scenarios, taking into account privacy requirements and communication costs. Rather than sharing parts of the original or perturbed data, we instead transmit the parameters of suitable generative models built at each local data site to a central location. We mathematically show that the best representative of all the data is a certain ""mean"" model, and empirically show that this model can be approximated quite well by generating artificial samples from the underlying distributions using Markov Chain Monte Carlo techniques, and then fitting a combined global model with a chosen parametric form to these samples. We also propose a new measure that quantifies privacy based on information theoretic concepts, and show that decreasing privacy leads to a higher quality of the combined model and vice versa. We provide empirical results on different data types to highlight the generality of our framework. The results show that high quality distributed clustering can be achieved with little privacy loss and low communication cost."
7DC76EBE	International Conference on Data Mining	marcus a maloof + jeremy z kolter	2003	Dynamic weighted majority: a new ensemble method for tracking concept drift	expert systems + concept drift tracking + majority voting + Blum implementation + incremental tree inducer + dynamic weighted majority + SEA concepts + learning artificial intelligence + STAGGER concepts + base algorithm + incremental naive Bayes + concept drift + naive bayes + ensemble method + tree data structures + Bayes methods + DWM + learning (artificial intelligence) + computational complexity	AuthorProvided Keywords Not Found	"Algorithms for tracking concept drift are important for many applications. We present a general method based on the weighted majority algorithm for using any online learner for concept drift. Dynamic weighted majority (DWM) maintains an ensemble of base learners, predicts using a weighted-majority vote of these ""experts"", and dynamically creates and deletes experts in response to changes in performance. We empirically evaluated two experimental systems based on the method using incremental naive Bayes and incremental tree inducer [ITI] as experts. For the sake of comparison, we also included Blum's implementation of weighted majority. On the STAGGER concepts and on the SEA concepts, results suggest that the ensemble method learns drifting concepts almost as well as the base algorithms learn each concept individually. Indeed, we report the best overall results for these problems to date."
803391A5	International Conference on Data Mining	jiuyong li + yanchun zhang	2003	Direct interesting rule generation	association rule + informative rule set + DIG + data mining + post-pruning process + Apriori + direct interesting rule generation algorithm + learning artificial intelligence + generic algorithm + rule generation process + learning (artificial intelligence) + interestingness criteria + computational complexity	AuthorProvided Keywords Not Found	An association rule generation algorithm usually generates too many rules including a lot of uninteresting ones. Many interestingness criteria are proposed to prune those uninteresting rules. However, they work in post-pruning process and hence do not improve the rule generation efficiency. We discuss properties of informative rule set and conclude that the informative rule set includes all interesting rules measured by many commonly used interestingness criteria, and that rules excluded by the informative rule set are forwardly prunable, i.e. they can be removed in the rule generation process instead of post pruning. Based on these properties, we propose a direct interesting rule generation algorithm, DIG, to directly generate interesting rules defined by any of 12 interestingness criteria. We further show experimentally that DIG is faster and uses less memory than Apriori.
7FB22DFC	International Conference on Data Mining	arkadiusz wojna	2003	Center-based indexing for nearest neighbors search	top down + iterative k-means algorithm + indexation + K nearest neighbors search + search pruning criteria + tree searching + center-based data indexing + database indexing + nearest neighbor search + k nearest neighbor + tree-based top-down indexing + k means algorithm + very large databases + tree node splitting + data sets + tree data structures	AuthorProvided Keywords Not Found	We address the problem of indexing data for the k nearest neighbors (k-nn) search. We present a tree-based top-down indexing method that uses an iterative k-means algorithm for tree node splitting and combines three different search pruning criteria from BST, GHT and GNAT into one. The experiments show that the presented indexing tree accelerates the k-nn searching up to several thousands times in case of large data sets.
7EA23108	International Conference on Data Mining	huseyin polat + wenliang du	2003	Privacy-preserving collaborative filtering using randomized perturbation techniques	collaborative filtering + perturbation techniques + data mining + privacy + e commerce + information filters + information overload + customer profiles + security of data + randomized perturbation techniques + customer data + data privacy + Internet + user privacy-preserving + internet	Privacy + Collaborative Filtering + Randomized Perturbation	Collaborative filtering (CF) techniques are becoming increasingly popular with the evolution of the Internet. To conduct collaborative filtering, data from customers are needed. However, collecting high quality data from customers is not an easy task because many customers are so concerned about their privacy that they might decide to give false information. We propose a randomized perturbation (RP) technique to protect users' privacy while still producing accurate recommendations.
7F2AE476	International Conference on Data Mining	andreas hotho + gerd stumme + steffen staab	2003	Ontologies improve text document clustering	document handling + text document clustering + pattern clustering + Java elearning course + Reuters newsfeeds + bag of words + data mining + document clustering + information browsing + information navigation + ontology + distance learning	AuthorProvided Keywords Not Found	Text document clustering plays an important role in providing intuitive navigation and browsing mechanisms by organizing large sets of documents into a small number of meaningful clusters. The bag of words representation used for these clustering methods is often unsatisfactory as it ignores relationships between important terms that do not cooccur literally. In order to deal with the problem, we integrate core ontologies as background knowledge into the process of clustering text documents. Our experimental evaluations compare clustering techniques based on pre-categorizations of texts from Reuters newsfeeds and on a smaller domain of an eLearning course about Java. In the experiments, improvements of results by background knowledge compared to a baseline without background knowledge can be shown in many interesting combinations.
7F2E4D7C	International Conference on Data Mining	huiqing liu + jinyan li	2003	Ensembles of cascading trees	UCI data sets + decision tree + learning artificial intelligence + biomedical data + cascading trees + CS4 + decision trees + medical information systems + learning (artificial intelligence) + classification + gene expression	AuthorProvided Keywords Not Found	We introduce a new method, called CS4, to construct committees of decision trees for classification. The method considers different top-ranked features as the root nodes of member trees. This idea is particularly suitable for dealing with high-dimensional bio-medical data as top-ranked features in this type of data usually possess similar merits for classification. To make a decision, the committee combines the power of individual trees in a weighted manner. Unlike Bagging or Boosting which uses bootstrapped training data, our method builds all the member trees of a committee using exactly the same set of training data. We have tested these ideas on UCI data sets as well as recent bio-medical data sets of gene expression or proteomic profiles that are usually described by more than 10,000 features. All the experimental results show that our method is efficient and that the classification performance are superior to C4.5 family algorithms.
804C6128	International Conference on Data Mining	qiang yang + jie yin + tacheng chen + charles x ling	2003	Postprocessing decision trees to extract actionable knowledge	profitability + decision trees postprocessing + profit-based objective function + data mining + human expert + customer relationship management + greedy heuristic + data mining algorithm + decision tree + optimisation + satisfiability + decision trees + customer profile + customer model + greedy algorithm + actionable knowledge extraction + exhaustive search + objective function	eol>Customer Relationship Management + action mining + profitoriented data mining	Most data mining algorithms and tools stop at discovered customer models, producing distribution information on customer profiles. Such techniques, when applied to industrial problems such as customer relationship management (CRM), are useful in pointing out customers who are likely attritors and customers who are loyal, but they require human experts to postprocess the mined information manually. Most of the postprocessing techniques have been limited to producing visualization results and interestingness ranking, but they do not directly suggest actions that would lead to an increase the objective function such as profit. Here, we present a novel algorithm that suggest actions to change customers from an undesired status (such as attritors) to a desired one (such as loyal) while maximizing objective function: the expected net profit. We develop these algorithms under resource constraints that are abound in reality. The contribution of the work is in taking the output from an existing mature technique (decision trees, for example), and producing novel, actionable knowledge through automatic postprocessing.
7F539BFA	International Conference on Data Mining	sheng ma + wei fan + philip s yu + haixun wang	2003	Is random model better? On its accuracy and efficiency	random decision tree algorithm + data mining + loss function + inductive learning + decision tree + optimisation + heuristic programming + NP-hard problem + heuristics + very large databases + large dataset + meta-learning + decision trees + optimal hypothesis + learning by example + computational complexity	AuthorProvided Keywords Not Found	Inductive learning searches an optimal hypothesis that minimizes a given loss function. It is usually assumed that the simplest hypothesis that fits the data is the best approximate to an optimal hypothesis. Since finding the simplest hypothesis is NP-hard for most representations, we generally employ various heuristics to search its closest match. Computing these heuristics incurs significant cost, making learning inefficient and unscalable for large dataset. At the same time, it is still questionable if the simplest hypothesis is indeed the closest approximate to the optimal model. Recent success of combining multiple models, such as bagging, boosting and meta-learning, has greatly improved the accuracy of the simplest hypothesis, providing a strong argument against the optimality of the simplest hypothesis. However, computing these combined hypotheses incurs significantly higher cost. We first advert that as long as the error of a hypothesis on each example is within a range dictated by a given loss function, it can still be optimal. Contrary to common beliefs, we propose a completely random decision tree algorithm that achieves much higher accuracy than the single best hypothesis and is comparable to boosted or bagged multiple best hypotheses. The advantage of multiple random tree is its training efficiency as well as minimal memory requirement.
5C484B89	International Conference on Data Mining	aidong zhang + daoying ma	2004	An adaptive density-based clustering algorithm for spatial database with noise	spatial data + adaptive density-based clustering + spatial database + pattern clustering + visual databases + neighbor selection + spatial object distribution	AuthorProvided Keywords Not Found	Clustering spatial data has various applications. Several clustering algorithms have been proposed to cluster objects in spatial databases. Spatial object distribution has significant effect on the results of clustering. Few of current algorithms consider the distribution of objects while processing clusters. In this paper, we propose an adaptive density-based clustering algorithm, ADBC, which uses a novel adaptive strategy for neighbor selection based on spatial object distribution to improve clustering accuracy. We perform a series of experiments on simulated data sets and real data sets. A comparison with DBSCAN and OPTICS shows the superiority of our new approach.
5AFE2946	International Conference on Data Mining	robert l grossman + a l turinsky	2004	A greedy algorithm for selecting models in ensembles	ensemble learning + greedy algorithms + model assignment approach + vote averaging + greedy data labeling + meta model + data mining + statistical model + statistical analysis + greedy algorithm + hierarchical system	AuthorProvided Keywords Not Found	We are interested in ensembles of models built over k data sets. Common approaches are either to combine models by vote averaging, or to build a meta-model on the outputs of the local models. In this paper, we consider the model assignment approach, in which a meta-model selects one of the local statistical models for scoring. We introduce an algorithm called greedy data labeling (GDL) that improves the initial data partition by reallocating some data, so that when each model is built on its local data subset, the resulting hierarchical system has minimal error. We present evidence that model assignment may in certain situations be more natural than traditional ensemble learning, and if enhanced by GDL, it often outperforms traditional ensembles.
5E623860	International Conference on Data Mining	claudio lucchese + francesco bonchi	2004	On closed constrained frequent pattern mining	satisfiability + data mining + closed frequent patterns + formal definition + pattern recognition + constrained frequent patterns + frequent pattern mining	AuthorProvided Keywords Not Found	Constrained frequent patterns and closed frequent patterns are two paradigms aimed at reducing the set of extracted patterns to a smaller, more interesting, subset. Although a lot of work has been done with both these paradigms, there is still confusion around the mining problem obtained by joining closed and constrained frequent patterns in a unique framework. In this paper, we shed light on this problem by providing a formal definition and a thorough characterization. We also study computational issues and show how to combine the most recent results in both paradigms, providing a very efficient algorithm which exploits the two requirements (satisfying constraints and being closed) together at mining time in order to reduce the computation as much as possible.
5AD4C94F	International Conference on Data Mining	aristides gionis + niina haiminen	2004	Unimodal segmentation of sequences	merging + greedy-merging heuristic + unimodality constraints + unimodal functions + greedy algorithms + unimodality test + regression analysis + dynamic programming + unimodal k-segmentation + sequences + unimodal sequence segmentation + heuristic programming + monotonicity constraints + quadratic-time algorithm + unimodal regression algorithm + computational complexity	AuthorProvided Keywords Not Found	We study the problem of segmenting a sequence into k pieces so that the resulting segmentation satisfies monotonicity or unimodality constraints. Unimodal functions can be used to model phenomena in which a measured variable first increases to a certain level and then decreases. We combine a well-known unimodal regression algorithm with a simple dynamic-programming approach to obtain an optimal quadratic-time algorithm for the problem of unimodal k-segmentation. In addition, we describe a more efficient greedy-merging heuristic that is experimentally shown to give solutions very close to the optimal. As a concrete application of our algorithms, we describe two methods for testing if a sequence behaves unimodally or not. Our experimental evaluation shows that our algorithms and the proposed unimodality tests give very intuitive results.
5A820302	International Conference on Data Mining	sanyih hwang + jamshid a vayghan + sandeep mane + jaideep srivastava	2004	Estimation of false negatives in classification	capture recapture + classification problem + false negative estimation + log-linear model + security of data + log linear model + capture-recapture based method + spam detection + network intrusion + unsolicited e-mail + classification + machine learning	AuthorProvided Keywords Not Found	"In many classification problems such as spam detection and network intrusion, a large number of unlabeled test instances are predicted negative by the classifier However, the high costs as well as time constraints on an expert's time prevent further analysis of the ""predicted false"" class instances in order to segregate the false negatives from the true negatives. A systematic method is thus required to obtain an estimate of the number of false negatives. A capture-recapture based method can be used to obtain an ML-estimate of false negatives when two or more independent classifiers are available. In the case for which independence does not hold, we can apply log-linear models to obtain an estimate of false negatives. However, as shown in this paper, lesser the dependencies among the classifiers, better is the estimate obtained for false negatives. Thus, ideally independent classifiers should be used to estimate the false negatives in an unlabeled dataset. Experimental results on the spam dataset from the UCI machine learning repository are presented."
5969AFCB	International Conference on Data Mining	juntae kim + hyungil kim + jonathan l herlocker	2004	Feature-based prediction of unknown preferences for nearest-neighbor collaborative filtering	cold-start problem + collaborative filtering + recommendation systems + unknown preferences + recommender system + nearest neighbor + nearest-neighbor collaborative filtering + data sparseness + feature-based prediction + information filtering	AuthorProvided Keywords Not Found	Recommendation systems analyze user preferences and recommend items to a user by predicting the user's preference for those items. Among various kinds of recommendation methods, collaborative filtering (CF) has been widely used and successfully applied to practical applications. However, collaborative filtering has two inherent problems: data sparseness and the cold-start problems. In this paper, we propose a method of integrating additional feature information of users and items into CF to overcome the difficulties caused by sparseness and improve the accuracy of recommendation. Several experimental results that show the effectiveness of the proposed method are also presented.
5E2A05A0	International Conference on Data Mining	fang chu + yizhou wang + carlo zaniolo	2004	An adaptive learning approach for noisy data streams	robust statistical techniques + pattern classification + statistical estimation + noisy data streams + data mining + adaptive learning + stream mining + learning artificial intelligence + concept drift + data contamination + noise + statistical analysis + learning (artificial intelligence) + noise sensitivity + robust statistics + discriminative model	AuthorProvided Keywords Not Found	Two critical challenges typically associated with mining data streams are concept drift and data contamination. To address these challenges, we seek learning techniques and models that are robust to noise and can adapt to changes in timely fashion. We approach the stream-mining problem using a statistical estimation framework, and propose a fast and robust discriminative model for learning noisy data streams. We build an ensemble of classifiers to achieve timely adaptation by weighting classifiers in a way that maximizes the likelihood of the data. We further employ robust statistical techniques to alleviate the problem of noise sensitivity. Experimental results on both synthetic and real-life data sets demonstrate the effectiveness of this model learning approach.
6BFEC8F4	International Conference on Data Mining	liang huai yang + yu guo wang + yi chen	2004	Incremental mining of frequent XML query patterns	query processing + data management + xml + data mining + XML + trees (mathematics) + XML data management + frequent XML query patterns + incremental mining + database management systems	AuthorProvided Keywords Not Found	The discovering of frequent XML query patterns gains its focus due to its many applications in XML data management, and several algorithms have been proposed to discover frequent query patterns using the frequent structure mining techniques. In this paper we consider the problem of incremental mining of frequent XML query patterns. We propose a method to minimize the I/O and computation requirements for handling incremental updates.
5C9633FA	International Conference on Data Mining	kotagiri ramamohanarao + laurence a f park	2004	Hybrid pre-query term expansion using latent semantic analysis	text analysis + document retrieval + hybrid latent semantic + user query + information retrieval + query mapping + latent semantic retrieval + vector space method + vector space + latent semantic analysis + hybrid prequery term expansion + query vectors	AuthorProvided Keywords Not Found	Latent semantic retrieval methods (unlike vector space methods) take the document and query vectors and map them into a topic space to cluster related terms and documents. This produces a more precise retrieval but also a long query time. We present a new method of document retrieval which allows us to process the latent semantic information into a hybrid latent semantic-vector space query mapping. This mapping automatically expands the users query based on the latent semantic information in the document set. This expanded query is processed using a fast vector space method. Since we have the latent semantic data in a mapping, we are able to store and retrieve vector information in the same fast manner that the vector space method offers. Multiple mappings are combined to produce hybrid latent semantic retrieval which provide precision results 5% greater than the vector space method and fast query times.
5E24A214	International Conference on Data Mining	rajesh natarajan + b shekar	2004	A transaction-based neighbourhood-driven approach to quantifying interestingness of association rules	transaction processing + association rule + retail market-basket + transaction-based neighbourhood-driven approach + relatedness contribution + data mining + item relatedness + association rules + interestingness coefficient + item pairs + junction embedding	AuthorProvided Keywords Not Found	In this paper, we present a data-driven approach for ranking association rules (ARs) based on interestingness. The occurrence of unrelated or weakly related item-pairs in an AR is interesting. In the retail market-basket context, items may be related through various relationships arising due to mutual interaction, 'substitutability' and 'complementarity.' Item-relatedness is a composite of these relationships. We introduce three relatedness measures for capturing relatedness between item-pairs. These measures use the concept of junction embedding to appropriately weigh the relatedness contributions due to complementarity and substitutability between items. We propose an interestingness coefficient by combining the three relatedness measures. We compare this with two objective measures of interestingness and show the intuitiveness of the proposed interestingness coefficient.
5F979E93	International Conference on Data Mining	hweehwa pang + kianlee tan + xi ma	2004	Finding constrained frequent episodes using minimal occurrences	position pairs set + minimal occurrences + data mining + trees (mathematics) + episode prefix tree + prefix-growth approach + episode mining + constrained frequent episode	AuthorProvided Keywords Not Found	Recurrent combinations of events within an event sequence, known as episodes, often reveal useful information. Most of the proposed episode mining algorithms adopt an apriori-like approach that generates candidates and then calculates their support levels. Obviously, such an approach is computationally expensive. Moreover, those algorithms are capable of handling only a limited range of constraints. In this paper, we introduce two mining algorithms - episode prefix tree (EPT) and position pairs set (PPS) - based on a prefix-growth approach to overcome the above limitations. Both algorithms push constraints systematically into the mining process. Performance study shows that the proposed algorithms run considerably faster than MINEPI (Mannila and Toivonen, 1996).
5FB43220	International Conference on Data Mining	sreeram ramachandaran + tzeyun leong + rohit joshi + xiaoli li	2004	Classifying biomedical citations without labeled training examples	domain-specific ontologies + search engine + mutually reinforcing learning algorithm + medical information systems + biomedical citation classification + classification knowledge + classification + naive bayes classifier + reinforcement learning + learning artificial intelligence + labeled training examples + naive Bayes classifier + training data + citation analysis + Bayes methods + learning (artificial intelligence)	AuthorProvided Keywords Not Found	"In this paper we introduce a novel technique for classifying text citations without labeled training examples. We first utilize the search results of a general search engine as original training data. We then proposed a mutually reinforcing learning algorithm (MRL) to mine the classification knowledge and to ""clean"" the training data. With the help of a set of established domain-specific ontological terms or keywords, the MRL mining step derives the relevant classification knowledge. The MRL cleaning step then builds a naive Bayes classifier based on the mined classification knowledge and tries to clean the training set. The MRL algorithm is iteratively applied until a clean training set is obtained. We show the effectiveness of the proposed technique in the classification of biomedical citations from a large medical literature database."
5C8327FF	International Conference on Data Mining	matjaz kukar	2004	Transduction and typicalness for quality assessment of individual classifications in machine learning and data mining	pattern classification + learning algorithm + joint confidence machine + kernel density estimation + data analysis + TCM-NN method + transductive reliability estimation + data mining + kernel density estimate + confidence level + density estimation method + typicalness-based confidence estimation + reliability theory + machine learning + individual classifications + learning artificial intelligence + data analysis tool + quality assessment + transduction-based confidence estimation + statistical analysis + learning (artificial intelligence) + density estimation	quality assessment,+machine learning,+confidence estimation,+typicalness,+transduction	In the past, machine learning algorithms have been successfully used in many problems, and are emerging as valuable data analysis tools. However, their serious practical use is affected by the fact, that more often than not, they cannot produce reliable and unbiased assessments of their predictions' quality. In last years, several approaches for estimating reliability or confidence of individual classifiers have emerged, many of them building upon the algorithmic theory of randomness, such as (historically ordered) transduction-based confidence estimation, typicalness-based confidence estimation, and transductive reliability estimation. Unfortunately, they all have weaknesses: either they are tightly bound with particular learning algorithms, or the interpretation of reliability estimations is not always consistent with statistical confidence levels. In the paper, we propose a joint approach that compensates the mentioned weaknesses by integrating typicalness-based confidence estimation and transductive reliability estimation into joint confidence machine. The resulting confidence machine produces confidence values in the statistical sense (e.g., a confidence level of 95% means that in 95% the predicted class is also a true class), as well as provides us with a general principle that is independent of to the particular underlying classifier. We perform a series of tests with several different machine learning algorithms in several problem domains. We compare our results with that of a proprietary TCM-NN method as well as with kernel density estimation. We show that the proposed method significantly outperforms density estimation methods, and how it may be used to improve their performance.
5F0A481E	International Conference on Data Mining	srinivasan parthasarathy + matthew eric otey + amol ghoting	2004	LOADED: link-based outlier and anomaly detection in evolving data sets	false positive rate + data analysis + information technology + data cleaning + evolving data sets + intrusion detection + anomaly detection + outlier detection + LOADED + link-based outlier	AuthorProvided Keywords Not Found	In this paper, we present LOADED, an algorithm for outlier detection in evolving data sets containing both continuous and categorical attributes. LOADED is a tunable algorithm, wherein one can trade off computation for accuracy so that domain-specific response times are achieved. Experimental results show that LOADED provides very good detection and false positive rates, which are several times better than those of existing distance-based schemes.
6E773C44	International Conference on Data Mining	harry zhang + shengli sheng	2004	Learning weighted naive Bayes with accurate ranking	hill climbing + pattern classification + gain ratio method + hill climbing method + monte carlo methods + classification algorithm + learning artificial intelligence + Monte Carlo methods + Markov chain Monte Carlo method + naive bayes + markov processes + Markov processes + Bayes methods + learning (artificial intelligence) + weighted naive Bayes learning	AuthorProvided Keywords Not Found	Naive Bayes is one of most effective classification algorithms. In many applications, however, a ranking of examples are more desirable than just classification. How to extend naive Bayes to improve its ranking performance is an interesting and useful question in practice. Weighted naive Bayes is an extension of naive Bayes, in which attributes have different weights. This paper investigates how to learn a weighted naive Bayes with accurate ranking from data, or more precisely, how to learn the weights of a weighted naive Bayes to produce accurate ranking. We explore various methods: the gain ratio method, the hill climbing method, and the Markov chain Monte Carlo method, the hill climbing method combined with the gain ratio method, and the Markov chain Monte Carlo method combined with the gain ratio method. Our experiments show that a weighted naive Bayes trained to produce accurate ranking outperforms naive Bayes.
5A3A2CA4	International Conference on Data Mining	panos m pardalos + haesun park + cheong hee park	2004	A comparative study of linear and nonlinear feature extraction methods	linear feature extraction + discriminant analysis + feature extraction + kernel method + nonlinear discriminant analysis + nonlinear feature extraction + generalized LDA algorithm + linear discriminant analysis + computational complexity + matrix algebra	AuthorProvided Keywords Not Found	This paper presents theoretical relationships among several generalized LDA algorithms and proposes computationally efficient approaches for them utilizing the relationships. Generalized LDA algorithms are extended nonlinearly by kernel methods resulting in nonlinear discriminant analysis. Performances and computational complexities of these linear and nonlinear discriminant analysis algorithms are compared.
5E03BA6C	International Conference on Data Mining	dolores romero morales + belen martinbarragan + emilio carrizosa	2004	A biobjective model to select features with good classification quality and low cost	Pareto optimal solutions + Pareto optimisation + pattern classification + multigroup classification + support vector machine + support vector machines + generalization ability + SVM + generalisation (artificial intelligence) + biobjective mixed integer problem + feature selection	AuthorProvided Keywords Not Found	In this paper we address a multigroup classification problem in which we want to take into account, together with the generalization ability, costs associated with the features. This cost is not limited to an economical payment, but can also refer to risk, computational effort, space requirements, etc. In order to get a good generalization ability, we use support vector machines (SVM) as the basic mechanism by considering the maximization of the margin. We formulate the problem as a biobjective mixed integer problem, for which Pareto optimal solutions can be obtained.
01329B92	International Conference on Data Mining	wei xu + peter bod ik + david a patterson	2004	A Flexible Architecture for Statistical Learning and Data Mining from System Log Streams	data mining		"
Modern computer systems are instrumented to generate huge amounts of system log data. This data contains valuable information for managing the system, localizing failures, and recovery. However, the complexity of these systems greatly surpasses what can be understood by human operators and thus automated analysis systems are beginning to be used. Due to preprocessing required by the statistical algorithms, the extremely high volume of data cannot be processed using ad-hoc scripts. We present a flexible, modular and scalable architecture for statistical learning from large data streams that can easily process lots of data. We built a prototype that is evaluated using system log data from a commercial on-line service. Moreover, the results of the analysis were genuinely useful for the on-line service operators.
"
58BC06BC	International Conference on Data Mining	alexander tuzhilin + tianyi jiang	2004	Divide and prosper: comparing models of customer behavior from populations to individuals	customer segmentation + comparative modeling + pattern clustering + 1-to-1 modeling + aggregate marketing + consumer behaviour + customer behavior	AuthorProvided Keywords Not Found	This paper compares customer segmentation, 1-to-1, and aggregate marketing approaches across a broad range of experimental settings, including multiple segmentation levels, marketing datasets, dependent variables, and different types of classifiers, segmentation techniques, and predictive measures. Our experimental results show that, overall, 1-to-1 modeling significantly outperforms the aggregate approach among high-volume customers and is never worse than aggregate approach among low-volume customers. Moreover, the best segmentation techniques tend to outperform 1-to-l modeling among low-volume customers.
7F201C32	International Conference on Data Mining	hugh e williams + nicholas lester + amanda clare	2004	Scalable multi-relational association mining	yeast homology collection mining + efficiency + multirelational data mining + multirelational association discovery + data mining + relational databases + scalability + scalable multirelational association mining + RADAR technique	AuthorProvided Keywords Not Found	We propose the RADAR technique for multirelational data mining. This permits the mining of very large collections and provides a technique for discovering multirelational associations. Results show that RADAR is reliable and scalable for mining a large yeast homology collection, and that it does not have the main-memory scalability constraints of the Farmer and Warmr tools.
59208B8D	International Conference on Data Mining	michael kuperberg + dan a simovici + namita singla	2004	Metric incremental clustering of nominal data	pattern clustering + data mining + metric incremental clustering + nominal data + clustering partition	AuthorProvided Keywords Not Found	We present an algorithm/or clustering nominal data that is based on a metric on the set of partitions of a finite set of objects; this metric is defined starting from a lower valuation of the lattice of partitions. The proposed algorithm seeks to determine a clustering partition such that the total distance between this partition and the partitions determined by the attributes of the objects has a local minimum. The resulting clustering is quite stable relative to the ordering of the objects.
584B6DA8	International Conference on Data Mining	jiawei han + duane searsmith + xiaolei li + hwanjo yu	2004	Scalable construction of topic directory with nonparametric closed termset mining	document handling + pattern clustering + nonparametric closed termset mining + data mining + document clustering + Yahoo directory + hierarchical clustering + topic directory + automatic generation	hierarchical clustering,+topic directory,+document clustering	A topic directory, e.g., Yahoo directory, provides a view of a document set at different levels of abstraction and is ideal for the interactive exploration and visualization of the document set. We present a method that dynamically generates a topic directory from a document set using a frequent closed termset mining algorithm. Our method shows experimental results of equal quality to recent document clustering methods and has additional benefits such as automatic generation of topic labels and determination of a clustering parameter.
5A914009	International Conference on Data Mining	andrew arnt + shlomo zilberstein	2004	Attribute measurement policies for time and cost sensitive classification	measurement problem + attribute measurement + pattern classification + cost sensitive classification + time sensitive classification + AO* heuristic search + heuristic search + realtime applications + markov processes + markov decision process + real-time systems + cost effectiveness + Markov processes + Markov decision process + real time systems + search problems	AuthorProvided Keywords Not Found	Attribute measurement is an important component of classification algorithms, which could limit their applicability in realtime settings. The time taken to assign a value to an unknown attribute may reduce the overall utility of the final result. We identify three different costs that must be considered, including a time sensitive utility function. We model this attribute measurement problem as a Markov decision process (MDP), and build a policy to control this process using AO* heuristic search. The results offer a cost-effective approach to attribute measurement and classification for a variety of realtime applications.
7DAD3354	International Conference on Data Mining	steffen bickel + tobias scheffer	2004	Multi-view clustering	text analysis + pattern classification + web pages + clustering algorithm + independent subsets + anchor text + data mining + agglomerative hierarchical multiview clustering + set theory + multiview learning + learning artificial intelligence + pattern clustering + text data + Web pages + partitioning + learning (artificial intelligence)	AuthorProvided Keywords Not Found	We consider clustering problems in which the available attributes can be split into two independent subsets, such that either subset suffices for learning. Example applications of this multi-view setting include clustering of Web pages which have an intrinsic view (the pages themselves) and an extrinsic view (e.g., anchor texts of inbound hyperlinks); multi-view learning has so far been studied in the context of classification. We develop and study partitioning and agglomerative, hierarchical multi-view clustering algorithms for text data. We find empirically that the multi-view versions of k-means and EM greatly improve on their single-view counterparts. By contrast, we obtain negative results for agglomerative hierarchical multi-view clustering. Our analysis explains this surprising phenomenon.
5A1DCEB2	International Conference on Data Mining	henry soldano + thibaut lamadon + veronique ventos	2004	Alpha Galois lattices	galois fields + clustering algorithm + data mining + lattice theory + representation language + alpha Galois lattices + Galois fields + instance set partition	AuthorProvided Keywords Not Found	"In many applications there is a need to represent a large number of data by clustering them in a hierarchy of classes. Our basic representation is a Galois lattice, a structure that exhaustively represents the whole set of concepts that are distinguishable given the instance set and the representation language. What we propose here is a method to reduce the size of the lattice, and thus simplify our view of the data, while conserving its formal structure and exhaustivity. For that purpose we use a preliminary partition of the instance set, representing the association of a ""type"" to each instance. By redefining the notion of extent of a term in order to cope, to a certain degree (denoted as α), with this partition, we define a particular family of Galois lattices denoted as alpha Galois lattices. We also discuss the related implication rules defined as inclusion of such α-extents."
NE369	International Conference on Data Mining	A. P. Topchy+M. H. C. Law+A. K. Jain+A. L. Fred	2004	Analysis of consensus partition in cluster ensemble	convergence properties + data mining + real-world data set + artificial data set + consensus function + supervised classifier systems + stochastic partition generation model + mean partition + pattern clustering + plurality voting + consensus partition + relabeling function + cluster ensemble + unsupervised clustering ensembles	AuthorProvided Keywords Not Found	"In combination of multiple partitions, one is usually interested in deriving a consensus solution with a quality better than that of given partitions. Several recent studies have empirically demonstrated improved accuracy of clustering ensembles on a number of artificial and real-world data sets. Unlike certain multiple supervised classifier systems, convergence properties of unsupervised clustering ensembles remain unknown for conventional combination schemes. In this paper, we present formal arguments on the effectiveness of cluster ensemble from two perspectives. The first is based on a stochastic partition generation model related to re-labeling and consensus function with plurality voting. The second is to study the property of the ""mean"" partition of an ensemble with respect to a metric on the space of all possible partitions. In both the cases, the consensus solution can be shown to converge to a true underlying clustering solution as the number of partitions in the ensemble increases. This paper provides a rigorous justification for the use of cluster ensemble."
5FBD9F11	International Conference on Data Mining	wai lam + taklam wong	2004	A probabilistic approach for adapting information extraction wrappers and discovering new attributes	attribute discovery + web pages + bayesian learning + data mining + probability + Bayesian learning + EM technique + text fragments + learning artificial intelligence + information extraction + information extraction wrappers + Web page + knowledge extraction + Bayes methods + Web sites + learning (artificial intelligence) + Web site + learned wrapper + wrapper adaptation	AuthorProvided Keywords Not Found	We develop a probabilistic framework for adapting information extraction wrappers with new attribute discovery. Wrapper adaptation aims at automatically adapting a previously learned wrapper from the source Web site to a new unseen site for information extraction. One unique characteristic of our framework is that it can discover new or previously unseen attributes as well as headers from the new site. It is based on a generative model for the generation of text fragments related to attribute items and formatting data in a Web page. To solve the wrapper adaptation problem, we consider two kinds of information from the source Web site. The first kind of information is the extraction knowledge contained in the previously learned wrapper from the source Web site. The second kind of information is the previously extracted or collected items. We employ a Bayesian learning approach to automatically select a set of training examples for adapting a wrapper for the new unseen site. To solve the new attribute discovery problem, we develop a model which analyzes the surrounding text fragments of the attributes in the new unseen site. A Bayesian learning method is developed to discover the new attributes and their headers. EM technique is employed in both Bayesian learning models. We conducted extensive experiments from a number of real-world Web sites to demonstrate the effectiveness of our framework.
7D44A108	International Conference on Data Mining	thomas hofmann + david gondek	2004	Non-redundant data clustering	text analysis + class structures + optimization scheme + class groupings + data mining + data clustering + knowledge discovery + nonredundant data clustering + conditional mutual information + pattern clustering + information bottleneck + computer vision + text mining + mutual information + coordinated conditional information bottleneck	AuthorProvided Keywords Not Found	Data clustering is a popular approach for automatically finding classes, concepts, or groups of patterns. In practice, this discovery process should avoid redundancies with existing knowledge about class structures or groupings, and reveal novel, previously unknown aspects of the data. In order to deal with this problem, we present an extension of the information bottleneck framework, called coordinated conditional information bottleneck, which takes negative relevance information into account by maximizing a conditional mutual information score subject to constraints. Algorithmically, one can apply an alternating optimization scheme that can be used in conjunction with different types of numeric and non-numeric attributes. We present experimental results for applications in text mining and computer vision.
5D7C34D8	International Conference on Data Mining	kotagiri ramamohanarao + hamad alhammady	2004	Using emerging patterns and decision trees in rare-class classification	pattern classification + decision tree + decision trees + rare-class classification + emerging patterns	AuthorProvided Keywords Not Found	The problem of classifying rarely occurring cases is faced in many real life applications. The scarcity of the rare cases makes it difficult to classify them correctly using traditional classifiers. In this paper, we propose an approach to use emerging patterns (EPs) (G. Dong and J. Li, 1999) and decision trees (DTs) in rare-class classification (EPDT). EPs are those itemsets whose supports in one class are significantly higher than their supports in the other classes. EPDT employs the power of EPs to improve the quality of rare-case classification. To achieve this aim, we first introduce the idea of generating nonexisting rare-class instances, and then we over-sample the most important rare-class instances. Our experiments show that EPDT outperforms many classification methods.
7D0904BF	International Conference on Data Mining	hanspeter kriegel + christian bohm + k railing + peer kroger	2004	Density connected clustering with local subspace preferences	feature space + clustering algorithm + density-based clustering + data mining + high-dimensional data + data clustering + feature spaces + local subspace preferences + high dimensional data + pattern clustering + subspace clustering + projected clustering + high point density	AuthorProvided Keywords Not Found	Many clustering algorithms tend to break down in high-dimensional feature spaces, because the clusters often exist only in specific subspaces (attribute subsets) of the original feature space. Therefore, the task of projected clustering (or subspace clustering) has been defined recently. As a solution to tackle this problem, we propose the concept of local subspace preferences, which captures the main directions of high point density. Using this concept, we adopt density-based clustering to cope with high-dimensional data. In particular, we achieve the following advantages over existing approaches: Our proposed method has a determinate result, does not depend on the order of processing, is robust against noise, performs only one single scan over the database, and is linear in the number of dimensions. A broad experimental evaluation shows that our approach yields results of significantly better quality than recent work on clustering high-dimensional data.
6ABD86F7	International Conference on Data Mining	ping sun	2004	Sparse kernel least squares classifier	pattern classification + learning algorithm + learning artificial intelligence + least squares approximations + recursive learning + sparse kernel least squares classifier + kernel matrix + large-scale problem + learning (artificial intelligence) + least square + data classification problem	AuthorProvided Keywords Not Found	In this paper, we propose a new learning algorithm for constructing kernel least squares classifier. The new algorithm adopts a recursive learning way and a novel two-step sparsification procedure is incorporated into learning phase. These two most important features not only provide a feasible approach for large-scale problems as it is not necessary to store the entire kernel matrix, but also produce a very sparse model with fast training and testing time. Experimental results on a number of data classification problems are presented to demonstrate the competitiveness of new proposed algorithm.
5C14C1D2	International Conference on Data Mining	michael baranski + jurgen voss	2004	Detecting patterns of appliances from total load data using a dynamic programming approach	nonintrusive appliance load monitoring + clustering method + appliance pattern detection + dynamic programming + time series + digital electricity meter + genetic algorithms + finite state machines + data collection + power engineering computing + domestic appliances + power consumption + time series optimization + load management + genetic algorithm + electric energy consumption + pattern clustering + viterbi algorithm + load forecasting + finite state machine	AuthorProvided Keywords Not Found	Nonintrusive appliance load monitoring (NIALM) systems require sufficient accurate total load data to separate the load into its major appliances. The most available solutions separate the whole electric energy consumption based on the measurement of all three voltages and currents. Aside from the cost for special measuring devices, the intrusion into the local installation is the main problem for reaching a high market distribution. The use of standard digital electricity meters could avoid this problem but the loss of information of the measured data has to be compensated by more intelligent algorithms and implemented rules to disaggregate the total load trace of only the active power measurements. The paper presents a NIALM approach to analyse data, collected from a standard digital electricity meter. To disaggregate the consumption of the entire active power into its major electrical end uses, an algorithm consisting of clustering methods, a genetic algorithm and a dynamic programming approach is presented. The genetic algorithm is used to combine frequently occurring events to create hypothetical finite state machines to model detectable appliances. The time series of each finite state machine is optimized using a dynamic programming method similar to the viterbi algorithm.
59A12941	International Conference on Data Mining	luonan chen + zhifang huang + jy cai + james j schauer + r ramakrishnan + david gross + david r musicant + stephen j wright	2004	Mass spectrum labeling: theory and practice	data analysis + data mining + mass spectra + machine learning + monitoring + mass spectroscopy + physics computing + mass spectrum labeling + real-time environmental monitoring + spectrum + formal representations + real time + environmental management	AuthorProvided Keywords Not Found	We introduce the problem of labeling a particle's mass spectrum with the substances it contains, and develop several formal representations of the problem, taking into account practical complications such as unknown compounds and noise. This task is currently a bottle-neck in analyzing data from a new generation of instruments for real-time environmental monitoring.
5B3C4B94	International Conference on Data Mining	william s yerazunis + christian siefkes + shalendra chhabra	2004	Spam filtering using a Markov random field model with variable weighting schemas	side effect + pattern classification + spam classification + markov processes + variable weighting schemas + Markov processes + unsolicited e-mail + information filtering + spam filtering + Markov random field + email	AuthorProvided Keywords Not Found	In this paper we present a Markov random field model based approach to filter spam. Our approach examines the importance of the neighborhood relationship (MRF cliques) among words in an email message for the purpose of spam classification. We propose and test several different theoretical bases for weighting schemes among corresponding neighborhood windows. Our results demonstrate that unexpected side effects depending on the neighborhood window size may have larger accuracy impact than the neighborhood relationship effects of the Markov random field.
61E5B169	International Conference on Data Mining	daniel venese + eric bloedorn + lowell rosen + jianping zhang	2004	Learning rules from highly unbalanced data sets	law administration + learning artificial intelligence + data mining + pattern discovery + unbalanced data sets + learning (artificial intelligence) + exhaustive search + fraudulent transaction + law enforcement problem + rule learning algorithm	AuthorProvided Keywords Not Found	This paper presents a simple and effective rule learning algorithm for highly unbalanced data sets. By using the small size of the minority class to its advantage this algorithm can conduct an almost exhaustive search for patterns within the known fraudulent cases. This algorithm was designed for and successfully applied to a law enforcement problem, which involves discovering common patterns of fraudulent transactions.
5CF78874	International Conference on Data Mining	feng zhang	2004	A polygonal line algorithm based nonlinear feature extraction method	nonlinear data structure + data structure + principal curve algorithm + computational geometry + polygonal line algorithm based nonlinear feature extraction + nonlinear curve estimation + high dimensional data + feature extraction + polynomial approximation + multivariate data + curve fitting + linear model + statistical redundancy elimination + sample size + principal component analysis + computational complexity	AuthorProvided Keywords Not Found	We propose a polygonal line based principal curve algorithm for nonlinear feature extraction, in which the nonlinearities among the multivariable data can be described by a set of local linear models. The proposed algorithm integrates the linear PCA approach with the polygonal line algorithm to represent complicated nonlinear data structure. Statistical redundancy elimination for high dimensional data is also discussed for describing the underlying principal curves without much loss of information among the original data sets. The polygonal line algorithm can produce robust and accurate nonlinear curve estimation for different multivariate data types, and it is helpful in reducing the computation complexity for existing principal curve approaches when the sample size is large.
5AB782C5	International Conference on Data Mining	vasant honavar + jun zhang	2004	AVT-NBL: an algorithm for learning compact and accurate naive Bayes classifiers from attribute value taxonomies and data	AVT-NBL algorithm + pattern classification + learning artificial intelligence + classifier learning + bayes classifier + naive Bayes classification + Bayes methods + learning (artificial intelligence) + attribute value taxonomies	AuthorProvided Keywords Not Found	In many application domains, there is a need for learning algorithms that can effectively exploit attribute value taxonomies (AVT) - hierarchical groupings of attribute values - to learn compact, comprehensible, and accurate classifiers from data - including data that are partially specified. This paper describes AVT-NBL, a natural generalization of the naive Bayes learner (NBL), for learning classifiers from AVT and data. Our experimental results show that AVT-NBL is able to generate classifiers that are substantially more compact and more accurate than those produced by NBL on a broad range of data sets with different percentages of partially specified values. We also show that AVT-NBL is more efficient in its use of training data: AVT-NBL produces classifiers that outperform those produced by NBL using substantially fewer training examples.
5E3F1662	International Conference on Data Mining	francois poulet	2004	SVM and graphical algorithms: a cooperative approach	graphical algorithm + visualization method + visualization tool + support vector machines + support vector machine + data visualisation + SVM parameter tuning + cooperative approach + frontier quality	AuthorProvided Keywords Not Found	"We present a cooperative approach using both support vector machine (SVM) algorithms and visualization methods. SVM are widely used today and often give high quality results, but they are used as ""black-box"" (it is very difficult to explain the obtained results) and cannot treat easily very large datasets. We have developed graphical methods to help the user to evaluate and explain the SVM results. The first method is a graphical representation of the separating frontier quality, it is then linked with other visualization tools to help the user explaining SVM results. The information provided by these graphical methods is also used for SVM parameter tuning, they are then used together with automatic algorithms to deal with very large datasets on standard computers. We present an evaluation of our approach with the UCI and the Kent Ridge Bio-medical data sets."
6AD54F7D	International Conference on Data Mining	pierre geurts + guy leduc + i el khayat	2004	A machine learning approach to improve congestion control over wireless computer networks	TCP + pattern classification + telecommunication congestion control + computer networks + decision tree boosting + congestion control + telecommunication network topology + random network topologies + wireless networks + wireless computer networks + machine learning + link errors + loss classifier + computer network + learning artificial intelligence + decision tree + satisfiability + wired network + decision trees + wireless network + learning (artificial intelligence)	AuthorProvided Keywords Not Found	In this paper, we present the application of machine learning techniques to the improvement of the congestion control of TCP in wired/wireless networks. TCP is sub-optimal in hybrid wired/wireless networks because it reacts in the same way to losses due to congestion and losses due to link errors. We thus propose to use machine learning techniques to build automatically a loss classifier from a database obtained by simulations of random network topologies. Several machine learning algorithms are compared for this task and the best method for this application turns out to be decision tree boosting. It outperforms ad hoc classifiers proposed in the networking literature.
6E62A35B	International Conference on Data Mining	baoying wang + william perrizo + dongmei ren	2004	RDF: a density-based outlier detection method using vertical data representation	relative density + data representation + density-based outlier detection + data mining + trees (mathematics) + vertical data representation + RDF-based outlier detection + relative density factor + P-trees + outlier detection + credit transactions + very large databases + fraud + credit card fraud + electronic commerce	AuthorProvided Keywords Not Found	Outlier detection can lead to discovering unexpected and interesting knowledge, which is critical important to some areas such as monitoring of criminal activities in electronic commerce, credit card fraud, etc. In this paper, we developed an efficient density-based outlier detection method for large datasets. Our contributions are: a) we introduce a relative density factor (RDF); b) based on RDF, we propose an RDF-based outlier detection method which can efficiently prune the data points which are deep in clusters, and detect outliers only within the remaining small subset of the data; c) the performance of our method is further improved by means of a vertical data representation, P-trees. We tested our method with NHL and NBA data. Our method shows an order of magnitude speed improvement compared to the contemporary approaches.
5CBBFAF1	International Conference on Data Mining	dawit seid + s c mehrotra	2004	Efficient relationship pattern mining using multi-relational iceberg-cubes	multirelational iceberg-cubes + multiple database relation + relationship pattern mining + multirelational data mining + data mining + relational databases + data cube	AuthorProvided Keywords Not Found	"Multi-relational data mining (MRDM) is concerned with data that contains heterogeneous and semantically rich relationships among various entity types. In this paper, we introduce multi-relational iceberg-cubes (MRI-Cubes) as a scalable approach to efficiently compute data cubes (aggregations) over multiple database relations and, in particular, as mechanisms to compute frequent multi-relational patterns (""item sets""). We also present a summary of performance results of our algorithm."
58B7CC82	International Conference on Data Mining	peter i cowling + fadi thabtah + yonghong peng	2004	MMAC: a new multi-class, multi-label associative classification approach	classification technique + pattern classification + large-scale databases + multiclass multilabel associative classification + multiple labels + very large databases + data mining + MMAC + association rule mining	AuthorProvided Keywords Not Found	Building fast and accurate classifiers for large-scale databases is an important task in data mining. There is growing evidence that integrating classification and association rule mining together can produce more efficient and accurate classifiers than traditional classification techniques. In this paper, the problem of producing rules with multiple labels is investigated. We propose a new associative classification approach called multi-class, multi-label associative classification (MMAC). This paper also presents three measures for evaluating the accuracy of data mining classification approaches to a wide range of traditional and multi-label classification problems. Results for 28 different datasets show that the MMAC approach is an accurate and effective classification technique, highly competitive and scalable in comparison with other classification approaches.
5AECB60F	International Conference on Data Mining	stefan kramer + ulrich ruckert + lothar richter	2004	Quantitative association rules based on half-spaces: an optimization approach	association rule + optimisation + gradient descent algorithm + score function + optimization + data mining + locally optimal rules + hyper rectangles + downward closure property + gradient descent + gradient methods + quantitative association rules	AuthorProvided Keywords Not Found	We tackle the problem of finding association rules for quantitative data. Whereas most of the previous approaches operate on hyper rectangles, we propose a representation based on half-spaces. Consequently, the left-hand side and right-hand side of an association rule does not contain a conjunction of items or intervals, but a weighted sum of variables tested against a threshold. Since the downward closure property does not hold for such rules, we propose an optimization setting for finding locally optimal rules. A simple gradient descent algorithm optimizes a parameterized score function, where iterations optimizing the first separating hyperplane alternate with iterations optimizing the second. Experiments with two real-world data sets show that the approach finds non-random patterns and scales up well. We therefore propose quantitative association rules based on half-spaces as an interesting new class of patterns with a high potential for applications.
63E45099	International Conference on Data Mining	frans coenen + paul leng	2004	An evaluation of approaches to classification rule selection	classification rule ordering + pattern classification + data mining + classification rule evaluation measures + classification rule selection	Classification rule evaluation measures	In this paper a number of classification rule evaluation measures are considered. In particular the authors review the use of a variety of selection techniques used to order classification rules contained in a classifier, and a number of mechanisms used to classify unseen data. The authors demonstrate that rule ordering founded on the size of antecedent works well given certain conditions.
5A31E85E	International Conference on Data Mining	giancarlo raiconi + d di bernardo + ciro donalek + angelo ciaramella + gennaro miele + roberto tagliaferri + l de vinco + robert j d amato + antonino staiano + g longo	2004	Probabilistic principal surfaces for yeast gene microarray data mining	chip + probabilistic principal surfaces + data analysis + scientific research + clustering tool + microarray data + data mining + probability + microarray chip + astronomy + yeast gene microarray + general computational tools + genetics + biology computing + pattern clustering + data visualisation + data visualization + computability theory + gene expression + general computational theories	AuthorProvided Keywords Not Found	The recent technological advances are producing huge data sets in almost all fields of scientific research, from astronomy to genetics. Although each research field often requires ad-hoc, fine tuned, procedures to properly exploit all the available information inherently present in the data, there is an urgent need for a new generation of general computational theories and tools capable to boost most human activities of data analysis. Here, we propose probabilistic principal surfaces (PPS) as an effective high-D data visualization and clustering tool for data mining applications, emphasizing its flexibility and generality of use in data-rich field. In order to better illustrate the potentialities of the method, we also provide a real world case-study by discussing the use of PPS for the analysis of yeast gene expression levels from microarray chips.
5C07FCE0	International Conference on Data Mining	l n de castro + ricardo j g b campello + estevam r hruschka	2004	Evolutionary algorithms for clustering gene-expression data	genetic algorithm + biology + pattern clustering + bioinformatics + evolutionary algorithms + gene-expression data clustering + genetic algorithms + clustering genetic algorithm + evolutionary algorithm + gene expression	AuthorProvided Keywords Not Found	This work deals with the problem of automatically finding optimal partitions in bioinformatics datasets. We propose incremental improvements for a clustering genetic algorithm (CGA) culminating in the evolutionary algorithm for clustering (EAC). The CGA and its modified versions are evaluated in five gene-expression datasets, showing that the proposed EAC is a promising tool for clustering gene-expression data.
5E6A534D	International Conference on Data Mining	wei fan + yian huang + philip s yu	2004	Decision tree evolution using limited number of labeled data items from drifting data streams	data stream mining + decision tree + demand-driven active data mining + drifting data streams + data mining + labeled data + decision trees + decision tree evolution	AuthorProvided Keywords Not Found	"Most previously proposed mining methods on data streams make an unrealistic assumption that ""labelled"" data stream is readily available and can be mined at anytime. However, in most real-world problems, labelled data streams are rarely immediately available. Due to this reason, models are reconstructed only when labelled data become available periodically. This passive stream mining model has several drawbacks. We propose a concept of demand-driven active data mining. In active mining, the loss of the model is either continuously guessed without using any true class labels or estimated, whenever necessary, from a small number of instances whose actual class labels are verified by paying an affordable cost. When the estimated loss is more than a tolerable threshold, the model evolves by using a small number of instances with verified true class labels. Previous work on active mining concentrates on error guess and estimation. In this paper, we discuss several approaches on decision tree evolution."
59AAE389	International Conference on Data Mining	ning zhong + muneaki ohshima + jiajin huang + y y yao + mingxin huang + chunnian liu	2004	Relational peculiarity oriented data mining	data mining + peculiarity rules + relational databases + attribute-based approach + relational peculiarity oriented data mining + peculiarity identification	AuthorProvided Keywords Not Found	Peculiarity rules are a new type of interesting rules which can be discovered by searching the relevance among peculiar data. A main task of mining peculiarity rules is the identification of peculiarity. Traditional methods of finding peculiar data are attribute-based approaches. This paper extends peculiarity oriented mining to relational peculiarity oriented mining. Peculiar data are identified on record level, and peculiar rules are mined and explained in a relational mining framework. The results from preliminary experiments show that relational peculiarity oriented mining is very effective.
58853E0E	International Conference on Data Mining	sian se cox + david g lindsay	2004	Improving the reliability of decision tree and naive Bayes learners	laplace transform + probability + reliability theory + Laplace transforms + receiver operator characteristic curves + simple binning + laplace transforms + naive Bayes learners + loss function + learning artificial intelligence + decision tree + Venn probability machine meta-learner + error rate + naive bayes + unreliable probability forecast + forecasting theory + decision trees + empirical reliability curves + Bayes methods + roc curve + learning (artificial intelligence) + Laplace transform	AuthorProvided Keywords Not Found	The C4.5 decision tree and naive Bayes learners are known to produce unreliable probability forecasts. We have used simple binning (Zadrozny and Elkan, 2001) and Laplace transform (Cestnik, 2001) techniques to improve the reliability of these learners and compare their effectiveness with that of the newly developed Venn probability machine (VPM) meta-learner (Vovk et al., 2003). We assess improvements in reliability using loss functions, receiver operator characteristic (ROC) curves and empirical reliability curves (ERC). The VPM outperforms the simple techniques to improve reliability, although at the cost of increased computational intensity and slight increase in error rate. These trade-offs are discussed.
58E69F30	International Conference on Data Mining	qiang yang + yidong shen + shiming zhang + zhiyong shen	2004	Cluster cores-based clustering for high dimensional data	semantics-based similarity measure + nearest neighbor + clustering algorithm + high dimensional data + curse of dimensionality + data mining + time complexity + cluster cores-based clustering + computational complexity	AuthorProvided Keywords Not Found	We propose a new approach to clustering high dimensional data based on a novel notion of cluster cores, instead of on nearest neighbors. A cluster core is a fairly dense group with a maximal number of pairwise similar objects. It represents the core of a cluster, as all objects in a cluster are with a great degree attracted to it. As a result, building clusters from cluster cores achieves high accuracy. Other major characteristics of the approach include: (1) It uses a semantics-based similarity measure. (2) It does not incur the curse of dimensionality and is scalable linearly with the dimensionality of data. (3) It outperforms the well-known clustering algorithm, ROCK, with both lower time complexity and higher accuracy.
5D32AAA5	International Conference on Data Mining	xindong wu + xingquan zhu	2004	Cost-guided class noise handling for effective cost-sensitive learning	cost-guided iterative classification filter + pattern classification + comparative study + learning artificial intelligence + effective cost-sensitive learning + noise identification + cost-sensitive classification + data mining + noise + cost-guided class noise handling + machine learning + learning (artificial intelligence)	AuthorProvided Keywords Not Found	Research in machine learning, data mining and related areas has produced a wide variety of algorithms for cost-sensitive (CS) classification, where instead of maximizing the classification accuracy, minimizing the misclassification cost becomes the objective. However, these methods assume that training sets do not contain significant noise, which is rarely the case in real-world environments. In this paper, we systematically study the impacts of class noise on CS learning, and propose a cost-guided class noise handling algorithm to identify noise for effective CS learning. We call it cost-guided iterative classification filter (CICF), because it seamlessly integrates costs and an existing classification filter (C. Brodley and M. Friedl, 1999) for noise identification. Instead of putting equal weights to handle noise in all classes in existing efforts, CICF puts more emphasis on expensive classes, which makes it especially successful in dealing with datasets with a large cost-ratio. Experimental results and comparative studies from real-world datasets indicate that the existence of noise may seriously corrupt the performance of CS classifiers, and by adopting the proposed CICF algorithm, we can significantly reduce the misclassification cost of a CS classifier in noisy environments.
5D490428	International Conference on Data Mining	nenad stojanovic	2004	On ranking refinements in the step-by-step searching through a product catalogue	formal logic + cataloguing + ontology-based queries + logic-based approach + information content + ranking refinements + ontologies (artificial intelligence) + step-by-step searching + search problems + product catalogue	AuthorProvided Keywords Not Found	In our previous work we have developed a logic-based approach for the refinement of ontology-based queries that enables a user to search through a repository in a step-by-step fashion. Since the set of refinements in a step can be large, they should be ranked according to their relevance for fulfilling a user's need. In this paper we present such a ranking model, which takes into account the information content (informativeness) of a refinement as well as the preferences of the user.
591C5E33	International Conference on Data Mining	chih lai + ninh t nguyen	2004	Predicting density-based spatial clusters over time	clustering algorithm + pattern clustering + cluster evolution prediction + data mining + density-based spatial cluster + statistical analysis + snapshot cluster discovery	AuthorProvided Keywords Not Found	Most of existing clustering algorithms are designed to discover snapshot clusters that reflect only the current status of a database. Snapshot clusters do not reveal the fact that clusters may either persist over a period of time, or slowly fade away as other clusters may gradually develop. Predicting dynamic cluster evolutions and their occurring periods are important because this information can guide users to prepare appropriate actions toward the right areas during the right time for the most effective results. In this paper we developed a simple but effective approach in predicting the future distance among object pairs. Objects that will be close in distance over different periods of time are then processed to discover density-based clusters that may occur or change over time.
5CF37B4E	International Conference on Data Mining	bjorn bringmann	2004	Matching in frequent tree discovery	tree matching + pattern matching + TreeMinerV algorithm + data mining + trees (mathematics) + frequent tree discovery + tree mining	AuthorProvided Keywords Not Found	Various definitions and frameworks for discovering frequent trees in forests have been developed. At the heart of these frameworks lies the notion of matching, which determines when a pattern tree matches a tree in a data set. We introduce a notion of tree matching for use in frequent tree mining and we show that it generalizes the framework of Zaki while still being more specific than that of Termier et al. Furthermore, we show how Zaki's TreeMinerV algorithm can be adapted towards our notion of tree matching. Experiments show the promise of the approach.
738DCC84	International Conference on Data Mining	dou shen + weiying ma + qiang yang + zheng chen + yong yu + wensi xi + huajun zeng + guirong xue	2004	IRC: an iterative reinforcement categorization algorithm for interrelated Web objects	search engine + iterative reinforcement categorization + interrelated Web objects + classification + Web sites	AuthorProvided Keywords Not Found	Most existing categorization algorithms deal with homogeneous Web data objects, and consider interrelated objects as additional features when taking the interrelationships with other types of objects into account. However, focusing on any single aspects of these interrelationships and objects does not fully reveal their true categories. In this paper, we propose a categorization algorithm, the iterative reinforcement categorization algorithm (IRC), to exploit the full interrelationships between the heterogeneous objects on the Web. IRC attempts to classify the interrelated Web objects by iterative reinforcement between individual classification results of different types via the interrelationships. Experiments on a clickthrough log dataset from MSN search engine show that, with the Fl measures, IRC achieves a 26.4% improvement over a pure content-based classification method, a 21% improvement over a query metadata-based method, and a 16.4% improvement over a virtual document-based method. Furthermore, our experiments show that IRC converges rapidly.
5E90147F	International Conference on Data Mining	mariechristine rousset + alexandre termier + michele sebag	2004	Dryade: a new approach for discovering closed frequent trees in heterogeneous tree databases	information extraction + tree pattern discovery + tree structure + relaxed tree inclusion + data mining + trees (mathematics) + closed frequent tree discovery + xml document + heterogeneous tree databases + NP-complete problem + computational complexity + Dryade	AuthorProvided Keywords Not Found	In this paper we present a novel algorithm for discovering tree patterns in a tree database. This algorithm uses a relaxed tree inclusion definition, making the problem more complex (checking tree inclusion is NP-complete), but allowing to mine highly heterogeneous databases. To obtain good performances, our DRYADE algorithm, discovers only closed frequent tree patterns.
59282645	International Conference on Data Mining	terumasa aoki + alejandro bassi + hiroshi yasuda + juan d velasquez	2004	Mining Web data to create online navigation recommendations	anonymous user + Web data mining + browsing behavior + clustering technique + online navigation recommendation + data mining + Web logs + Web visitors + Internet + information filters + internet	AuthorProvided Keywords Not Found	A system to provide online navigation recommendation for Web visitors is introduced. We call visitor the anonymous user, i.e., when only data about her/his browsing behavior (Web logs) are available. We first apply clustering techniques over a large sample of Web data. Next, from the significant patterns that are discovered, a set of rules about how to use them is created. Finally, comparing the current Web visitor session with the patterns, online navigation recommendations are proposed using the mentioned rules. The system was tested using data from a real Web site, showing its effectiveness.
5D06E960	International Conference on Data Mining	akihiro inokuchi	2004	Mining generalized substructures from a set of labeled graphs	graph mining + labeled graphs + transaction data + pattern mining + graph theory + data mining + frequent substructure mining + frequent itemset mining + generalized substructure mining	AuthorProvided Keywords Not Found	"The problem of mining frequent itemsets in transactional data has been studied frequently and has yielded several algorithms that can find the itemsets within a limited amount of time. Some of them can derive ""generalized"" frequent itemsets consisting of items at any level of a taxonomy (Srikant and Agrawal, 1995). Several approaches have been proposed to mine frequent substructures (patterns) from a set of labeled graphs. The graph mining approaches are easily extended to mine generalized patterns where some vertices and/or edges have labels at any level of a taxonomy of the labels by extending the definition of ""subgraph"". However, the extended method outputs a massive set of the patterns most of which are over-generalized, which causes computation explosion. In this paper, an efficient method is proposed to discover all frequent patterns which are not over-generalized from labeled graphs, when taxonomies on vertex and edge labels are available."
5E01B68D	International Conference on Data Mining	anthony k h tung + gao cong + kianlee tan + feng pan	2004	Mining frequent closed patterns in microarray data	spatial data structures + item enumeration space + microarray data + row enumeration space + data mining + frequent closed pattern mining + pattern discovery + real-life gene expression data	AuthorProvided Keywords Not Found	Microarray data typically contains a large number of columns and a small number of rows, which poses a great challenge for existing frequent (closed) pattern mining algorithms that discover patterns in item enumeration space. In this paper, we propose two algorithms that explore the row enumeration space to mine frequent closed patterns. Several experiments on real-life gene expression data show that the algorithms are faster than existing algorithms, including CLOSET, CHARM, CLOSET+ and CARPENTER.
7EA864E1	International Conference on Data Mining	jennifer neville + david jensen	2004	Dependency networks for relational data	instance independence + machine learning + classification + relational databases + inference mechanisms + RDN models + real-world datasets + model learning + relational dependency networks + relational data + learning artificial intelligence + synthetic data + graphical model + graphical models + cyclic relational dependencies + inference procedures + learning (artificial intelligence)	AuthorProvided Keywords Not Found	Instance independence is a critical assumption of traditional machine learning methods contradicted by many relational datasets. For example, in scientific literature datasets, there are dependencies among the references of a paper. Recent work on graphical models for relational data has demonstrated significant performance gains for models that exploit the dependencies among instances. In this paper, we present relational dependency networks (RDNs), a new form of graphical model capable of reasoning with such dependencies in a relational setting. We describe the details of RDN models and outline their strengths, most notably the ability to learn and reason with cyclic relational dependencies. We present RDN models learned on a number of real-world datasets, and evaluate the models in a classification context, showing significant performance improvements. In addition, we use synthetic data to evaluate the quality of model learning and inference procedures.
6BEC4534	International Conference on Data Mining	chunyi shi + weiying ma + zheng chen + yuchang lu + huajun zeng + jiantao sun	2004	Supervised latent semantic indexing for document categorization	document handling + latent semantic indexing + indexing + supervised latent semantic indexing + document representation + discriminative basis vectors + information retrieval + dimension-reduced space + document categorization + machine learning + dimension reduction	AuthorProvided Keywords Not Found	Latent semantic indexing (LSI) is a successful technology in information retrieval (IR) which attempts to explore the latent semantics implied by a query or a document through representing them in a dimension-reduced space. However, LSI is not optimal for document categorization tasks because it aims to find the most representative features for document representation rather than the most discriminative ones. In this paper, we propose supervised LSI (SLSI) which selects the most discriminative basis vectors using the training data iteratively. The extracted vectors are then used to project the documents into a reduced dimensional space for better classification. Experimental evaluations show that the SLSI approach leads to dramatic dimension reduction while achieving good classification results.
5C3C6F9D	International Conference on Data Mining	david f gleich + leonid zhukov	2004	SVD based term suggestion and ranking system	ranking system + clustered data structure + orthogonal subspace projections + search term suggestion + advertising + pay-for-performance search market + query formulation + singular value decomposition + search problems	AuthorProvided Keywords Not Found	In this paper, we consider the application of the singular value decomposition (SVD) to a search term suggestion system in a pay-for-performance search market. We propose a positive and negative refinement method based on orthogonal subspace projections. We demonstrate that SVD subspace-based methods: 1) expand coverage by reordering the results, and 2) enhance the clustered structure of the data. The numerical experiments reported in this paper were performed on Overture's pay-per-performance search market data.
5BA53BE7	International Conference on Data Mining	gang wu + edward y chang	2004	Aligning boundary in kernel space for learning imbalanced dataset	kernel boundary alignment + learning artificial intelligence + support vector machines + imbalanced dataset learning + supervised learning + kernel matrix + empirical study + SVM + training-data imbalance + learning (artificial intelligence) + class prediction + matrix algebra	AuthorProvided Keywords Not Found	An imbalanced training dataset poses serious problem for many real-world supervised learning tasks. In this paper, we propose a kernel-boundary-alignment algorithm, which considers training-data imbalance as prior information to augment SVMs to improve class-prediction accuracy. Using a simple example, we first show that SVMs can suffer from high incidences of false negatives when the training instances of the target class are heavily outnumbered by the training instances of a nontarget class. The remedy we propose is to adjust the class boundary by modifying the kernel matrix, according to the imbalanced data distribution. Through theoretical analysis backed by empirical study, we show that our kernel-boundary-alignment algorithm works effectively on several datasets.
5C4916FC	International Conference on Data Mining	hanspeter kriegel + stefan brecheisen + martin pfeifle	2004	Efficient density-based clustering of complex objects	distance function + clustering algorithm + density-based clustering + multistep query processing + complex distance function + data mining + DBSCAN + lower bound + range query + complex distance computations + query processing + complex object representation + pattern clustering + very large databases + test data sets + OPTICS + approximative distance function + large databases + complex distance measures	AuthorProvided Keywords Not Found	Nowadays, data mining in large databases of complex objects from scientific, engineering or multimedia applications is getting more and more important. In many different application domains, complex object representations along with complex distance functions are used for measuring the similarity between objects. Often, not only these complex distance measures are available but also simpler distance functions which can be computed much more efficiently. Traditionally, the well known concept of multi-step query processing which is based on exact and lower-bounding approximative distance functions are used independently of data mining algorithms. In this paper, we demonstrate how the paradigm of multi-step query processing can be integrated into the two density-based clustering algorithms DBSCAN and OPTICS resulting in a considerable efficiency boost. Our approach tries to confine itself to ε-range queries on the simple distance functions and carries out complex distance computations only at that stage of the clustering algorithm where they are compulsory to compute the correct clustering result. In a broad experimental evaluation based on real-world test data sets, we demonstrate that our approach accelerates the generation of flat and hierarchical density-based clusterings by more than one order of magnitude.
5AEF4713	International Conference on Data Mining	jaideep vaidya + chris clifton	2004	Privacy-preserving outlier detection	national security + data mining + homogeneous data distribution + knowledge discovery + outlier detection + security of data + very large databases + large distributed databases + distributed databases + data privacy + heterogeneous data distribution + privacy-preserving outlier detection + data sharing	AuthorProvided Keywords Not Found	Outlier detection can lead to the discovery of truly unexpected knowledge in many areas such as electronic commerce, credit card fraud and especially national security. We look at the problem of finding outliers in large distributed databases where privacy/security concerns restrict the sharing of data. Both homogeneous and heterogeneous distribution of data is considered. We propose techniques to detect outliers in such scenarios while giving formal guarantees on the amount of information disclosed.
5BC7B885	International Conference on Data Mining	paul mccullagh + yihua huang + n d black	2004	Feature selection via supervised model construction	data mining + supervised model construction + starter selection + data transformation + classification + feature selection + ReliefF + feature mining	ReliefF,+Feature Selection	ReliefF is a feature mining technique, which has been successfully used in data mining applications. However, ReliefF is sensitive to the definition of relevance that is used in its implementation and when handling a large data set, it is computationally expensive. This paper presents an optimisation (feature selection via supervised model construction) for data transformation and starter selection, and evaluates its effectiveness with C4.5. Experiments indicate that the proposed method gave improvement of computation efficiency whilst maintaining classification accuracy of trial data sets.
5F8BE84C	International Conference on Data Mining	zhenqiu liu + jens gregor	2004	A Bayesian framework for regularized SVM parameter estimation	soft margin classifier + pattern classification + support set + regularized SVM + support vector machines + support vector machine + nonseparable learning samples + public domain + Bayesian framework + parameter estimation + Bayes methods	AuthorProvided Keywords Not Found	The support vector machine (SVM) is considered here in the context of pattern classification. The emphasis is on the soft margin classifier which uses regularization to handle non-separable learning samples. We present an SVM parameter estimation algorithm that first identifies a subset of the learning samples that we call the support set and then determines not only the weights of the classifier but also the hyperparameter that controls the influence of the regularizing penalty term on basis thereof. We provide numerical results using several data sets from the public domain.
5E40221B	International Conference on Data Mining	christos faloutsos + hyungjeong yang + jiayu pan	2004	MMSS: multi-modal story-oriented video summarization	multi-modal story-oriented video summarization + MMSS + graph theory + video retrieval + image retrieval + fine-tuned domain-specific heuristics + video signal processing + domain-independent graph-based framework	AuthorProvided Keywords Not Found	We propose multi-modal story-oriented video summarization (MMSS) which, unlike previous works that use fine-tuned, domain-specific heuristics, provides a domain-independent, graph-based framework. MMSS uncovers correlation between information of different modalities which gives meaningful story-oriented news video summaries. MMSS can also be applied for video retrieval, giving performance that matches the best traditional retrieval techniques (OKAPI and LSI), with no fine-tuned heuristics such as tf/idf.
5E244590	International Conference on Data Mining	sanjay chawla + pei sun	2004	On local spatial outliers	SLOM + very large databases + data mining + large data sets + spatial neighborhood + visual databases + local spatial outliers + spatial local outlier measure	AuthorProvided Keywords Not Found	"We propose a measure, spatial local outlier measure (SLOM) which captures the local behaviour of datum in their spatial neighborhood. With the help of SLOM, we are able to discern local spatial outliers which are usually missed by global techniques like ""three standard deviations away from the mean"". Furthermore, the measure takes into account the local stability around a data point and supresses the reporting of outliers in highly unstable areas, where data is too heterogeneous and the notion of outliers is not meaningful. We prove several properties of SLOM and report experiments on synthetic and real data sets which show that our approach is scalable to large data sets."
5F338152	International Conference on Data Mining	rui camacho + a c alves + eugenio oliveira	2004	Discovery of functional relationships in multi-relational data using inductive logic programming	PAC method + statistical-based techniques + data mining + search stopping + regression analysis + model selection + machine learning + relational databases + inference mechanisms + relational data + learning artificial intelligence + model validation + functional relationship discovery + noise handling + regression tasks + multirelational data + numerical reasoning + learning (artificial intelligence) + inductive logic programming	AuthorProvided Keywords Not Found	ILP systems have been largely applied to data mining classification tasks with a considerable success. The use of ILP systems in regression tasks has been far less successful. Current systems have very limited numerical reasoning capabilities, which limits the application of ILP to discovery of functional relationships of numeric nature. This paper proposes improvements in numerical reasoning capabilities of ILP systems for dealing with regression tasks. It proposes the use of statistical-based techniques like model validation and model selection to improve noise handling and it introduces a search stopping criterium based on the PAC method to evaluate learning performance. We have found these extensions essential to improve on results over machine learning and statistical-based algorithms used in the empirical evaluation study.
59603B69	International Conference on Data Mining	sheng ma + tao li	2004	Mining temporal patterns without predefined time windows	pattern classification + dependence problem + temporal pattern mining + data mining + chi square test + cheap statistics + statistical distributions + candidates removal + temporal pattern discovery + distance method + probability distributions + chi-squared test + predefined time windows + probability distribution + dependence testing	AuthorProvided Keywords Not Found	"This paper proposes algorithms for discovering temporal patterns without predefined time windows. The problem of discovering temporal patterns is divided into two sub-tasks: (1) using ""cheap statistics"" for dependence testing and candidates removal, (2) identifying the temporal relationships between dependent event types. The dependence problem is formulated as the problem of comparing two probability distributions and is solved using a technique reminiscent of the distance methods used in spatial point process, while the latter problem is solved using an approach based on chi-squared tests. Experiments are conducted to evaluate the effectiveness and scalability of the proposed methods."
5D8A55C1	International Conference on Data Mining	haixun wang + richard r muntz + philip s yu + yun chi	2004	Moment: maintaining closed frequent itemsets over a stream sliding window	transaction processing + data mining + trees (mathematics) + data structure + closed enumeration tree + limited memory space + sliding window + closed frequent itemset mining + compact data structure + moment + stream sliding window + time constraint + concept drift + Moment + mining transactions + memory constraint + synopsis data structure + data structures	AuthorProvided Keywords Not Found	This paper considers the problem of mining closed frequent itemsets over a sliding window using limited memory space. We design a synopsis data structure to monitor transactions in the sliding window so that we can output the current closed frequent itemsets at any time. Due to time and memory constraints, the synopsis data structure cannot monitor all possible itemsets. However, monitoring only frequent itemsets make it impossible to detect new itemsets when they become frequent. In this paper, we introduce a compact data structure, the closed enumeration tree (CET), to maintain a dynamically selected set of item-sets over a sliding-window. The selected itemsets consist of a boundary between closed frequent itemsets and the rest of the itemsets. Concept drifts in a data stream are reflected by boundary movements in the CET. In other words, a status change of any itemset (e.g., from non-frequent to frequent) must occur through the boundary. Because the boundary is relatively stable, the cost of mining closed frequent item-sets over a sliding window is dramatically reduced to that of mining transactions that can possibly cause boundary movements in the CET. Our experiments show that our algorithm performs much better than previous approaches.
5CB76D7F	International Conference on Data Mining	srinivasan parthasarathy + hui yang + sameep mehta	2004	Correlation preserving discretization	data mining + frequent item set mining + data warehousing + PCA-based unsupervised algorithm + classification + missing data + multivariate dataset + correlation structure + unsupervised discretization + correlation preserving discretization + data warehouses + principal component analysis + missing values	Missing Data,+Unsupervised Discretization	Discretization is a crucial preprocessing primitive for a variety of data warehousing and mining tasks. In this article we present a novel PCA-based unsupervised algorithm for the discretization of continuous attributes in multivariate datasets. The algorithm leverages the underlying correlation structure in the dataset to obtain the discrete intervals, and ensures that the inherent correlations are preserved. The approach also extends easily to datasets containing missing values. We demonstrate the efficacy of the approach on real datasets and as a preprocessing step for both classification and frequent item set mining tasks. We also show that the intervals are meaningful and can uncover hidden patterns in data.
6649FB80	International Conference on Data Mining	ruslan salakhutdinov + grigoris j karakoulas	2004	Semi-supervised mixture-of-experts classification	semi supervised learning + pattern classification + model variance + semisupervised learning + bias-variance decomposition + bias error term + mixture model + mixture modeling + learning artificial intelligence + semisupervised mixture-of-experts classification + unlabeled data + learning (artificial intelligence) + variance decomposition	AuthorProvided Keywords Not Found	We introduce a mixture-of-experts technique that is a generalization of mixture modeling techniques previously suggested for semi-supervised learning. We apply the bias-variance decomposition to semi-supervised classification and use the decomposition to study the effects from adding unlabeled data when learning a mixture model. Our empirical results indicate that the biggest gain from adding unlabeled data comes from the reduction of the model variance, whereas the behavior of the bias error term heavily depends on the correctness of the underlying model assumptions.
5911B3A2	International Conference on Data Mining	gongyi wu + benyu zhang + weiying ma + zheng chen + tao liu	2004	Improving text classification using local latent semantic indexing	training set + text analysis + pattern classification + single value decomposition + indexing + latent semantic indexing + term vectors + class discrimination information + information retrieval + local LSI method + text classification + local relevancy weighted LSI + global LSI + singular value decomposition + local latent semantic indexing	AuthorProvided Keywords Not Found	"Latent semantic indexing (LSI) has been shown to be extremely useful in information retrieval, but it is not an optimal representation for text classification. It always drops the text classification performance when being applied to the whole training set (global LSI) because this completely unsupervised method ignores class discrimination while only concentrating on representation. Some local LSI methods have been proposed to improve the classification by utilizing class discrimination information. However, their performance improvements over original term vectors are still very limited. In this paper, we propose a new local LSI method called ""local relevancy weighted LSI"" to improve text classification by performing a separate single value decomposition (SVD) on the transformed local region of each class. Experimental results show that our method is much better than global LSI and traditional local LSI methods on classification within a much smaller LSI dimension."
5DE4B60B	International Conference on Data Mining	tava lennon olsen + kun liu + hillol kargupta + chris giannella	2004	Communication efficient construction of decision trees over heterogeneously distributed data	decision tree + heterogeneously distributed data + distributed data mining + data mining + decision trees + distributed processing + communication efficient construction + communication complexity + random projection + algorithm design	Random Projection,+Decision Trees,+Distributed Data Mining	We present an algorithm designed to efficiently construct a decision tree over heterogeneously distributed data without centralizing. We compare our algorithm against a standard centralized decision tree implementation in terms of accuracy as well as the communication complexity. Our experimental results show that by using only 20% of the communication cost necessary to centralize the data we can achieve trees with accuracy at least 80% of the trees produced by the centralized version.
0F6F3149	International Conference on Data Mining	vasant honavar + adrian silvescu + jun zhang + daeki kang	2004	Generation of Attribute Value Taxonomies from Data and Their Use in Data-Driven Construction of Accurate and Compact Naive Bayes Classifiers	naive bayes classifier + naive bayes		"
Attribute Value Taxonomies (AVT) have been shown to be useful in constructing compact and robust classifiers. However, in many application domains, human-designed AVTs are unavailable. For this problem, we introduce AVT-Learner, an algorithm for automated construction of attribute value taxonomies from data. AVT-Learner uses Hierarchical Agglomerative Clustering (HAC) to cluster attribute values based on the distribution of classes that cooccur with the values. We describe experiments of AVT-Learner on several benchmark data sets that compare the performance of AVT-NBL (an AVT-guided Naive Bayes Learner) with that of the standard Naive Bayes Learner (NBL) applied to the original data set as well as a data set generated by augmenting the original data set with a set of additional attributes corresponding to the nodes in the AVTs. Our results show that the AVTs generated by AVT-Learner are competitive with human-generated AVTs (in cases where such AVTs are available). AVT-NBL using AVTs generated by AVT-Learner achieves classification accuracies that are comparable to or higher than that obtained by NBL; and the resulting classifiers are significantly more compact than those generated by NBL.
"
7E8358C9	International Conference on Data Mining	michael r berthold + giuseppe di fatta	2004	Distributed mining of molecular fragments	grid computing + data structure + computational complexity + data mining		"
In real world applications sequential algorithms of data mining and data exploration are often unsuitable for datasets with enormous size, high-dimensionality and complex data structure. Grid computing promises unprecedented opportunities for unlimited computing and storage resources. In this context there is the necessity to develop high performance distributed data mining algorithms. However, the computational complexity of the problem and the large amount of data to be explored often make the design of large scale applications particularly challenging. In this paper we present the first distributed formulation of a frequent subgraph mining algorithm for discriminative fragments of molecular compounds. Two distributed approaches have been developed and compared on the wellknown National Cancer Institute's HIV-screening dataset. We present experimental results on a small-scale computing environment.
"
5ADDDC06	International Conference on Data Mining	mikhail j atallah + wojciech szpankowski + robert gwadera	2004	Detection of significant sets of episodes in event sequences	 + probability + reference model + probabilistic analysis + set theory + sequences + probabilistic model + pattern recognition		"
We present a method for a reliable detection of “unusual” sets of episodes in the form of many pattern sequences, scanned simultaneously for an occurrence as a subsequence in a large event stream within a window of size w. We also investigate the important special case of all permutations of the same sequence, which models the situation where the order of events in an episode does not matter, e.g., when events correspond to purchased market basket items. In order to build a reliable monitoring system we compare obtained measurements to a reference model which in our case is a probabilistic model (Bernoulli or Markov). We first present a precise analysis that leads to a construction of a threshold. The difficulties of carrying out a probabilistic analysis for an arbitrary set of patterns, stems from the possible simultaneous occurrence of many members of the set as subsequences in the same window, the fact that the different patterns typically do have common symbols or common subsequences or possibly common prefixes, and that they may have different lengths. We also report on extensive experimental results, carried out on the Wal-Mart transactions database, that show a remarkable agreement with our theoretical analysis. This paper is an extension of our previous work in [8] where we laid out foundation for the problem of the reliable detection of an “unusual” episodes, but did not consider more than one episode scanned simultaneously for an occurrence.
"
599DAFC7	International Conference on Data Mining	sourav chakraborty + philip s yu + ke wang	2004	Bottom-up generalization: a data mining solution to privacy protection	data mining + private information + generalisation (artificial intelligence) + data holder + classification model + pattern clustering + privacy protection + bottom-up generalization + bottom up + data privacy + data generalization + data masking + randomized data	AuthorProvided Keywords Not Found	The well-known privacy-preserved data mining modifies existing data mining techniques to randomized data. In this paper, we investigate data mining as a technique for masking data, therefore, termed data mining based privacy protection. This approach incorporates partially the requirement of a targeted data mining task into the process of masking data so that essential structure is preserved in the masked data. The idea is simple but novel: we explore the data generalization concept from data mining as a way to hide detailed information, rather than discover trends and patterns. Once the data is masked, standard data mining techniques can be applied without modification. Our work demonstrated another positive use of data mining technology: not only can it discover useful patterns, but also mask private information. We consider the following privacy problem: a data holder wants to release a version of data for building classification models, but wants to protect against linking the released data to an external source for inferring sensitive information. We adapt an iterative bottom-up generalization from data mining to generalize the data. The generalized data remains useful to classification but becomes difficult to link to other sources. The generalization space is specified by a hierarchical structure of generalizations. A key is identifying the best generalization to climb up the hierarchy at each iteration. Enumerating all candidate generalizations is impractical. We present a scalable solution that examines at most one generalization in each iteration for each attribute involved in the linking.
5A5C16E2	International Conference on Data Mining	karlton sequeira + mohammed j zaki	2004	SCHISM: a new approach for interesting subspace mining	feature space + clustering algorithm + data mining + interesting subspaces + vertical dataset representation + tree searching + depth-first search + high dimensional data + pattern clustering + backtracking + subspace mining + Chernoff-Hoeffding bound + depth first search + SCHISM	AuthorProvided Keywords Not Found	High-dimensional data pose challenges to traditional clustering algorithms due to their inherent sparsity and data tend to cluster in different and possibly overlapping subspaces of the entire feature space. Finding such subspaces is called subspace mining. We present SCHISM, a new algorithm for mining interesting subspaces, using the notions of support and Chernoff-Hoeffding bounds. We use a vertical representation of the dataset, and use a depth-first search with backtracking to find maximal interesting subspaces. We test our algorithm on a number of high-dimensional synthetic and real datasets to test its effectiveness.
5D9A8417	International Conference on Data Mining	jianyong wang + george karypis	2004	SUMMARY: efficiently summarizing transactions for clustering	transaction processing + algorithms + clustering algorithm + data mining + document clustering + accuracy + document classification + summarizing transactions + classification + frequent itemset mining + association rule mining + transaction database + identification + pattern clustering + SUMMARY + transaction clustering + categorical data + clustering + search space + data bases + search space pruning + transaction classification	AuthorProvided Keywords Not Found	Frequent itemset mining was initially proposed and has been studied extensively in the context of association rule mining. In recent years, several studies have also extended its application to the transaction (or document) classification and clustering. However, most of the frequent-itemset based clustering algorithms need to first mine a large intermediate set of frequent itemsets in order to identify a subset of the most promising ones that can be used for clustering. In this paper, we study how to directly find a subset of high quality frequent itemsets that can be used as a concise summary of the transaction database and to cluster the categorical data. By exploring some properties of the subset of itemsets that we are interested in, we proposed several search space pruning methods and designed an efficient algorithm called SUMMARY. Our empirical results have shown that SUMMARY runs very fast even when the minimum support is extremely low and scales very well with respect to the database size, and surprisingly, as a pure frequent itemset mining algorithm, it is very effective in clustering the categorical data and summarizing the dense transaction databases.
5FAF3966	International Conference on Data Mining	george karypis + michihiro kuramochi	2004	GREW - a scalable frequent subgraph discovery algorithm	algorithms + graph theory + vertex-disjoint embedding + data mining + heuristic frequent subgraph discovery + graph datasets + connected component + classification + heuristic algorithm + graph mining + graphs + clustering + scaling factor + frequent pattern discovery + GREW	graph mining,+frequent pattern discovery,+frequent subgraph	Existing algorithms that mine graph datasets to discover patterns corresponding to frequently occurring subgraphs can operate efficiently on graphs that are sparse, contain a large number of relatively small connected components, have vertices with low and bounded degrees, and contain well-labeled vertices and edges. However, for graphs that do not share these characteristics, these algorithms become highly unscalable. In this paper we present a heuristic algorithm called GREW to overcome the limitations of existing complete or heuristic frequent subgraph discovery algorithms. GREW is designed to operate on a large graph and to find patterns corresponding to connected subgraphs that have a large number of vertex-disjoint embeddings. Our experimental evaluation shows that GREW is efficient, can scale to very large graphs, and find non-trivial patterns.
5F8386C8	International Conference on Data Mining	xindong wu + xingquan zhu + ying yang	2004	Dynamic classifier selection for effective mining from noisy data streams	pattern classification + comparative study + concept drift + sensor network + data mining + noise + base classifier + dynamic classifier selection + noisy data stream mining	AuthorProvided Keywords Not Found	"Mining from data streams has become an important and challenging task for many real-world applications such as credit card fraud protection and sensor networking. One popular solution is to separate stream data into chunks, learn a base classifier from each chunk, and then integrate all base classifiers for effective classification. In this paper, we propose a dynamic classifier selection (DCS) mechanism to integrate base classifiers for effective mining from data streams. The proposed algorithm dynamically selects a single ""best"" classifier to classify each test instance at run time. Our scheme uses statistical information from attribute values, and uses each attribute to partition the evaluation set into disjoint subsets, followed by a procedure that evaluates the classification accuracy of each base classifier on these subsets. Given a test instance, its attribute values determine the subsets that the similar instances in the evaluation set have constructed, and the classifier with the highest classification accuracy on those subsets is selected to classify the test instance. Experimental results and comparative studies demonstrate the efficiency and efficacy of our method. Such a DCS scheme appears to be promising in mining data streams with dramatic concept drifting or with a significant amount of noise, where the base classifiers are likely conflictive or have low confidence."
7D92A1A1	International Conference on Data Mining	shotaro akaho + toshihiro kamishima	2004	Filling-in missing objects in orders	collaborative filtering + collaborative filtering system + information filtering + data handling + order filling-in + missing values	AuthorProvided Keywords Not Found	Filling-in techniques are important, since missing values frequently appear in real data. Such techniques have been established for categorical or numerical values. Though lists of ordered objects are widely used as representational forms (e.g., Web search results, best-seller lists), filling-in techniques for orders have received little attention. We therefore propose a simple but effective technique to fill-in missing objects in orders. We built this technique into our collaborative filtering system.
815BDAB1	International Conference on Data Mining	k railing + claudia plant + hanspeter kriegel + christian baumgartner + peer kroger	2004	Subspace selection for clustering high-dimensional data	k-nearest neighbor distances + feature space + clustering algorithm + data mining + subspace selection + subspaces relevant for clustering + feature spaces + comparative method + k nearest neighbor + high dimensional data + pattern clustering + sorting + SURFING + high-dimensional data clustering + sparse data sets + feature selection	AuthorProvided Keywords Not Found	"In high-dimensional feature spaces traditional clustering algorithms tend to break down in terms of efficiency and quality. Nevertheless, the data sets often contain clusters which are hidden in various subspaces of the original feature space. In this paper, we present a feature selection technique called SURFING (subspaces relevant for clustering) that finds all subspaces interesting for clustering and sorts them by relevance. The sorting is based on a quality criterion for the interestingness of a subspace using the k-nearest neighbor distances of the objects. As our method is more or less parameterless, it addresses the unsupervised notion of the data mining task ""clustering"" in a best possible way. A broad evaluation based on synthetic and real-world data sets demonstrates that SURFING is suitable to find all relevant sub-spaces in high dimensional, sparse data sets and produces better results than comparative methods."
5CCCA05F	International Conference on Data Mining	jiong yang + wei wang	2004	AGILE: a general approach to detect transitions in evolving data streams	data analysis + hidden Markov model + telecommunication services + transition detection + e commerce + AGILE + streaming data monitoring + emission tree + stream processing + markov model + system diagnosis + data structures + e-commerce + evolving data streams + variable memory Markov model	Stream processing + Transition detection + Variable memory Markov model + Emission tree	In many applications such as e-commerce, system diagnosis and telecommunication services, data arrives in streams at a high speed. It is common that the underlying process generating the stream may change over time, either as a result of the fundamental evolution or in response to some external stimulus. Detecting these changes is a very challenging problem of great practical importance. The overall volume of the stream usually far exceeds the available main memory and access to the data stream is typically performed via a linear scan in ascending order of the indices of the records. In this paper, we propose a novel approach, AGILE, to monitor streaming data and to detect distinguishable transitions of the underlying processes. AGILE has many advantages over the traditional Hidden Markov Model, e.g., AGILE only requires one scan of the data.
5CA633DB	International Conference on Data Mining	antonio gulli + paolo ferragina	2004	The anatomy of a hierarchical clustering engine for Web-page, news and book snippets	Blogline + query refinement + search engines + web pages + information retrieval + SnakeT + sentences selection + cluster assignment + Web search engines + knowledge bases + pattern clustering + book snippets + hierarchical clustering engine + knowledge based systems + Web page + clusters on-the-fly + ephemeral clustering + Google News + hierarchical clustering + Amazon collection + ranking functions + Web sites + linear time	AuthorProvided Keywords Not Found	In this paper, we investigate the Web snippet hierarchical clustering problem in its full extent by devising an algorithmic solution, and a software prototype called SnakeT (accessible at http://roquefort.di.unipi.it/), that: (1) draws the snippets from 16 Web search engines, the Amazon collection of books a9.com, the news of Google News and the blogs of Blogline; (2) builds the clusters on-the-fly (ephemeral clustering (Maarek et al., 2000)) in response to a user query without adopting any predefined organization in categories; (3) labels the clusters with sentences of variable length, drawn from the snippets and possibly missing some terms, provided they are not too many; (4) uses some ranking functions which exploit two knowledge bases properly built by our engine at preprocessing time for the sentences selection and cluster-assignment process; (5) organizes the clusters into a hierarchy, and assigns to the nodes intelligible sentences in order to allow post-navigation for query refinement. Our clustering algorithm possibly let the clusters overlap at different levels of the hierarchy.
5B691B1E	International Conference on Data Mining	jinze liu + wei wang + k strohmaier	2004	Revealing true subspace clusters in high dimensions	cluster intersection + overlapping cluster + high dimensional space + gaussian processes + pattern clustering + subspace clustering + similarity measurement + Gaussian processes + Gaussian tailed hyperrectangles + statistical analysis + gene expression	Subspace Clustering + Overlapping Cluster + Adhesion + Gaussian Tails + Cluster Intersection + Local Grid + Gene Expression	Subspace clustering is one of the best approaches for discovering meaningful clusters in high dimensional space. One cluster in high dimensional space may be transcribed into multiple distinct maximal clusters by projecting onto different subspaces. A direct consequence of clustering independently in each subspace is an overwhelmingly large set of overlapping clusters which may be significantly similar. To reveal the true underlying clusters, we propose a similarity measurement of the overlapping clusters. We adopt the model of Gaussian tailed hyper-rectangles to capture the distribution of any subspace cluster. A set of experiments on a synthetic dataset demonstrates the effectiveness of our approach. Application to real gene expression data also reveals impressive meta-clusters expected by biologists.
5DAEC1CC	International Conference on Data Mining	vasant honavar + adrian silvescu + daeki kang + jun zhang	2004	Generation of attribute value taxonomies from data for data-driven construction of accurate and compact classifiers	pattern classification + AVT-NBL + UCI data sets + human-designed AVT + data mining + cluster attribute values + AVT-learner + data-driven construction + learning artificial intelligence + naive bayes + automated construction + compact classifiers + Bayes methods + learning (artificial intelligence) + naive Bayes learner + attribute value taxonomies + hierarchical agglomerative clustering	AuthorProvided Keywords Not Found	Attribute value taxonomies (AVT) have been shown to be useful in constructing compact, robust, and comprehensible classifiers. However, in many application domains, human-designed AVTs are unavailable. We introduce AVT-learner, an algorithm for automated construction of attribute value taxonomies from data. AVT-learner uses hierarchical agglomerative clustering (HAC) to cluster attribute values based on the distribution of classes that co-occur with the values. We describe experiments on UCI data sets that compare the performance of AVT-NBL (an AVT-guided naive Bayes learner) with that of the standard naive Bayes learner (NBL) applied to the original data set. Our results show that the AVTs generated by AVT-learner are competitive with human-gene rated AVTs (in cases where such AVTs are available). AVT-NBL using AVTs generated by AVT-learner achieves classification accuracies that are comparable to or higher than those obtained by NBL; and the resulting classifiers are significantly more compact than those generated by NBL.
7E6DFBF6	International Conference on Data Mining	hillol kargupta + haimonti dutta	2004	Orthogonal decision trees	data stream mining + decision tree + orthogonal decision trees + data mining + decision trees + random forest + principal component + eigen analysis + computational complexity + eigenvalues and eigenfunctions + model complexity	AuthorProvided Keywords Not Found	This paper introduces orthogonal decision trees that offer an effective way to construct a redundancy-free, accurate, and meaningful representation of large decision-tree-ensembles often created by popular techniques such as bagging, boosting, random forests and many distributed and data stream mining algorithms. Orthogonal decision trees are functionally orthogonal to each other and they correspond to the principal components of the underlying function space. This paper offers a technique to construct such trees based on eigen-analysis of the ensemble and offers experimental results to document the performance of orthogonal trees on grounds of accuracy and model complexity.
7D0152B2	International Conference on Data Mining	ana l fred + alexander topchy + anil k jain	2004	Analysis of consensus partition in cluster ensemble	data mining		"
In combination of multiple partitions, one is usually interested in deriving a consensus solution with a quality better than that of given partitions. Several recent studies have empirically demonstrated improved accuracy of clustering ensembles on a number of artificial and realworld data sets. Unlike certain multiple supervised classifier systems, convergence properties of unsupervised clustering ensembles remain unknown for conventional combination schemes. In this paper we present formal arguments on the effectiveness of cluster ensemble from two perspectives. The first is based on a stochastic partition generation model related to re-labeling and consensus function with plurality voting. The second is to study the property of the “mean” partition of an ensemble with respect to a metric on the space of all possible partitions. In both the cases, the consensus solution can be shown to converge to a true underlying clustering solution as the number of partitions in the ensemble increases. This paper provides a rigorous justification for the use of cluster ensemble.
"
7D1830AC	International Conference on Data Mining	foster provost + raymond j mooney + maytal saartsechansky + prem melville	2004	Active feature-value acquisition for classifier induction	predictive model + data acquisition + classification + missing data + classifier induction + active feature-value acquisition	AuthorProvided Keywords Not Found	Many induction problems include missing data that can be acquired at a cost. For building accurate predictive models, acquiring complete information for all instances is often expensive or unnecessary, while acquiring information for a random subset of instances may not be most effective. Active feature-value acquisition tries to reduce the cost of achieving a desired model accuracy by identifying instances for which obtaining complete information is most informative. We present an approach in which instances are selected for acquisition based on the current model's accuracy and its confidence in the prediction. Experimental results demonstrate that our approach can induce accurate models using substantially fewer feature-value acquisitions as compared to alternative policies.
5C423B48	International Conference on Data Mining	gosta grahne + jianfei zhu	2004	Mining frequent itemsets from secondary memory	storage management + association rule + secondary memory + disk accesses + data mining + information retrieval + data structure + data structures + frequent itemsets + memory databases	AuthorProvided Keywords Not Found	Mining frequent itemsets is at the core of mining association rules, and is by now quite well understood algorithmically for main memory databases. In this paper, we investigate approaches to mining frequent itemsets when the database or the data structures used in the mining are too large to fit in main memory. Experimental results show that our techniques reduce the required disk accesses by orders of magnitude, and enable truly scalable data mining.
5E4D74DE	International Conference on Data Mining	reda alhajj + mehmet kaya	2004	Integrating multi-objective genetic algorithms into clustering for fuzzy association rules mining	association rule + fuzzy set + multiobjective genetic algorithms + pattern clustering + data mining + fuzzy set theory + fuzzy association rules mining + clustering + genetic algorithms + fuzzy set mining	AuthorProvided Keywords Not Found	In this paper, we propose an automated method to decide on the number of fuzzy sets and for the autonomous mining of both fuzzy sets and fuzzy association rules. We compare the proposed multiobjective GA based approach with: 1) CURE based approach; 2) Chien et al. (2001) clustering approach. Experimental results on JOOK transactions extracted from the adult data of United States census in year 2000 show that the proposed method exhibits good performance over the other two approaches in terms of runtime, number of large itemsets and number of association rules.
6D7396D6	International Conference on Data Mining	stephan bloehdorn + andreas hotho	2004	Text classification by boosting weak learners based on terms and concepts	text analysis + weak learner boosting + bag of words + ontologies (artificial intelligence) + document representations + text classification + classification + bag-of-words paradigm	AuthorProvided Keywords Not Found	Document representations for text classification are typically based on the classical bag-of-words paradigm. This approach comes with deficiencies that motivate the integration of features on a higher semantic level than single words. In this paper we propose an enhancement of the classical document representation through concepts extracted from background knowledge. Boosting is used for actual classification. Experimental evaluations on two well known text corpora support our approach through consistent improvement of the results.
5F24188D	International Conference on Data Mining	ruoming jin + gagan agrawal + anjan goswami	2004	Fast and exact out-of-core k-means clustering	k means clustering + cluster centers + k-means clustering + pattern clustering + k means algorithm + data mining + k means + real datasets + k-means algorithm + large disk-resident datasets + synthetic datasets	AuthorProvided Keywords Not Found	Clustering has been one of the most widely studied topics in data mining and k-means clustering has been one of the popular clustering algorithms. K-means requires several passes on the entire dataset, which can make it very expensive for large disk-resident datasets. In view of this, a lot of work has been done on various approximate versions of k-means, which require only one or a small number of passes on the entire dataset. In this paper, we present a new algorithm which typically requires only one or a small number of passes on the entire dataset, and provably produces the same cluster centers as reported by the original k-means algorithm. The algorithm uses sampling to create initial cluster centers, and then takes one or more passes over the entire dataset to adjust these cluster centers. We provide theoretical analysis to show that the cluster centers thus reported are the same as the ones computed by the original k-means algorithm. Experimental results from a number of real and synthetic datasets show speedup between a factor of 2 and 4.5, as compared to k-means.
5F53BA08	International Conference on Data Mining	tsay young lin	2004	Mining associations by linear inequalities	bitmaps + pattern classification + attribute oriented generalization + finite set + data mining + isomorphic theorem + canonical model + association + isomorphic relations + set theory + association mining + linear inequalities + isomorphic classes + relational table + feature + granules + generalized associations + polynomial time + theorem proving + bitmaps indexes + isomorphic patterns	association + deduction + feature + granules + bitmaps	The main theorem is: generalized associations of a relational table can be found by a finite set of linear inequalities within polynomial time. It is derived from the following three results, which were established in ICDMO'02 and are re-developed here. They are: (1) isomorphic theorem: isomorphic relations have isomorphic patterns. Such an isomorphism classifies relational tables into isomorphic classes. (2) A variant of the classical bitmaps indexes uniquely exists in each isomorphic class. We take it as the canonical model of the class. (3) All possible attributes/features can be generated by a generalized procedure of the classical AOG (attribute oriented generalization). Then, (4) the main theorem for canonical model is established. By isomorphism theorem, we had the final result (5).
5BD2E015	International Conference on Data Mining	jiang su + he zhang	2004	Learning conditional independence tree for ranking	conditional independence + learning algorithm + conditional independence tree + data mining + accurate ranking + decision tree learning + decision tree + learning artificial intelligence + naive bayes + decision trees + naive Bayes method + Bayes methods + learning (artificial intelligence)	AuthorProvided Keywords Not Found	Accurate ranking is desired in many real-world data mining applications. Traditional learning algorithms, however, aim only at high classification accuracy. It has been observed that both traditional decision trees and naive Bayes produce good classification accuracy but poor probability estimates. In this paper, we use a new model, conditional independence tree (CITree), which is a combination of decision tree and naive Bayes and more suitable for ranking and more learnable in practice. We propose a novel algorithm for learning CITree for ranking, and the experiments show that the CITree algorithm outperforms the state-of-the-art decision tree learning algorithm C4.4 and naive Bayes significantly in yielding accurate rankings. Our work provides an effective data mining algorithm for applications in which an accurate ranking is required.
587116F1	International Conference on Data Mining	ella bingham + heli hiisila	2004	Dependencies between transcription factor binding sites: comparison between ICA, NMF, PLSA and frequent sets	transcription factor + transcription factor binding sites + baker yeast + transcription factors + probabilistic latent semantic analysis + data mining + data structure + DNA sequence + frequent sets + matrix decomposition + S. Cerevisiae + biological database + dna sequence + independent component analysis + genetics + biology computing + dna + data structures + human gene upstream regions + latent variable + eucaryotes + binding site + probability + transcription factor binding site + nonnegative matrix factorization + DNA + non negative matrix factorization + gene expression	AuthorProvided Keywords Not Found	Gene expression of eucaryotes is regulated through transcription factors, which are molecules able to attach to the binding sites in the DNA sequence. These binding sites are small pieces of DNA usually found upstream from the gene they regulate. As the binding sites play an important role in the gene expression, it is of interest to find out their characteristics. In this paper, we look for dependencies and independencies between these binding sites using independent component analysis (ICA), non-negative matrix factorization (NMF), probabilistic latent semantic analysis (PLSA) and the method of frequent sets. The data used are human gene upstream regions and possible binding sites listed in a biological database. Also, results on the baker's yeast (S. Cerevisiae) upstream regions are briefly discussed for comparison. ICA, NMF and PLSA are latent variable methods that decompose the observed data into smaller components. Of these, ICA and NMF were originally aimed for continuous data. We show that these methods can be successfully used on discrete DNA data as well. PLSA and the method of frequent sets were created for discrete data sets. The above methods reveal partially overlapping sets of possible binding sites such that the binding sites within a set are dependent of each other. The methods of frequent sets and NMF give a good overview of the most common data structures, whereas using ICA and PLSA we find large sets that are surprisingly frequent. That is, sets of very frequently occurring possible binding sites can be found near hundreds or thousands of genes; also interesting but less frequent ones co-occur surprisingly often.
7DC89DFB	International Conference on Data Mining	markus prechtel + winfried gunther + matthias grabert + tomas hrycej	2004	An Early Warning System for Vehicle Related Quality Data	data warehouse + data mining + seasonality + failure rate + neural network + early warning system + grid computing + sequence analysis		"
Vehicle production audit tests, warranty claims and car control unit data are stored in a central data warehouse for data mining analysis. Neural network based part failure rate estimations, adjusted for mileage and seasonality, are used for monitoring warranty claims. Association and sequence analysis connect production audit data, car control unit data and warranty claims for an early detection of quality changes both in production state and car field usage. Calculations are performed via grid computing.
"
587532DE	International Conference on Data Mining	k sivakumar + da meng + hillol kargupta	2004	Privacy-sensitive Bayesian network parameter learning	bayesian network + privacy-sensitive Bayesian network parameter learning + data mining + random projection-based method + linear equation + secure computation + feature vector + learning artificial intelligence + privacy-sensitive dataset + conditional probability + data privacy + inner product + binary-valued dataset + belief networks + learning (artificial intelligence) + linear equations	AuthorProvided Keywords Not Found	This paper considers the problem of learning the parameters of a Bayesian network, assuming the structure of the network is given, from a privacy-sensitive dataset that is distributed between multiple parties. For a binary-valued dataset, we show that the count information required to estimate the conditional probabilities in a Bayesian network can be obtained as a solution to a set of linear equations involving some inner product between the relevant different feature vectors. We consider a random projection-based method that was proposed elsewhere to securely compute the inner product (with a modified implementation of that method).
8154EDB1	International Conference on Data Mining	qiang yang + benyu zhang + shuicheng yan + weiying ma + zheng chen + jun yan + chenyong hu	2004	Mining ratio rules via principal sparse non-negative matrix factorization	association rule + data mining + association rules + matrix decomposition + quantitative association knowledge + support measurement + ratio rules mining + principle component analysis + quantifiable data mining + non negative matrix factorization + principal sparse nonnegative matrix factorization + principal component analysis + sparse matrices	AuthorProvided Keywords Not Found	Association rules are traditionally designed to capture statistical relationship among itemsets in a given database. To additionally capture the quantitative association knowledge, Korn et al. (1998) proposed a paradigm named ratio rules for quantifiable data mining. However, their approach is mainly based on principle component analysis (PCA) and as a result, it cannot guarantee that the ratio coefficient is nonnegative. This may lead to serious problems in the rules' application. In this paper, we propose a method, called principal sparse nonnegative matrix factorization (PSNMF), for learning the associations between itemsets in the form of ratio rules. In addition, we provide a support measurement to weigh the importance of each rule for the entire dataset.
5CE75DF8	International Conference on Data Mining	xiaoyong chai + lin deng + qiang yang + charles x ling	2004	Test-cost sensitive naive Bayes classification	pattern classification + decision tree algorithm + misclassification costs + naive bayes classifier + inductive learning + decision tree + classification errors + test-cost sensitive naive Bayes classification + naive bayes + decision trees + test case + Bayes methods + learning by example + csNB method + missing values	AuthorProvided Keywords Not Found	Inductive learning techniques such as the naive Bayes and decision tree algorithms have been extended in the past to handle different types of costs mainly by distinguishing different costs of classification errors. However, it is an equally important issue to consider how to handle the test costs associated with querying the missing values in a test case. When the value of an attribute is missing in a test case, it may or may not be worthwhile to take the effort to obtain its missing value, depending on how much the value results in a potential gain in the classification accuracy. In this paper, we show how to obtain a test-cost sensitive naive Bayes classifier (csNB) by including a test strategy which determines how unknown attributes are selected to perform test on in order to minimize the sum of the mis-classification costs and test costs. We propose and evaluate several potential test strategies including one that allows several tests to be done at once. We empirically evaluate the csNB method, and show that it compares favorably with its decision tree counterpart.
5E69BEAE	International Conference on Data Mining	ricardo vilalta + nidal zeidat + christoph f eick	2004	Using representative-based clustering for nearest neighbor dataset editing	pattern classification + learning artificial intelligence + nearest neighbor + combinatorial mathematics + nearest neighbor dataset editing + pattern clustering + Wilson editing + learning (artificial intelligence) + supervised clustering editing + instance-based learning + representative-based clustering + instance based learning	nearest neighbor editing + instance-based learning + supervised clustering + representative-based clustering + clustering for classification + Wilson editing	The goal of dataset editing in instance-based learning is to remove objects from a training set in order to increase the accuracy of a classifier. For example, Wilson editing removes training examples that are misclassified by a nearest neighbor classifier so as to smooth the shape of the resulting decision boundaries. This paper revolves around the use of representative-based clustering algorithms for nearest neighbor dataset editing. We term this approach supervised clustering editing. The main idea is to replace a dataset by a set of cluster prototypes. A clustering approach called supervised clustering is introduced for this purpose. Our empirical evaluation using eight UCI datasets shows that both Wilson and supervised clustering editing improve accuracy on more than 50% of the datasets tested. However, supervised clustering editing achieves four times higher compression rates than Wilson editing.
5BE338F0	International Conference on Data Mining	wai lam + yiqiu han	2004	Query-driven support pattern discovery for classification learning	query processing + pattern classification + learning artificial intelligence + query-driven support pattern discovery + classification learning + data mining + polynomial time + learning (artificial intelligence) + query-driven lazy learning	AuthorProvided Keywords Not Found	We propose a query-driven lazy learning algorithm which attempts to discover useful local patterns, called support patterns, for classifying a given query. The learning is customized to the query to avoid the horizon effect. We show that this query-driven learning algorithm can guarantee to discover all support patterns with perfect expected accuracy in polynomial time. The experimental results on benchmark data sets also demonstrate that our learning algorithm really has prominent learning performance.
5C5EDDBF	International Conference on Data Mining	trevor p martin + nick clarke + b s lee + detlef nauck + basim majeed	2004	Dynamic daily-living patterns and association analyses in tele-care systems	domain knowledge + telemedicine + data analysis + sensor-network domain knowledge + telecare systems + sensor network + association analysis + environment-dependent data + daily-living patterns + individual-dependent data + health care + missing values + fuzzy association analysis	AuthorProvided Keywords Not Found	Tele-care systems aim to carry out intelligent analyses of a person's wellbeing using data about their daily activities. This is a very challenging task because the massive dataset is likely to be erroneous, possibly with misleading sections due to noise or missing values. Furthermore, the interpretation of the data is highly sensitive to the lifestyle of the monitored person and the environment in which they interact. In our tele-care project, sensor-network domain knowledge is used to overcome the difficulties of monitoring long-term wellbeing with an imperfect data source. In addition, a fuzzy association analysis is leveraged to implement a dynamic and flexible analysis over individual- and environment-dependent data.
5E692719	International Conference on Data Mining	miyen yeh + jenwei huang + mingsyan chen + biru dai	2004	Clustering on demand for multiple data streams	multiple data streams + pattern clustering + online statistics collection + time constraints + space constraints + data mining + compact multiresolution approximations + data evolution + pattern generation + flexible mining requirements + computational complexity + clustering-on-demand	AuthorProvided Keywords Not Found	In the data stream environment, the patterns generated by the mining techniques are usually distinct at different time because of the evolution of data. In order to deal with various types of multiple data streams and to support flexible mining requirements, we devise in this paper a clustering on demand framework, abbreviated as COD framework, to dynamically cluster multiple data streams. While providing a general framework of clustering on multiple data streams, the COD framework has two major features, namely one data scan for online statistics collection and compact multiresolution approximations, which are designed to address, respectively, the time and the space constraints in a data stream environment. Furthermore, with the multiresolution approximations of data streams, flexible clustering demands can be supported.
598C7F26	International Conference on Data Mining	jie huang + margaret h dunham + yu meng	2004	Extensible Markov model	data models + Markov chain + data model + extensible Markov model + markov processes + spatiotemporal data modeling + markov model + Markov processes + data modeling tool + spatiotemporal prediction problems + markov chain	AuthorProvided Keywords Not Found	A Markov chain is a popular data modeling tool. This paper presents a variation of Markov chain, namely extensible Markov model (EMM). By providing a dynamically adjustable structure, EMM overcomes the problems caused by the static nature of the traditional Markov chain. Therefore, EMMs are particularly well suited to model spatiotemporal data such as network traffic, environmental data, weather data, and automobile traffic. Performance studies using EMMs for spatiotemporal prediction problems show the advantages of this approach.
5C031693	International Conference on Data Mining	marko salmenkivi	2004	Evaluating attraction in spatial point patterns with an application in the field of cultural history	neighbourhood constraint + data mining + cultural history + history + spatial point pattern + density estimation + spatial collocation rules	AuthorProvided Keywords Not Found	Spatial collocation rules are often useful for describing dependencies between spatial features. Still, the commonly used criteria for the interestingness of the rules and the selected neighbourhood constraints for spatial objects may be too rough for capturing the essentials of such dependencies. We demonstrate the difficulties with concrete examples on a large place-name data set. We propose a technique based on simple density estimation for assessing the interesting-ness with different neighbouring constraints.
7E225B80	International Conference on Data Mining	xingzhi sun + philip s yu	2005	A border-based approach for hiding sensitive frequent itemsets	sensitive knowledge + side effect + privacy issue + data mining + knowledge extraction + data privacy + sensitive frequent itemset hiding + border-based approach + data sharing	AuthorProvided Keywords Not Found	Sharing data among organizations often leads to mutual benefit. Recent technology in data mining has enabled efficient extraction of knowledge from large databases. This, however, increases risks of disclosing the sensitive knowledge when the database is released to other parties. To address this privacy issue, one may sanitize the original database so that the sensitive knowledge is hidden. The challenge is to minimize the side effect on the quality of the sanitized database so that nonsensitive knowledge can still be mined. In this paper, we study such a problem in the context of hiding sensitive frequent itemsets by judiciously modifying the transactions in the database. To preserve the non-sensitive frequent itemsets, we propose a border-based approach to efficiently evaluate the impact of any modification to the database during the hiding process. The quality of database can be well maintained by greedily selecting the modifications with minimal side effect. Experiments results are also reported to show the effectiveness of the proposed approach.
7D77FE61	International Conference on Data Mining	andrew remsen + lawrence o hall + dmitry b goldgof + tong luo	2005	Bit reduction support vector machine	data cardinality + data compression + data reduction + prediction time + support vector machines + support vector machine + fast compression method + bit reduction support vector machine + large data sets + random sampling	AuthorProvided Keywords Not Found	Support vector machines are very accurate classifiers and have been widely used in many applications. However, the training and to a lesser extent prediction time of support vector machines on very large data sets can be very long. This paper presents a fast compression method to scale up support vector machines to large data sets. A simple bit reduction method is applied to reduce the cardinality of the data by weighting representative examples. We then develop support vector machines which may be trained on weighted data. Experiments indicate that the bit reduction support vector machine produces a significant reduction in the time required for both training and prediction with minimum loss in accuracy. It is also shown to be more accurate than random sampling, when the data is not over-compressed.
7EF445E7	International Conference on Data Mining	samuel burer + yi zhang + w n street	2005	Sharing classifiers among ensembles from related problem domains	semidefinite programming + pattern classification + prediction problem + classification ensemble + ensemble pruning	AuthorProvided Keywords Not Found	A classification ensemble is a group of classifiers that all solve the same prediction problem in different ways. It is well-known that combining the predictions of classifiers within the same problem domain using techniques like bagging or boosting often improves the performance. This research shows that sharing classifiers among different but closely related problem domains can also be helpful. In addition, a semi-definite programming based ensemble pruning method is implemented in order to optimize the selection of a subset of classifiers for each problem domain. Computational results on a catalog dataset indicate that the ensembles resulting from sharing classifiers among different product categories generally have larger AUCs than those ensembles trained only on their own categories. The pruning algorithm not only prevents the occasional decrease of effectiveness caused by conflicting concepts among the problem domains, but also provides a better understanding of the problem domains and their relationships.
7E93306E	International Conference on Data Mining	taneli mielikainen + aristides gionis + panayiotis tsaparas + heikki mannila + gautam das + foto n afrati	2005	Mining chains of relations	association rule + relational chain + association rule discovery + satisfiability + data mining	AuthorProvided Keywords Not Found	Traditional data mining applications consider the problem of mining a single relation between two attributes. For example, in a scientific bibliography database, authors are related to papers, and we may be interested in discovering association rules between authors. However, in real life, we often have multiple attributes related though chains of relations. For example, authors write papers, and papers concern one or more topics. Mining such relational chains poses additional challenges. In this paper we consider the following problem: given a chain of two relations R1 (A, P) and R2(P, T) we want to find selectors for the objects in T such that the projected relation between A and P satisfies a specific property. The motivation for our approach is that a given property might not hold on the whole dataset, but it might hold when projecting the data on a selector set. We discuss various algorithms and we examine the conditions under which the a priori technique can be used. We experimentally demonstrate the effectiveness of our methods.
805EADC8	International Conference on Data Mining	robert c james + jorg denzinger + jie gao	2005	CoLe: a cooperative data mining approach and its application to early diabetes detection	CoLe + data mining + diseases + medical computing + cooperative data mining + early diabetes detection + hybrid knowledge discovery	AuthorProvided Keywords Not Found	We present CoLe, a cooperative data mining approach for discovering hybrid knowledge. It employs multiple different data mining algorithms, and combines results from them to enhance the mined knowledge. For our medical application area, we analyse several focusing strategies that allowed us to gain medically significant results.
7EE4A2B6	International Conference on Data Mining	raz tamir	2005	A random walk through human associations	steady state + human associations + interestingness measure + user profile + association rule + data mining + local confidence gain + turing test + random walk + association rule discovery + directed graphs + weighted directed graph + user associations + directed graph + associative thinking + query expansion + association graph	AuthorProvided Keywords Not Found	"Letting one's thoughts wander is not simply an arbitrary or rambling process. It can better be described as ""associative thinking"", where a complex chain of associative thoughts and ideas are linked. It is our contention that this seemingly chaotic process can be modeled by a random walk in a weighted directed graph. Furthermore, is it possible to predict mathematically the ""steady state"" of such a process, to determine where such wandering is leading. The random walk process uses rules of association, defined by the Local Confidence Gain (LCG) interestingness measure. Extracted concepts are used as nodes of a directed graph. The associative ""forces"" between any two concepts (measured by LCG) are used to weigh the edges connecting the nodes that create a graph of associations. It is common, yet not trivial, for people to look for data about a subject without knowing its exact nomenclature (for example, finding the name of a disease just by knowing its symptoms). Random walk in association graphs can discover highly informative phrases that can be used for query expansion in a way that better expresses the user's initial search goals. A different usage is to create a user profile representing his current interests. We used a modified version of the Turing Test to show that the random walk process discovers association rules that conform to a human associations generating process. By constructing the user associations we were able to build a profile representing the user's ""line of thoughts"". The suggested algorithm can be used in any database and can implement the ranking measures of other association rules."
7DF5F6B1	International Conference on Data Mining	philip k chan + matthew v mahoney	2005	Modeling multiple time series for anomaly detection	false alarm rate + time domain + feature space + security of data + NASA shuttle program + time series + anomaly detection + monitoring task + multiple time series modeling	AuthorProvided Keywords Not Found	Our goal is to generate comprehensible and accurate models from multiple time series for anomaly detection. The models need to produce anomaly scores in an online manner for real-life monitoring tasks. We introduce three algorithms that work in a constructed feature space and evaluate them with a real data set from the NASA shuttle program. Our offline and online evaluations indicate that our algorithms can be more accurate than two existing algorithms.
7E029C26	International Conference on Data Mining	paul komarek + andrew w moore	2005	Making logistic regression a core data mining tool with TR-IRLS	data preprocessing + pattern classification + least squares approximations + data mining + iteratively reweighted least squares + truncated Newton method + regression analysis + data mining tool + regularization method + newton method + logistic regression + binary classification + Newton method	AuthorProvided Keywords Not Found	Binary classification is a core data mining task. For large datasets or real-time applications, desirable classifiers are accurate, fast, and need no parameter tuning. We present a simple implementation of logistic regression that meets these requirements. A combination of regularization, truncated Newton methods, and iteratively re-weighted least squares make it faster and more accurate than modern SVM implementations, and relatively insensitive to parameters. It is robust to linear dependencies and some scaling problems, making most data preprocessing unnecessary.
5E36157C	International Conference on Data Mining	vipin kumar + michael steinbach	2005	Generalizing the notion of confidence [Mining association rules]	binary transaction data + association analysis + data mining + association pattern + conditional probability + confidence measure + association rule mining + error tolerant itemsets	AuthorProvided Keywords Not Found	In this paper, we explore extending association analysis to non-traditional types of patterns and nonbinary data by generalizing the notion of confidence. The key idea is to regard confidence as a measure of the extent to which the strength of one association pattern provides information about the strength of another. This approach provides a framework that encompasses the traditional concept of confidence as a special case and can be used as the basis for designing a variety of new confidence measures. Besides discussing such confidence measures, we provide examples that illustrate the potential usefulness of a generalized notion of confidence. In particular, we describe an approach to defining confidence for error tolerant itemsets that preserves the interpretation of confidence as a conditional probability and derive a confidence measure for continuous data that agrees with the standard confidence measure when applied to binary transaction data.
7F94AC27	International Conference on Data Mining	richard butterworth + dan a simovici + gregory piatetskyshapiro	2005	On feature selection through clustering	pattern clustering + classification algorithm + feature selection + attribute clustering	AuthorProvided Keywords Not Found	We study an algorithm for feature selection that clusters attributes using a special metric and then makes use of the dendrogram of the resulting cluster hierarchy to choose the most relevant attributes. The main interest of our technique resides in the improved understanding of the structure of the analyzed data and of the relative importance of the attributes for the selection process.
7D67AC06	International Conference on Data Mining	wonsuk lee + daesu lee	2005	Finding maximal frequent itemsets over online data streams adaptively	maximal frequent itemsets + data mining + trees (mathematics) + online data streams + mining method + CP-tree + adaptive memory utilization + compressed-prefix tree	AuthorProvided Keywords Not Found	Due to the characteristics of a data stream, it is very important to confine the memory usage of a data mining process regardless of the amount of information generated in the data stream. For this purpose, this paper proposes a CP-tree (compressed-prefix tree) that can be effectively used in finding either frequent or maximal frequent itemsets over an online data stream. Unlike a prefix tree, a node of a CP-tree can maintain the information of several item-sets together. Based on this characteristic, the size of a CP-tree can be flexibly controlled by merging or splitting nodes. In this paper, a mining method employing a CP-tree is proposed and an adaptive memory utilization scheme is also presented in order to maximize the mining accuracy of the proposed method for confined memory space at all times. Finally, the performance of the proposed method is analyzed by a series of experiments to identify its various characteristics.
7D4F5246	International Conference on Data Mining	s basil + m sahami + mikhail bilenko	2005	Adaptive product normalization: using online learning for record linkage in comparison shopping	distance function + learning artificial intelligence + record linkage + online machine learning + home shopping + Internet + adaptive product normalization + learning (artificial intelligence) + internet + similarity function + Internet comparison shopping + online learning	AuthorProvided Keywords Not Found	The problem of record linkage focuses on determining whether two object descriptions refer to the same underlying entity. Addressing this problem effectively has many practical applications, e.g., elimination of duplicate records in databases and citation matching for scholarly articles. In this paper, we consider a new domain where the record linkage problem is manifested: Internet comparison shopping. We address the resulting linkage setting that requires learning a similarity function between record pairs from streaming data. The learned similarity function is subsequently used in clustering to determine which records are co-referent and should be linked. We present an online machine learning method for addressing this problem, where a composite similarity function based on a linear combination of basis functions is learned incrementally. We illustrate the efficacy of this approach on several real-world datasets from an Internet comparison shopping site, and show that our method is able to effectively learn various distance functions for product data with differing characteristics. We also provide experimental results that show the importance of considering multiple performance measures in record linkage evaluation.
81444A37	International Conference on Data Mining	ashok samal + david b marx + jiazheng shi	2005	Face recognition using landmark-based bidimensional regression	eigenvalues + correlation statistics + regression analysis + face recognition + eigenvalue weighted bidimensional regression + face images + landmark-based bidimensional regression + principal component analysis + eigenvalues and eigenfunctions + biologically meaningful landmarks	AuthorProvided Keywords Not Found	This paper studies how biologically meaningful landmarks extracted from face images can be exploited for face recognition using the bidimensional regression. Incorporating the correlation statistics of landmarks, this paper also proposes a new approach called eigenvalue weighted bidimensional regression. Complex principal component analysis is used for computing eigenvalues and removing correlation among landmarks. We evaluate our approach using two standard face databases: the Purdue AR and the NIST FERET. Experimental results show that the bidimensional regression is an efficient method to exploit geometry information of face images.
5D08DF80	International Conference on Data Mining	csaba szepesvari + zoltan szamonek	2005	X-mHMM: an efficient algorithm for training mixtures of HMMs when the number of mixtures is unknown	hidden Markov models + hidden markov models + X-means algorithm + sequence clustering + pattern clustering + hidden Markov model + synthetic data + hidden markov model + X-mHMM algorithm	AuthorProvided Keywords Not Found	In this paper we consider sequence clustering problems and propose an algorithm for the estimation of the number of clusters based on the X-means algorithm. The sequences are modeled using mixtures of Hidden Markov Models. By means of experiments with synthetic data we analyze the proposed algorithm. This algorithm proved to be both computationally efficient and capable of providing accurate estimates of the number of clusters. Some results of experiments with real-world Web-log data are also given.
7D932714	International Conference on Data Mining	lars schmidtthieme	2005	Compound classification models for recommender systems	collaborative filtering + pattern classification + autocorrelation structure + binary classification problem + multiclass classification problem + consumer behaviour + information filters + linear support vector machines + recommender system + recommender systems + support vector machine + multi class classification + compound classification model + customer behavior + nearest neighbor method	AuthorProvided Keywords Not Found	Recommender systems recommend products to customers based on ratings or past customer behavior. Without any information about attributes of the products or customers involved, the problem has been tackled most successfully by a nearest neighbor method called collaborative filtering in the context, while additional efforts invested in building classification models did not pay off and did not increase the quality. Therefore, classification methods have mainly been used in conjunction with product or customer attributes. Starting from a view on the plain recommendation task without attributes as a multi-class classification problem, we investigate two particularities, its autocorrelation structure as well as the absence of re-occurring items (repeat buying). We adapt the standard generic reductions 1-vs-rest and 1-vs-l of multi-class problems to a set of binary classification problems to these particularities and thereby provide a generic compound classifier for recommender systems. We evaluate a particular specialization thereof using linear support vector machines as member classifiers on MovieLens data and show that it outperforms state-of-the-art methods, i.e., item-based collaborative filtering.
7FA8425D	International Conference on Data Mining	shotaro akaho + hideto kazawa + toshihiro kamishima	2005	Supervised ordering - an empirical survey	learning artificial intelligence + ordered object + sorting + supervised ordering + ordered lists + learning (artificial intelligence) + object sorting	AuthorProvided Keywords Not Found	Ordered lists of objects are widely used as representational forms. Such ordered objects include Web search results or bestseller lists. In spite of their importance, methods of processing orders have received little attention. However, research concerning orders has become common; in particular, researchers have developed various methods for the task of supervised ordering to acquire functions for object sorting from example orders. Here, we give a unified view of these methods and our new one, and empirically survey their merits and demerits.
8128159E	International Conference on Data Mining	bruno martins + mario j silva	2005	A graph-ranking algorithm for geo-referencing documents	document handling + computer science + PageRank + geographic information systems + geographical scope + georeferencing documents + graph-ranking algorithm	AuthorProvided Keywords Not Found	This paper presents an application of PageRank for assigning documents with a corresponding geographical scope. We describe the technique in detail, together with its theoretical formulation. Experimental results are promising, comparing favorably with previous proposals.
5E0DB475	International Conference on Data Mining	haixun wang + jianyong wang + ke wang + philip s yu + jian liu + jian pei	2005	Efficiently mining frequent closed partial orders	data mining + data sequence + total orders frequent segments + frequent closed partial orders mining + mining ordering information + total order + sequential pattern mining + partial order	AuthorProvided Keywords Not Found	Mining ordering information from sequence data is an important data mining task. Sequential pattern mining (Agrawal and Srikant, 1995) can be regarded as mining frequent segments of total orders from sequence data. However, sequential patterns are often insufficient to concisely capture the general ordering information.
7F4CEE12	International Conference on Data Mining	hanshen huang + bouho yang + chunnan hsu	2005	Triple jump acceleration for the EM algorithm	bound optimization + em algorithm + extrapolation + optimisation + triple jump acceleration + pattern clustering + expectation-maximisation algorithm + convergence rate + EM algorithm + third search point extrapolation + probabilistic model + search problems	AuthorProvided Keywords Not Found	This paper presents the triple jump framework for accelerating the EM algorithm and other bound optimization methods. The idea is to extrapolate the third search point based on the previous two search points found by regular EM. As the convergence rate of regular EM becomes slower, the distance of the triple jump is longer, and thus provide higher speedup for data sets where EM converges slowly. Experimental results show that the triple jump framework significantly outperforms EM and other acceleration methods of EM for a variety of probabilistic models, especially when the data set is sparse. The results also show that the triple jump framework is particularly effective for cluster models.
8143F633	International Conference on Data Mining	wensheng wu + anhai doan + clement yu	2005	Merging interface schemas on the deep Web via clustering aggregation	approximation theory + optimization problem + LMax algorithm + NP-complete problem + rule based + optimisation + schema integration + satisfiability + approximation algorithm + clustering aggregation + interface schema + Internet + internet + deep web + deep Web + computational complexity	AuthorProvided Keywords Not Found	We consider the problem of integrating a large number of interface schemas over the deep Web, The scale of the problem and the diversity of the sources present serious challenges to the conventional manual or rule-based approaches to schema integration. To address these challenges, we propose a novel formulation of schema integration as an optimization problem, with the objective of maximally satisfying the constraints given by individual schemas. Since the optimization problem can be shown to be NP-complete, we develop a novel approximation algorithm LMax, which builds the unified schema via recursive applications of clustering aggregation. We further extend LMax to handle the irregularities frequently occurring among the interface schemas. Extensive evaluation on real-world data sets shows the effectiveness of our approach.
8101E3F6	International Conference on Data Mining	keke chen + ling liu	2005	Privacy preserving data classification with rotation perturbation	data model + pattern classification + privacy preserving data classification + condensation approach + randomization approach + data mining + data privacy + data perturbation + rotation perturbation + privacy preserving data mining	AuthorProvided Keywords Not Found	Data perturbation techniques are one of the most popular models for privacy preserving data mining (Agrawal and Srikant, 2000; Aggarwal and Yu, 2004). It is especially convenient for applications where the data owners need to export/publish the privacy-sensitive data. A data perturbation procedure can be simply described as follows. Before the data owner publishes the data, they randomly change the data in certain way to disguise the sensitive information while preserving the particular data property that is critical for building the data models. Several perturbation techniques have been proposed recently, among which the most typical ones are randomization approach (Agrawal and Srikant, 2000) and condensation approach (Aggarwal and Yu, 2004).
7D474726	International Conference on Data Mining	walid g aref + ahmed k elmagarmid + mohamed g elfeky	2005	WARP: time warping for periodicity detection	periodicity detection + data mining + noise + time series + periodicity mining + time warping + time series data + noise removal	AuthorProvided Keywords Not Found	Periodicity mining is used for predicting trends in time series data. Periodicity detection is an essential process in periodicity mining to discover potential periodicity rates. Existing periodicity detection algorithms do not take into account the presence of noise, which is inevitable in almost every real-world time series data. In this paper, we tackle the problem of periodicity detection in the presence of noise. We propose a new periodicity detection algorithm that deals efficiently with all types of noise. Based on time warping, the proposed algorithm warps (extends or shrinks) the time axis at various locations to optimally remove the noise. Experimental results show that the proposed algorithm outperforms the existing periodicity detection algorithms in terms of noise resiliency.
7F74F125	International Conference on Data Mining	kouzou ohara + mariechristine rousset + michele sebag + takashi washio + hiroshi motoda + alexandre termier	2005	Efficient mining of high branching factor attribute trees	frequent pattern depth + hooking principle + efficient tree mining + data mining + trees (mathematics) + high branching factor attribute trees + DryadeParent + algorithm complexity + CMTreeMiner + computational complexity	AuthorProvided Keywords Not Found	In this paper, we present a new tree mining algorithm, DryadeParent, based on the hooking principle first introduced in Dryade (Termier et al, 2004). In the experiments, we demonstrate that the branching factor and depth of the frequent patterns to find are key factor of complexity for tree mining algorithms. We show that DryadeParent outperforms the current fastest algorithm, CMTreeMiner, by orders of magnitude on datasets where the frequent patterns have a high branching factor.
7D47D283	International Conference on Data Mining	peng wang + haixun wang + baile shi + xiaochen wu + wei wang	2005	On reducing classifier granularity in mining concept-drifting data streams	pattern classification + ensemble classifiers + concept drift + concept-drifting data stream mining + model granularity reduction + data mining + synthetic data + classifier granularity + model update cost reduction + incrementally updated classifier	AuthorProvided Keywords Not Found	Many applications use classification models on streaming data to detect actionable alerts. Due to concept drifts in the underlying data, how to maintain a model's up-to-dateness has become one of the most challenging tasks in mining data streams. State of the art approaches, including both the incrementally updated classifiers and the ensemble classifiers, have proved that model update is a very costly process. In this paper, we introduce the concept of model granularity. We show that reducing model granularity will reduce model update cost. Indeed, models of fine granularity enable us to efficiently pinpoint local components in the model that are affected by the concept drift. It also enables us to derive new components that can easily integrate with the model to reflect the current data distribution, thus avoiding expensive updates on a global scale. Experiments on real and synthetic data show that our approach is able to maintain good prediction accuracy at a fraction of model updating cost of state of the art approaches.
7FDA0CE2	International Conference on Data Mining	wei fan + ian davidson + philip s yu + bianca zadrozny	2005	An improved categorization of classifier's sensitivity on sample selection bias	pattern classification + support vector machines + classifier learning + classifier sensitivity categorization + regression analysis + hard-margin support vector machine + sample selection bias + feature vector + Bayesian classifier + selection bias + decision tree + learning artificial intelligence + naive bayes + decision trees + naive Bayes + bayesian classifier + Bayes methods + logistic regression + learning (artificial intelligence)	AuthorProvided Keywords Not Found	"A recent paper categorizes classifier learning algorithms according to their sensitivity to a common type of sample selection bias where the chance of an example being selected into the training sample depends on its feature vector x but not (directly) on its class label y. A classifier learner is categorized as ""local"" if it is insensitive to this type of sample selection bias, otherwise, it is considered ""global"". In that paper, the true model is not clearly distinguished from the model that the algorithm outputs. In their discussion of Bayesian classifiers, logistic regression and hard-margin SVMs, the true model (or the model that generates the true class label for every example) is implicitly assumed to be contained in the model space of the learner, and the true class probabilities and model estimated class probabilities are assumed to asymptotically converge as the training data set size increases. However, in the discussion of naive Bayes, decision trees and soft-margin SVMs, the model space is assumed not to contain the true model, and these three algorithms are instead argued to be ""global learners"". We argue that most classifier learners may or may not be affected by sample selection bias; this depends on the dataset as well as the heuristics or inductive bias implied by the learning algorithm and their appropriateness to the particular dataset."
7D3B37FF	International Conference on Data Mining	ted e senator	2005	Multi-stage classification	pattern classification + cost-benefit ratio + multistage classification + resources processing + data linking + linked data + data collection	AuthorProvided Keywords Not Found	While much research has focused on methods for evaluating and maximizing the accuracy of classifiers either individually or in ensembles, little effort has been devoted to analyzing how classifiers are typically deployed in practice. In many domains, classifiers are used as part of a multi-stage process that increases accuracy at the expense of more data collection and/or more processing resources as the likelihood of a positive class label increases. This paper systematically explores the tradeoffs inherent in constructing these multi-stage classifiers from a series of increasingly accurate and expensive individual classifiers, considering a variety of metrics such as accuracy, cost/benefit ratio, and lift. It suggests architectures appropriate for both independent instances and for highly linked data.
7F5F2E41	International Conference on Data Mining	srujana merugu + thomas george	2005	A scalable collaborative filtering framework based on co-clustering	parallel algorithms + collaborative filtering + matrix factorization + parallel algorithm + e commerce + information filtering + real-time collaborative filtering + information filters + collaborative filtering-based recommender system + recommender system + real-time systems + weighted coclustering + real time systems + real time	AuthorProvided Keywords Not Found	Collaborative filtering-based recommender systems have become extremely popular due to the increase in Web-based activities such as e-commerce and online content distribution. Current collaborative filtering (CF) techniques such as correlation and SVD based methods provide good accuracy, but are computationally expensive and can be deployed only in static off-line settings. However, a number of practical scenarios require dynamic real-time collaborative filtering that can allow new users, items and ratings to enter the system at a rapid rate. In this paper, we consider a novel CF approach based on a proposed weighted co-clustering algorithm (Banerjee et al., 2004) that involves simultaneous clustering of users and items. We design incremental and parallel versions of the co-clustering algorithm and use it to build an efficient real-time CF framework. Empirical evaluation demonstrates that our approach provides an accuracy comparable to that of the correlation and matrix factorization based approaches at a much lower computational cost.
597EAB2B	International Conference on Data Mining	michael j brooks + yuhong yan + daniel lemire	2005	An optimal linear time algorithm for quasi-monotonic segmentation	top down + linear time algorithm + quasimonotonic segmentation + time series + array segmentation + qualitative modeling + linear time + pattern recognition + computational complexity + linear time top-down regression	AuthorProvided Keywords Not Found	Monotonicity is a simple yet significant qualitative characteristic. We consider the problem of segmenting an array in up to K segments. We want segments to be as monotonic as possible and to alternate signs. We propose a quality metric for this problem, present an optimal linear time algorithm based on novel formalism, and compare experimentally its performance to a linear time top-down regression algorithm. We show that our algorithm is faster and more accurate. Applications include pattern recognition and qualitative modeling.
7DA67274	International Conference on Data Mining	sam kwong + hanli wang + chiho tsang	2005	Anomaly intrusion detection using multi-objective genetic fuzzy system and agent-based evolutionary computation framework	knowledge base + multi-agent systems + evolutionary computing + agent-based evolutionary computation + intrusion detection + genetic algorithms + multi agent systems + intrusion detection system + rule based + security of data + fuzzy rule-based knowledge + knowledge based systems + anomaly intrusion detection + multiobjective genetic fuzzy system + fuzzy systems	AuthorProvided Keywords Not Found	In this paper, we present a multi-objective genetic fuzzy system for anomaly intrusion detection. The proposed system extracts accurate and interpret able fuzzy rule-based knowledge from network data using an agent-based evolutionary computation framework. The experimental results on KDD-Cup99 intrusion detection benchmark data demonstrate that our system can achieve high detection rate for intrusion attacks and low false positive rate for normal network traffic.
5D755B13	International Conference on Data Mining	tsuyoshi ide	2005	Pairwise symmetry decomposition method for generalized covariance analysis	decomposition method + pairwise symmetry decomposition + irreducible representation + pattern clustering + cumulant + probability + cluster expansion + generalized covariance analysis + generating function + covariance analysis + pairwise cross-cumulants + probability density function	AuthorProvided Keywords Not Found	We propose a new theoretical framework for generalizing the traditional notion of covariance. First, we discuss the role of pairwise cross-cumulants by introducing a cluster expansion technique for the cumulant generating function. Next, we introduce a novel concept of symmetry decomposition of probability density functions according to the C4V group. By utilizing the irreducible representations, generalized covariances are explicitly defined, and their utility is demonstrated using an analytically solvable model.
80D4FA9A	International Conference on Data Mining	jayasimha katukuri + saygin celebi + dheerendranath mundluru	2005	Automatically mining result records from search engine response pages	search engines + query submission + search engine + web mining + data mining + metasearch engines + Web applications + information extraction + automatically mining result records + deep Web crawlers + Web mining systems + search engine response pages + Internet + deep web + internet	AuthorProvided Keywords Not Found	Usually, Web applications such as deep Web crawlers, metasearch engines, and other Web mining systems need to extract information displayed in the form of result records on response pages returned by search engines in response to submitted queries. Extracting such records is challenging as search engines are heterogeneous in displaying their records. In addition, response pages returned by many search engines include other noisy content such as advertisements, suggestion links, etc., which make the extraction task even more complicated. In this paper, we propose a highly effective and efficient algorithm for automatically mining result records from search engine response pages.
813AAFAC	International Conference on Data Mining	jing peng + zujia xu + bill p buckles + kun zhang	2005	Learning through changes: an empirical study of dynamic behaviors of probability estimation trees	learning artificial intelligence + binary classification problem + confusion factor trees + probability + trees (mathematics) + empirical study + probability estimation trees + binary classification + learning (artificial intelligence) + learning through changes	AuthorProvided Keywords Not Found	In practice, learning from data is often hampered by the limited training examples. In this paper, as the size of training data varies, we empirically investigate several probability estimation tree algorithms over eighteen binary classification problems. Nine metrics are used to evaluate their performances. Our aggregated results show that ensemble trees consistently outperform single trees. Confusion factor trees(CFT) register poor calibration even as training size increases, which shows that CFTs are potentially biased if data sets have small noise. We also provide analysis on the observed performance of the tree algorithms.
5F9CDAF0	International Conference on Data Mining	krishna kummamuru + nimit kumar + deepa paranjpe	2005	Semi-supervised clustering with metric learning using relative comparisons	relative comparison + learning artificial intelligence + clustering algorithm + metric learning + pattern clustering + dissimilarity measure + semisupervised clustering + learning (artificial intelligence)	AuthorProvided Keywords Not Found	Semi-supervised clustering algorithms partition a given data set using limited supervision from the user. In this paper, we propose a clustering algorithm that uses supervision in terms of relative comparisons, viz., x is closer to y than to z. The success of a clustering algorithm also depends on the kind of dissimilarity measure. The proposed clustering algorithm learns the underlying dissimilarity measure while finding compact clusters in the given data set. Through our experimental studies on high-dimensional textual data sets, we demonstrate that the proposed algorithm achieves higher accuracy than the algorithms using pair-wise constraints for supervision.
7FC0840D	International Conference on Data Mining	hiroyuki kitagawa + christos faloutsos + cui zhu	2005	Example-based robust outlier detection in high dimensional datasets	example-based robust outlier detection + data analysis + outlier detection + high dimensional data sets + high dimensional outlier	AuthorProvided Keywords Not Found	Detecting outliers is an important problem. Most of its applications typically possess high dimensional datasets. In high dimensional space, the data becomes sparse which implies that every object can be regarded as an outlier from the point of view of similarity. Furthermore, a fundamental issue is that the notion of which objects are outliers typically varies between users, problem domains or, even, datasets. In this paper, we present a novel robust solution which detects high dimensional outliers based on user examples and tolerates incorrect inputs. It studies the behavior of projections of such a few examples, to discover further objects that are outstanding in the projection where many examples are outlying. Our experiments on both real and synthetic datasets demonstrate the ability of the proposed method to detect outliers corresponding to the user examples.
7E08D06D	International Conference on Data Mining	tariqul hoque + carson kaisang leung + quamrul i khan	2005	CanTree: a tree structure for efficient incremental mining of frequent patterns	transaction processing + CanTree + tree structure + data mining + tree nodes + tree data structures + incremental mining + canonical-order tree + FP-tree based frequent-pattern mining + incremental updating + transaction database	AuthorProvided Keywords Not Found	Since its introduction, frequent-pattern mining has been the subject of numerous studies, including incremental updating. Many existing incremental mining algorithms are Apriori-based, which are not easily adoptable to FP-tree based frequent-pattern mining. In this paper, we propose a novel tree structure, called CanTree (canonical-order tree), that captures the content of the transaction database and orders tree nodes according to some canonical order. By exploiting its nice properties, the CanTree can be easily maintained when database transactions are inserted, deleted, and/or modified. For example, the CanTree does not require adjustment, merging, and/or splitting of tree nodes during maintenance. No rescan of the entire updated database or reconstruction of a new tree is needed for incremental updating. Experimental results show the effectiveness of our CanTree.
7E5D798A	International Conference on Data Mining	xintao wu + yongge wang	2005	Approximate inverse frequent itemset mining: privacy, complexity, and approximation	association rule + complexity + approximation theory + data mining + association rules + privacy + NP-complete problem + approximate inverse frequent itemset mining + synthetic basket dataset + approximation algorithm + data privacy + benchmark testing + real-life databases + computational complexity	inverse frequent itemset mining,+data mining,+privacy,+complexity	In order to generate synthetic basket datasets for better benchmark testing, it is important to integrate characteristics from real-life databases into the synthetic basket datasets. The characteristics that could be used for this purpose include the frequent itemsets and association rules. The problem of generating synthetic basket datasets from frequent itemsets is generally referred to as inverse frequent itemset mining. In this paper, we show that the problem of approximate inverse frequent itemset mining is NP-complete. Then we propose and analyze an approximate algorithm for approximate inverse frequent itemset mining, and discuss privacy issues related to the synthetic basket dataset. In particular, we propose an approximate algorithm to determine the privacy leakage in a synthetic basket dataset.
7E7CC6FE	International Conference on Data Mining	weiming hu + stephen j maybank + xindong wu + dacheng tao + xuelong li	2005	Supervised tensor learning	learning machine design + discriminant analysis + support vector machines + data mining + supervised learning + tensors + machine learning + minimax techniques + minimax probability machines + supervised tensor learning + learning artificial intelligence + support vector machine + generic algorithm + feature extraction + convex optimization + binary classification + statistical analysis + learning (artificial intelligence) + linear discriminant analysis + tenor rank-one discriminant analysis	AuthorProvided Keywords Not Found	This paper aims to take general tensors as inputs for supervised learning. A supervised tensor learning (STL) framework is established for convex optimization based learning techniques such as support vector machines (SVM) and minimax probability machines (MPM). Within the STL framework, many conventional learning machines can be generalized to take nth-order tensors as inputs. We also study the applications of tensors to learning machine design and feature extraction by linear discriminant analysis (LDA). Our method for tensor based feature extraction is named the tenor rank-one discriminant analysis (TR1DA). These generalized algorithms have several advantages: 1) reduce the curse of dimension problem in machine learning and data mining; 2) avoid the failure to converge; and 3) achieve better separation between the different categories of samples. As an example, we generalize MPM to its STL version, which is named the tensor MPM (TMPM). TMPM learns a series of tensor projections iteratively. It is then evaluated against the original MPM. Our experiments on a binary classification problem show that TMPM significantly outperforms the original MPM.
807AF1FA	International Conference on Data Mining	steven m beitzel + david d lewis + aleksander kolcz + ophir frieder + abdur chowdhury + eric c jensen	2005	Improving automatic query classification via semi-supervised learning	semi supervised learning + manual matching + search engines + automatic query classification + semisupervised learning + computational linguistics + supervised learning + data mining + information retrieval + classification + topical classification + learning artificial intelligence + query classification + Web query logs + Web query classification + Web search systems + Internet + learning (artificial intelligence) + internet	AuthorProvided Keywords Not Found	Accurate topical classification of user queries allows for increased effectiveness and efficiency in general-purpose Web search systems. Such classification becomes critical if the system is to return results not just from a general Web collection but from topic-specific back-end databases as well. Maintaining sufficient classification recall is very difficult as Web queries are typically short, yielding few features per query. This feature sparseness coupled with the high query volumes typical for a large-scale search service makes manual and supervised learning approaches alone insufficient. We use an application of computational linguistics to develop an approach for mining the vast amount of unlabeled data in Web query logs to improve automatic topical Web query classification. We show that our approach in combination with manual matching and supervised learning allows us to classify a substantially larger proportion of queries than any single technique. We examine the performance of each approach on a real Web query stream and show that our combined method accurately classifies 46% of queries, outperforming the recall of best single approach by nearly 20%, with a 7% improvement in overall effectiveness.
7FCDD024	International Conference on Data Mining	runa bhaumik + robin burke + bamshad mobasher + chad williams	2005	Segment-based injection attacks against collaborative filtering recommender systems	collaborative filtering + item-based algorithm + recommender system + security of data + collaborative filtering recommender systems + user-based algorithm + biased profile injection + information filtering + segment-based injection attack	AuthorProvided Keywords Not Found	"Significant vulnerabilities have recently been identified in collaborative filtering recommender systems. Researchers have shown that attackers can manipulate a system's recommendations by injecting biased profiles into it. In this paper, we examine attacks that concentrate on a targeted set of users with similar tastes, biasing the system's responses to these users. We show that such attacks are both pragmatically reasonable and also highly effective against both user-based and item-based algorithms. As a result, an attacker can mount such a ""segmented"" attack with little knowledge of the specific system being targeted and with strong likelihood of success."
816FF541	International Conference on Data Mining	mehmet keskinoz + ali inan + yucel saygin + ayca azgin hintoglu	2005	Suppressing data sets to prevent discovery of association rules	association rule + data analysis + confidential information hiding + data set suppression + data mining + association rule discovery prevention + data privacy + data collection + customer relationship management	AuthorProvided Keywords Not Found	Enterprises have been collecting data for many reasons including better customer relationship management, and high-level decision making. Public safety was another motivation for large-scale data collection efforts initiated by government agencies. However, such widespread data collection efforts coupled with powerful data analysis tools raised concerns about privacy. This is due to the fact that collected data may contain confidential information. One method to ensure privacy is to selectively hide confidential information from the data sets to be disclosed. In this paper, we focus on hiding confidential correlations. We introduce a heuristic to reduce the information loss and propose a blocking method that prevents discovery of confidential correlations while preserving the usefulness of the data set.
NE513	International Conference on Data Mining	V. P. Janeja+V. Atluri	2005	FS3: a random walk based free-form spatial scan statistic for anomalous window detection	data analysis + anomalous window detection + scan window + random processes + FS3 + statistical analysis + random walk based free-form spatial scan statistic	AuthorProvided Keywords Not Found	Often, it is required to identify anomalous windows over a spatial region that reflect unusual rate of occurrence of a specific event of interest. A spatial scan statistic essentially considers a scan window, and identifies anomalous windows by moving the scan window in the region. While spatial scan statistic has been successful, earlier proposals suffer from two limitations: (i) They restrict the scan window to be of a regular shape (e.g., circle, rectangle, cylinder). However, the region of anomaly, in general, is not necessarily of a regular shape. (ii) They take into account autocorrelation among spatial data, but not spatial heterogeneity. As a result, they often result in inaccurate anomalous windows. To address these limitations, we propose a random walk based free-form spatial scan statistic (FS3). Application of FS3 on real datasets has shown that it can identify more refined anomalous windows with better likelihood ratio of it being an anomaly, than those identified by earlier spatial scan statistic approaches.
7F4C23F1	International Conference on Data Mining	haiyun bian	2005	A levelwise search algorithm for interesting subspace clusters	interesting subspace clusters + search algorithm + high dimensional data + pattern clustering + satisfiability + minimum density property + levelwise search algorithm + search problems	AuthorProvided Keywords Not Found	We present a levelwise search algorithm for finding subspace clusters in high dimensional data satisfying various properties besides the commonly used minimum density property. A set of such properties are summarized and a user can choose any of these properties. A lattice is built with all the discovered clusters which enables further analysis and discovery of useful knowledge about the clusters and their inter-relationships.
7D40A7AD	International Conference on Data Mining	anjana kakoti mahanta + ningthoujam gourakishwar singh + sanasam ranbir singh	2005	CloseMiner: discovering frequent closed itemsets using frequent closed tidsets	frequent closed itemset discovery + real database + data mining + frequent closed tidsets + synthetic database + CloseMiner + set theory	AuthorProvided Keywords Not Found	Complete set of itemsets can be grouped into non-overlapping clusters identified by closed tidsets. Each cluster has only one closed itemset and is the superset of all itemsets with the same support. Number of closed itemsets is identical to the number of clusters. Therefore, the problem of discovering closed itemsets can be considered as the problem of clustering the complete set of itemsets by closed tidsets. In this paper, we present CloseMiner, a new algorithm for discovering all frequent closed itemsets by grouping the complete set of itemsets into non-overlapping clusters identified by closed tidsets. An extensive experimental evaluation on a number of real and synthetic databases shows that CloseMiner outperforms Apriori and CHARM.
80D884BA	International Conference on Data Mining	wai lam + taklam wong	2005	Hot item mining and summarization from multiple auction Web sites	semi supervised learning + multiple auction Web sites + online auction Web sites + web pages + hidden Markov model + semisupervised learning + graph theory + data mining + HMM-based learning + graph mincuts algorithm + product feature extraction + hot item summarization + hidden Markov models + hidden markov models + learning artificial intelligence + hot item mining + Web sites + learning (artificial intelligence) + electronic commerce	AuthorProvided Keywords Not Found	Online auction Web sites are fast changing, highly dynamic, and complex as they involve tremendous sellers and potential buyers, as well as a huge amount of items listed for bidding. We develop a two-phase framework which aims at mining and summarizing hot items from multiple auction Web sites to assist decision making. The objective of the first phase is to automatically extract the product features and product feature values of the items from the descriptions provided by the sellers. We design a HMM-based learning method to train an extended HMM model which can adapt to the unseen Web page from which the information is extracted. The goal of the second phase is to discover and summarize the hot items based on the extracted information. We formulate the hot item mining task as a semi-supervised learning problem and employ the graph mincuts algorithm to accomplish this task. The summary of the hot items is then generated by considering the frequency and the position of the product features being mentioned in the descriptions. We have conducted extensive experiments from several real-world auction Web sites to demonstrate the effectiveness of our framework.
80A9678F	International Conference on Data Mining	qiang yang + jie yin	2005	Integrating hidden Markov models and spectral analysis for sensory time series clustering	sequence clustering + wireless sensor networks + hidden Markov model + data mining + multidimensional trajectory data + time series + spectral analysis + standard model + data reduction + hidden Markov models + hidden markov models + dimensionality reduction + sensor network + pattern clustering + hidden markov model + noise reduction + equal-length vector + time series data + spectral clustering + sensory time series clustering	AuthorProvided Keywords Not Found	We present a novel approach for clustering sequences of multi-dimensional trajectory data obtained from a sensor network. The sensory time-series data present new challenges to data mining, including uneven sequence lengths, multi-dimensionality and high levels of noise. We adopt a principled approach, by first transforming all the data into an equal-length vector form while keeping as much temporal information as we can, and then applying dimensionality and noise reduction techniques such as spectral clustering to the transformed data. Experimental evaluation on synthetic and real data shows that our proposed approach outperforms standard model-based clustering algorithms for time series data.
7FC38B16	International Conference on Data Mining	eamonn keogh + chotirat ann ratanamahatana + longin jan latecki + qiang wang + rolf lakaemper + vasileios megalooikonomou	2005	Partial elastic matching of time series	pattern matching + subsequence matching + partial elastic matching + directed graphs + time series matching + directed acyclic graph + time series + query series matching	AuthorProvided Keywords Not Found	We consider the problem of elastic matching of time series. We propose an algorithm that determines a subsequence of a target time series that best matches a query series. In the proposed algorithm, we map the problem of the best matching subsequence to the problem of a cheapest path in a DAG (directed acyclic graph). The proposed approach allows us to also compute the optimal scale and translation of time series values, which is a nontrivial problem in the case of subsequence matching.
7E14828D	International Conference on Data Mining	alexey pryakhin + hanspeter kriegel + matthias schubert + peer kroger	2005	Effective and efficient distributed model-based clustering	pattern clustering + distributed data mining + distributed model-based clustering + data mining + distributed databases + Gaussian distribution + gaussian distribution + distributed environment + data repository + local Gaussian distributions + mixture of gaussians + global patterns	AuthorProvided Keywords Not Found	In many companies data is distributed among several sites, i.e. each site generates its own data and manages its own data repository. Analyzing and mining these distributed sources requires distributed data mining techniques to find global patterns representing the complete information. The transmission of the entire local data set is often unacceptable because of performance considerations, privacy and security aspects, and bandwidth constraints. Traditional data mining algorithms, demanding access to complete data, are not appropriate for distributed applications. Thus, there is a need for distributed data mining algorithms in order to analyze and discover new knowledge in distributed environments. One of the most important data mining tasks is clustering which aims at detecting groups of similar data objects. In this paper, we propose a distributed model-based clustering algorithm that uses EM for detecting local models in terms of mixtures of Gaussian distributions. We propose an efficient and effective algorithm for deriving and merging these local Gaussian distributions to generate a meaningful global model. In a broad experimental evaluation we show that our framework is scalable in a highly distributed environment.
7E17F7EA	International Conference on Data Mining	gagan agrawal + ruoming jin	2005	An algorithm for in-core frequent itemset mining on streaming data	incore frequent item set mining + multipass Apriori algorithm + streaming data + one pass algorithm + data mining	AuthorProvided Keywords Not Found	Frequent item set mining is a core data mining operation and has been extensively studied over the last decade. This paper takes a new approach for this problem and makes two major contributions. First, we present a one pass algorithm for frequent item set mining, which has deterministic bounds on the accuracy, and does not require any out-of-core summary structure. Second, because our one pass algorithm does not produce any false negatives, it can be easily extended to a two pass accurate algorithm. Our two pass algorithm is very memory efficient, and allows mining of datasets with large number of distinct items and/or very low support levels. Our detailed experimental evaluation on synthetic and real datasets shows the following. First, our one pass algorithm is very accurate in practice. Second, our algorithm requires significantly lower memory than Manku and Motwani's one pass algorithm and the multi-pass Apriori algorithm. Our two pass algorithm outperforms Apriori and FP-tree when the number of distinct items is large and/or support levels are very low. In other cases, it is quite competitive, with possible exception of cases where the average length of frequent item sets is quite high.
80B1D5B4	International Conference on Data Mining	eamonn keogh + h van herle + li wei + agenor mafraneto	2005	Atomic wedgie: efficient query filtering for streaming time series	query processing + query filtering + envelope-based lower bounding + time series streaming + data mining + time series + lower bound + atomic wedgie	AuthorProvided Keywords Not Found	In many applications, it is desirable to monitor a streaming time series for predefined patterns. In domains as diverse as the monitoring of space telemetry, patient intensive care data, and insect populations, where data streams at a high rate and the number of predefined patterns is large, it may be impossible for the comparison algorithm to keep up. We propose a novel technique that exploits the commonality among the predefined patterns to allow monitoring at higher bandwidths, while maintaining a guarantee of no false dismissals. Our approach is based on the widely used envelope-based lower bounding technique. Extensive experiments demonstrate that our approach achieves tremendous improvements in performance in the offline case, and significant improvements in the fastest possible arrival rate of the data stream that can be processed with guaranteed no false dismissal.
7E17B542	International Conference on Data Mining	bruno cremilleux + arnaud soulet	2005	Optimizing constraint-based mining by automatically relaxing constraints	approximation theory + antimonotone property + monotone property + data mining + relaxation theory + approximation algorithm + automatic constraint relaxation + search space + monotone relaxation + constraint-based mining	AuthorProvided Keywords Not Found	In constraint-based mining, the monotone and anti-monotone properties are exploited to reduce the search space. Even if a constraint has not such suitable properties, existing algorithms can be re-used thanks to an approximation, called relaxation. In this paper, we automatically compute monotone relaxations of primitive-based constraints. First, we show that the latter are a superclass of combinations of both kinds of monotone constraints. Second, we add two operators to detect the properties of monotonicity of such constraints. Finally, we define relaxing operators to obtain monotone relaxations of them.
7ECA9028	International Conference on Data Mining	philip s yu + benjamin c m fung + ke wang	2005	Template-based privacy preservation in classification problems	classification problem + pattern classification + data mining + template-based privacy preservation + data privacy + sensitive information + privacy templates + classification analysis + sensitive inference	AuthorProvided Keywords Not Found	"In this paper, we present a template-based privacy preservation to protect against the threats caused by data mining abilities. The problem has dual goals: preserve the information for a wanted classification analysis and limit the usefulness of unwanted sensitive inferences that may be derived from the data. Sensitive inferences are specified by a set of ""privacy templates"". Each template specifies the sensitive information to be protected, a set of identifying attributes, and the maximum association between the two. We show that suppressing the domain values is an effective way to eliminate sensitive inferences. For a large data set, finding an optimal suppression is hard, since it requires optimization over all suppressions. We present an approximate but scalable solution. We demonstrate the effectiveness of this approach on real life data sets."
7EED01FE	International Conference on Data Mining	krishna kummamuru + raghu krishnapuram + rakesh agrawal	2005	On learning asymmetric dissimilarity measures	learning artificial intelligence + feature space + learning (artificial intelligence) + asymmetric dissimilarity measure learning + context-sensitive learnable asymmetric dissimilarity measures + gradient descent + objective function	AuthorProvided Keywords Not Found	"Many practical applications require that distance measures to be asymmetric and context-sensitive. We introduce context-sensitive learnable asymmetric dissimilarity (CLAD) measures, which are defined to be a weighted sum of a fixed number of dissimilarity measures where the associated weights depend on the point from which the dissimilarity is measured. The parameters used in defining the measure capture the global relationships among the features. We provide an algorithm to learn the dissimilarity measure automatically from a set of user specified comparisons in the form ""x is closer to y than to z"" and study its performance. The experimental results show that the proposed algorithm outperforms other approaches due to the context sensitive nature of the CLAD measures."
7FCD4960	International Conference on Data Mining	bing liu + kaidi zhao + weimin xiao + thomas m tirpak	2005	A visual data mining framework for convenient identification of useful knowledge	comparative analysis + drill down visualization + data visualisation + data mining + Opportunity Map + house of quality + quality function deployment + data visualization + trend behavior visualization + visual data mining framework + interactive matrix	AuthorProvided Keywords Not Found	Data mining algorithms usually generate a large number of rules, which may not always be useful to human users. In this project, we propose a novel visual data-mining framework, called Opportunity Map, to identify useful and actionable knowledge quickly and easily from the discovered rules. The framework is inspired by the House of Quality from Quality Function Deployment (QFD) in Quality Engineering. It associates discovered rules, related summarized data and data distributions with the application objective using an interactive matrix. Combined with drill down visualization, integrated visualization of data distribution bars and rules, visualization of trend behaviors, and comparative analysis, the Opportunity Map allows users to analyze rules and data at different levels of detail and quickly identify the actionable knowledge and opportunities. The proposed framework represents a systematic and flexible approach to rule analysis. Applications of the system to large-scale data sets from our industrial partner have yielded promising results.
7FE9734F	International Conference on Data Mining	costin barbu + jing peng + raja tanveer iqbal	2005	Classifier fusion using shared sampling distribution for boosting	pattern classification + weighted classifier ensemble + sampling methods + shared sampling distribution + weight update process + classifier fusion	AuthorProvided Keywords Not Found	We present a new framework for classifier fusion that uses a shared sampling distribution for obtaining a weighted classifier ensemble. The weight update process is self regularizing as subsequent classifiers trained on the disjoint views rectify the bias introduced by any classifier in preceding iterations. We provide theoretical guarantees that our approach indeed provides results which are better than the case when boosting is performed separately on different views. The results are shown to outperform other classifier fusion strategies on a well known texture image database.
7D43C8C8	International Conference on Data Mining	kirsten hildrum + philip s yu	2005	Focused community discovery	social network + focused community discovery + Livejournal friends graph + graph theory + social sciences + publicly-available social network + point of interest	AuthorProvided Keywords Not Found	We present a new approach to community discovery. Community discovery usually partitions the graph into communities or clusters. Focused community discovery allows the searcher to specify start points of interest, and find the community of those points. Focused search allows for a much more scalable algorithm in which the time depends only on the size of the community, and not on the number of nodes in the graph, and so is scalable to arbitrarily large graphs. Furthermore, our algorithm is robust to imperfect data, such as extra or missing edges in the graph. We show the effectiveness of our algorithm using both synthetic graphs and on the real-life Livejournal friends graph, a publicly-available social network consisting of over two million users and 13 million edges.
7F514293	International Conference on Data Mining	jan f prins + jinze liu + wei wang + susan paulsen + andrew b nobel	2005	Mining approximate frequent itemsets from noisy data	col + noise-tolerant itemset model + data analysis + noisy data + data mining + data sets analysis + data patterns + frequent itemset mining + approximate frequent itemset + exact frequent itemset + error tolerant itemset	AuthorProvided Keywords Not Found	"Frequent itemset mining is a popular and important first step in analyzing data sets across a broad range of applications. The traditional, ""exact"" approach for finding frequent itemsets requires that every item in the itemset occurs in each supporting transaction. However, real data is typically subject to noise, and in the presence of such noise, traditional itemset mining may fail to detect relevant itemsets, particularly those large itemsets that are more vulnerable to noise. In this paper we propose approximate frequent itemsets (AFI), as a noise-tolerant itemset model. In addition to the usual requirement for sufficiently many supporting transactions, the AFI model places constraints on the fraction of errors permitted in each item column and the fraction of errors permitted in a supporting transaction. Taken together, these constraints winnow out the approximate itemsets that exhibit systematic errors. In the context of a simple noise model, we demonstrate that AFI is better at recovering underlying data patterns, while identifying fewer spurious patterns than either the exact frequent itemset approach or the existing error tolerant itemset approach of Yang et al."
7E6E4336	International Conference on Data Mining	fabio aiolli	2005	A preference model for structured supervised learning tasks	ordinal regression + instance ranking + supervised learning + regression analysis + label ranking + preference model + classification regression + rate prediction + order prediction + structured prediction + structured supervised learning + learning artificial intelligence + learning (artificial intelligence)	AuthorProvided Keywords Not Found	The preference model introduced in this paper gives a natural framework and a principled solution for a broad class of supervised learning problems with structured predictions, such as predicting orders (label and instance ranking), and predicting rates (classification and ordinal regression). We show how all these problems can be cast as linear problems in an augmented space, and we propose an on-line method to efficiently solve them. Experiments on an ordinal regression task confirm the effectiveness of the approach.
7E65D8EE	International Conference on Data Mining	shipeng yu + volker tresp + matthias schubert + hanspeter kriegel + kai yu + yi huang	2005	Hierarchy-regularized latent semantic indexing	optimization problem + text analysis + latent semantic indexing + indexing + data mining + hierarchical structure + empirical study + knowledge management + document mapping + similarity graph + hierarchy-regularized latent semantic indexing + text mining + vector space + hierarchical taxonomy + textual documents	AuthorProvided Keywords Not Found	Organizing textual documents into a hierarchical taxonomy is a common practice in knowledge management. Beside textual features, the hierarchical structure of directories reflect additional and important knowledge annotated by experts. It is generally desired to incorporate this information into text mining processes. In this paper, we propose hierarchy-regularized latent semantic indexing, which encodes the hierarchy into a similarity graph of documents and then formulates an optimization problem mapping each document into a low dimensional vector space. The new feature space preserves the intrinsic structure of the original taxonomy and thus provides a meaningful basis for various learning tasks like visualization and classification. Our approach employs the information about class proximity and class specificity, and can naturally cope with multi-labeled documents. Our empirical studies show very encouraging results on two real-world data sets, the new Reuters (RCVI) benchmark and the Swissprot protein database.
80FA9555	International Conference on Data Mining	yixin chen + huimin chen + henry l bart + shuqing huang	2005	A computational framework for taxonomic research: diagnosing body shape within fish species complexes	pattern classification + automated feature selection + data analysis + species complex + taxonomic research + new species discovery + body shape + fish species complexes + body shape diagnosis + computational framework + automated feature classification + feature selection + zoology	AuthorProvided Keywords Not Found	It is estimated that ninety percent of the world's species have yet to be discovered and described. The main reason for the slow pace of new species description is that the science of taxonomy, as traditionally practiced, can be very laborious. To formally describe a new species, taxonomists have to manually gather and analyze data from large numbers of specimens, often from broad geographic areas, and identify the smallest subset of external body characters that uniquely diagnoses the new species as distinct from all its known relatives. In this paper, we use an automated feature selection and classification approach to address the taxonomic impediment in new species discovery. The experiments on a taxonomic problem involving species of suckers in the genus Carpiodes demonstrate promising results.
806C47A1	International Conference on Data Mining	deepak agarwal	2005	An empirical Bayes approach to detect anomalies in dynamic multidimensional arrays	data mining + large-scale spoken dialog systems + anomaly detection + empirical Bayes approach + business intelligence + gaussian processes + process control + statistical test + error rate + multiple testing + Gaussian processes + Gaussian mixture + Bayes methods + false positive + dynamic multidimensional arrays	AuthorProvided Keywords Not Found	"We consider the problem of detecting anomalies in data that arise as multidimensional arrays with each dimension corresponding to the levels of a categorical variable. In typical data mining applications, the number of cells in such arrays is usually large. Our primary focus is detecting anomalies by comparing information at the current time to historical data. Naive approaches advocated in the process control literature do not work well in this scenario due to the multiple testing problems - performing multiple statistical tests on the same data produce excessive number of false positives. We use an empirical Bayes method which works by fitting a two component Gaussian mixture to deviations at current time. The approach is scalable to problems that involve monitoring massive number of cells and fast enough to be potentially useful in many streaming scenarios. We show the superiority of the method relative to a naive ""per component error rate"" procedure through simulation. A novel feature of our technique is the ability to suppress deviations that are merely the consequence of sharp changes in the marginal distributions. This research was motivated by the need to extract critical application information and business intelligence from the daily logs that accompany large-scale spoken dialog systems deployed by AT&T. We illustrate our method on one such system."
8155A05F	International Conference on Data Mining	volker heun + stefan kramer + johannes fischer	2005	Fast frequent string mining using suffix arrays	computational biology + data mining + string matching + fast frequent string mining + lcp arrays + computational complexity + suffix arrays	AuthorProvided Keywords Not Found	We present a method to mine strings that are frequent in one database and infrequent in another. The method uses suffix- and lcp-arrays that can be computed extremely fast and space efficiently, and further exhibit a good locality behavior. Experiments with several biologically relevant data sets show that our approach outperforms existing methods in terms of time and space.
81789EBE	International Conference on Data Mining	anne m denton	2005	Kernel-density-based clustering of time series subsequences using a continuous random-walk noise model	random walk + white noise + continuous random-walk noise model + pattern clustering + noise elimination + kernel-density-based clustering + time series + kernel density + time series subsequence data + statistical analysis + stochastic processes	AuthorProvided Keywords Not Found	Noise levels in time series subsequence data are typically very high, and properties of the noise differ front those of white noise. The proposed algorithm incorporates a continuous random-walk noise model into kernel-density-based clustering. Evaluation is done by testing to what extent the resulting clusters are predictive of the process that generated the time series. It is shown that the new algorithm not only outperforms partitioning techniques that lead to trivial and unsatisfactory results under the given quality measure, but also improves upon other density-based algorithms. The results suggest that the noise elimination properties of kernel-density-based clustering algorithms can be of significant value for the use of clustering in preprocessing of data.
8024E469	International Conference on Data Mining	anna m manning + david j haglin	2005	A new algorithm for finding minimal sample uniques for use in statistical disclosure assessment	minimal sample uniques + recursive algorithm + SUDA2 + search space + database management systems + statistical analysis + special unique detection algorithm + statistical disclosure assessment	AuthorProvided Keywords Not Found	We present SUDA2, a recursive algorithm for finding minimal sample uniques (MSUs). SUDA2 uses a novel method for representing the search space for MSUs and new observations about the properties of MSUs to prune and traverse this space. Experimental comparisons with previous work demonstrate that SUDA2 is not only several orders of magnitude faster but is also capable of identifying the boundaries of the search space, enabling datasets of larger numbers of columns than before to be addressed.
801EB297	International Conference on Data Mining	ada waichee fu + alexander tuzhilin + yuelong jiang + ke wang	2005	Mining patterns that respond to actions	pattern mining + data mining + pattern recognition	AuthorProvided Keywords Not Found	Data mining focuses on patterns that summarize the data. In this paper, we focus on mining patterns that could change the state by responding to opportunities of actions.
7E1A9335	International Conference on Data Mining	lisa singh	2005	Pruning social networks using structural properties and descriptive attributes	social network + NASDAQ + bibliographic network + structural property + graph theory + NYSE + social network pruning + descriptive attribute + information networks	AuthorProvided Keywords Not Found	Scale is often an issue with understanding and making sense of large social networks. Here we investigate methods for pruning social networks by determining the most relevant relationships. We measure importance in terms of predictive accuracy on a set of target attributes of the social network. Our goal is to create a pruned network that models only the most informative affiliations and relationships. We present methods for pruning networks based on both structural properties and descriptive attributes demonstrate it on a network of NASDAQ and NYSE businesses and on a bibliographic network.
800F482E	International Conference on Data Mining	michalis vazirgiannis + magdalini eirinaki	2005	Usage-based PageRank for Web personalization	web personalization + web pages + usage data + personalized recommendation + information filters + usage-based PageRank + Web structure + Web graph + Web personalization + personalized navigational graph synopsis + recommendation algorithm + link analysis + Internet + Web sites + internet + navigational pattern	AuthorProvided Keywords Not Found	"Recommendation algorithms aim at proposing ""next"" pages to a user based on her current visit and the past users' navigational patterns. In the vast majority of related algorithms, only the usage data are used to produce recommendations, whereas the structural properties of the Web graph are ignored. We claim that taking also into account the Web structure and using link analysis algorithms ameliorates the quality of recommendations. In this paper we present UPR, a novel personalization algorithm which combines usage data and link analysis techniques for ranking and recommending Web pages to the end user. Using the Web site's structure and its usage data we produce personalized navigational graph synopsis (prNG) to be used for applying UPR and produce personalized recommendations. Experimental results show that the accuracy of the recommendations is superior to pure usage-based approaches."
808133EA	International Conference on Data Mining	chunsheng chen + ricardo vilalta + christoph f eick + abraham bagherjeiran	2005	Adaptive clustering: obtaining better clusters using feedback and past experience	learning artificial intelligence + Q-learning + data analysis + adaptive clustering + k-nearest neighbor classifier + pattern clustering + distance function learning + data clustering + learning (artificial intelligence) + external feedback + instance-based learning	AuthorProvided Keywords Not Found	Adaptive clustering uses external feedback to improve cluster quality; past experience serves to speed up execution time. An adaptive clustering environment is proposed that uses Q-learning to learn the reward values of successive data clusterings. Adaptive clustering supports the reuse of clusterings by memorizing what worked well in the past. It has the capability of exploring multiple paths in parallel when searching for good clusters. In a case study, we apply adaptive clustering to instance-based learning relying on a distance function modification approach. A distance function adaptation scheme that uses external feedback is proposed and compared with other distance function learning approaches. Experimental results indicate that the use of adaptive clustering leads to significant improvements of instance-based learning techniques, such as k-nearest neighbor classifiers. Moreover, as a by-product a new instance-based learning technique is introduced that classifies examples by solely using cluster representatives; this technique shows high promise in our experimental evaluation.
7F3EA88D	International Conference on Data Mining	gang wang + zhihua zhang + frederick h lochovsky + hui zhang	2005	A Bernoulli relational model for nonlinear embedding	statistical distributions + stochastic neighbor embedding + high-dimensional space + stochastic embedding model + Bernoulli relational model + gaussian processes + Gaussian process latent variable model + nonlinear embedding + synthetic data + nonlinear dimensionality reduction + Gaussian processes + stochastic relational model + relational model + probabilistic distribution + gaussian process	AuthorProvided Keywords Not Found	The notion of relations is extremely important in mathematics. In this paper, we use relations to describe the embedding problem and propose a novel stochastic relational model for nonlinear embedding. Given some relation among points in a high-dimensional space, we start from preserving the same relation in a low embedded space and model the relation as probabilistic distributions over these two spaces, respectively. We illustrate that the stochastic neighbor embedding and the Gaussian process latent variable model can be derived from our relational model. Moreover we devise a new stochastic embedding model and refer to it as Bernoulli relational embedding (BRE). BRE's ability in nonlinear dimensionality reduction is illustrated on a set of synthetic data and collections of bitmaps of handwritten digits and face images.
7E68CBC4	International Conference on Data Mining	christos faloutsos + huiming qu + deepayan chakrabarti + jimeng sun	2005	Neighborhood formation and anomaly detection in bipartite graphs	random walk + neighborhood formation + graph theory + random walk method + anomaly detection + bipartite graph + graph partitioning	AuthorProvided Keywords Not Found	Many real applications can be modeled using bipartite graphs, such as users vs. files in a P2P system, traders vs. stocks in a financial trading system, conferences vs. authors in a scientific publication network, and so on. We introduce two operations on bipartite graphs: 1) identifying similar nodes (Neighborhood formation), and 2) finding abnormal nodes (Anomaly detection). And we propose algorithms to compute the neighborhood for each node using random walk with restarts and graph partitioning; we also propose algorithms to identify abnormal nodes, using neighborhood information. We evaluate the quality of neighborhoods based on semantics of the datasets, and we also measure the performance of the anomaly detection algorithm with manually injected anomalies. Both effectiveness and efficiency of the methods are confirmed by experiments on several real datasets.
7DA8B0DF	International Conference on Data Mining	benyu zhang + fengshan bai + zheng chen + leefeng chien + jun yan + wenyin liu + ning liu	2005	Text representation: from vector to tensor	text analysis + tensor space model + vectors + high-order singular value decomposition + vector space model + multifactor structures + multilinear algebraic high-order tensor + text representation + tensors + multilinear algebra + dimension reduction + singular value decomposition	AuthorProvided Keywords Not Found	In this paper, we propose a text representation model, Tensor Space Model (TSM), which models the text by multilinear algebraic high-order tensor instead of the traditional vector. Supported by techniques of multilinear algebra, TSM offers a potent mathematical framework for analyzing the multifactor structures. TSM is further supported by certain introduced particular operations and presented tools, such as the High-Order Singular Value Decomposition (HOSVD) for dimension reduction and other applications. Experimental results on the 20 Newsgroups dataset show that TSM is constantly better than VSM for text classification.
7E61CBF7	International Conference on Data Mining	ricardo cartaxo m souza + gilberto camara + d m valeriano + marcelino pereira s silva + maria isabel s escada	2005	Mining patterns of change in remote sensing image databases	remote sensing image databases + information extraction + large image data sets + data mining + visual databases + remote sensing + change pattern mining + spatial information + large remote sensing image database + remote sensing data archives + image data mining	AuthorProvided Keywords Not Found	Remote sensing image databases are the fastest growing archives of spatial information. However, we still have a limited capacity for extracting information from large remote sensing image databases. There are currently very few techniques for image data mining and information extraction in large image data sets, and thus we are failing to exploit our large remote sensing data archives. This paper proposes a methodology to provide guidance for mining remote sensing image databases. The basic idea is to use domain concepts to build generic description of patterns in remote sensing images, and then use structural approaches to identify such patterns in images. We illustrate our proposal with a case study for detecting land use patterns in Amazonia from INPE's remote sensing image database.
7F9CF091	International Conference on Data Mining	wingho shum + kwongsak leung + manleung wong	2005	Learning functional dependency networks based on genetic programming	bayesian network + genetic programming + network model + a priori knowledge + functional dependency network + network complexity + functional dependency + user-defined function + genetic algorithms + belief networks + Bayesian network + expressive power	AuthorProvided Keywords Not Found	Bayesian Network (BN) is a powerful network model, which represents a set of variables in the domain and provides the probabilistic relationships among them. But BN can handle discrete values only; it cannot handle continuous, interval and ordinal ones, which must be converted to discrete values and the order information is lost. Thus, BN tends to have higher network complexity and lower understandability. In this paper, we present a novel dependency network which can handle discrete, continuous, interval and ordinal values through functions; it has lower network complexity and stronger expressive power; it can represent any kind of relationships; and it can incorporate a-priori knowledge though user-defined functions. We also propose a novel Genetic Programming (GP) to learn dependency networks. The novel GP does not use any knowledge-guided nor application-oriented operator, thus it is robust and easy to replicate. The experimental results demonstrate that the novel GP can successfully discover the target novel dependency networks, which have the highest accuracy and the lowest network complexity.
7E7BA0DF	International Conference on Data Mining	harry zhang + liangxiao jiang	2005	Learning instance greedily cloning naive Bayes for ranking	conditional independence + learning artificial intelligence + naive bayes + data mining + eager learning + lazy learning + classification algorithm + Bayes methods + machine learning + learning (artificial intelligence) + instance greedily cloning naive Bayes	AuthorProvided Keywords Not Found	Naive Bayes (simply NB) (Langley et al., 1992) has been widely used in machine learning and data mining as a simple and effective classification algorithm. Since its conditional independence assumption is rarely true, researchers have made a substantial amount of effort to improve naive Bayes. The related research work can be broadly divided into two approaches: eager learning and lazy learning, depending on when the major computation occurs. Different from eager approach, the key idea for extending naive Bayes from the lazy approach is to learn a naive Bayes for each testing example. In recent years, some lazy extensions of naive Bayes have been proposed. For example, SNNB, LWNB, and LBR. All are aiming at improving the classification accuracy of naive Bayes. In many real-world machine learning and data mining applications, however, an accurate ranking is more desirable than an accurate classification. Responding to this fact, we present a lazy learning algorithm called instance greedily cloning naive Bayes (simply IGCNB) in this paper. Our motivation is to improve naive Bayes' ranking performance measured by AUC (Bradley, 1997; Provost and Fawcett, 1997). We experimentally tested our algorithm, using the whole 36 UCI datasets recommended by Weka, and compared it to C4.4 (Provost and Domingos, 2003), NB (Langley et al., 1992), SNNB (Xie, 2002) and LWNB (Frank, 2003). The experimental results show that our algorithm outperforms all the other algorithms used to compare significantly in yielding accurate ranking.
7D7F8A42	International Conference on Data Mining	ada fu + eamonn keogh + jessica lin	2005	HOT SAX: efficiently finding the most unusual time series subsequence	clustering quality + summarization + data cleaning + data mining + time series discords + HOT SAX + time series + clustering + anomaly detection	eol>Time Series Data Mining + Anomaly Detection + Clustering	In this work, we introduce the new problem of finding time series discords. Time series discords are subsequences of a longer time series that are maximally different to all the rest of the time series subsequences. They thus capture the sense of the most unusual subsequence within a time series. Time series discords have many uses for data mining, including improving the quality of clustering, data cleaning, summarization, and anomaly detection. Discords are particularly attractive as anomaly detectors because they only require one intuitive parameter (the length of the subsequence) unlike most anomaly detection algorithms that typically require many parameters. We evaluate our work with a comprehensive set of experiments. In particular, we demonstrate the utility of discords with objective experiments on domains as diverse as Space Shuttle telemetry monitoring, medicine, surveillance, and industry, and we demonstrate the effectiveness of our discord discovery algorithm with more than one million experiments, on 82 different datasets from diverse domains.
7E008AB6	International Conference on Data Mining	hidenao abe + shusaku tsumoto + miho ohsaki + takahira yamaguchi	2005	A rule evaluation support method with learning models based on objective rule evaluation indexes	adaptive rule evaluation support + learning algorithm + learning artificial intelligence + objective rule evaluation index + data mining + rule evaluation model + indexation + learning model + learning (artificial intelligence)	AuthorProvided Keywords Not Found	In this paper, we present a novel rule evaluation support method for post-processing of mined results with rule evaluation models based on objective indexes. Post-processing of mined results is one of the key issues to make a data mining process successfully. However, it is difficult for human experts to evaluate many thousands of rules from a large dataset with noises completely. To reduce the costs of rule evaluation procedures, we have developed the rule evaluation support method with rule evaluation models, which are obtained with objective rule evaluation indexes and evaluations of a human expert for each rule. Since the method is needed more accurate rule evaluation models, we have compared learning algorithms to construct rule evaluation models with the actual meningitis data mining result and actual rule sets from UCI datasets. Then we show the availability of our adaptive rule evaluation support method.
7DB1BF97	International Conference on Data Mining	hidetomo nabeshima + yo takano + koji iwanuma + ryuichi ishihara	2005	Extracting frequent subsequences from a single long data sequence a novel anti-monotonic measure and a simple on-line algorithm	total frequency measure + antimonotonic measure + data mining + online algorithm + frequent subsequence extraction	AuthorProvided Keywords Not Found	In this paper, we study frequent subsequence extraction from a single very-long data-sequence. First we propose a novel frequency measure, called the total frequency, for counting multiple occurrences of a sequential pattern in a single data sequence. The total frequency is anti-monotonic, and makes it possible to count up pattern occurrences without duplication. Moreover the total frequency has a good property for implementation based on the dynamic programming strategy. Second we give a simple on-line algorithm for a specialized subsequence extraction problem, i.e., a problem with the infinite window-length. This specialized problem is considered to be a relaxation of the general-case problem, thus this fast on-line algorithm is important from the view of practical applications.
7ECDF1B0	International Conference on Data Mining	philip s yu + zhongfei zhang + bo long	2005	Combining multiple clusterings by soft correspondence	correspondence problem + consensus clustering + pattern clustering + multiplicative updating rule + data mining + multiple clusterings + correspondence matrices + soft correspondence	AuthorProvided Keywords Not Found	Combining multiple clusterings arises in various important data mining scenarios. However, finding a consensus clustering from multiple clusterings is a challenging task because there is no explicit correspondence between the classes from different clusterings. We present a new framework based on soft correspondence to directly address the correspondence problem in combining multiple clusterings. Under this framework, we propose a novel algorithm that iteratively computes the consensus clustering and correspondence matrices using multiplicative updating rules. This algorithm provides a final consensus clustering as well as correspondence matrices that gives intuitive interpretation of the relations between the consensus clustering and each clustering from clustering ensembles. Extensive experimental evaluations also demonstrate the effectiveness and potential of this framework as well as the algorithm for discovering a consensus clustering from multiple clusterings.
5E4A1487	International Conference on Data Mining	loick lhote + francois rioult + arnaud soulet	2005	Average number of frequent (closed) patterns in Bernoulli and Markovian databases	association rule + frequent patterns + data mining + upper bound + lower bound + fixed frequency threshold + association rules discovery + probabilistic model + Markovian model + frequent enumeration + probabilistic models + closed patterns + average analysis + proportional frequency threshold + Bernoulli model	AuthorProvided Keywords Not Found	In data mining, enumerate the frequent or the closed patterns is often the first difficult task leading to the association rules discovery. The number of these patterns represents a great interest. The lower bound is known to be constant whereas the upper bound is exponential, but both situations correspond to pathological cases. For the first time, we give an average analysis of the number of frequent or closed patterns. Average analysis is often closer to real situations and gives more information about the role of the parameters. In this paper, two probabilistic models are studied: a Bernoulli and a Markovian. In both models and for large databases, we prove that the number of frequent patterns, for a fixed frequency threshold, is exponential in the number of items and polynomial in the number of transactions. On the other hand, for a proportional frequency threshold, the number of frequent patterns is polynomial in the number of items and does not involve the number of transactions. Finally, we prove in the Bernoulli model that the number of closed patterns, for a proportional frequency threshold, is polynomial in the number of items.
80718F58	International Conference on Data Mining	wei fan + k drammey + philip s yu + e greengrass + james a mccloskey	2005	Effective estimation of posterior probabilities: explaining the accuracy of randomized decision tree approaches	estimation theory + probability + posterior probability estimation + randomization method + randomized decision tree + posterior probability + loss function + decision tree + decision tree construction + decision trees + probability distribution + gain function + loss reduction	AuthorProvided Keywords Not Found	There has been increasing number of independently proposed randomization methods in different stages of decision tree construction to build multiple trees. Randomized decision tree methods have been reported to be significantly more accurate than widely-accepted single decision trees, although the training procedure of some methods incorporates a surprisingly random factor and therefore opposes the generally accepted idea of employing gain functions to choose optimum features at each node and compute a single tree that fits the data. One important question that is not well understood yet is the reason behind the high accuracy. We provide an insight based on posterior probability estimations. We first establish the relationship between effective posterior probability estimation and effective loss reduction. We argue that randomized decision tree methods effectively approximate the true probability distribution using the decision tree hypothesis space. We conduct experiments using both synthetic and real-world datasets under both 0-1 and cost-sensitive loss functions.
7CF07E4E	International Conference on Data Mining	muhammad subianto + arno siebes + ad feelders	2005	Instability of classifiers on categorical data	pattern classification + data mining + categorical data + classifier instability	AuthorProvided Keywords Not Found	In this paper we study the local behaviour of arbitrary classifiers using the instability of that classifier in a data point. Moreover, we introduce two algorithms. The first to find highly unstable points, the second to find islands of stability.
59B67264	International Conference on Data Mining	hanspeter kriegel + martin pfeifle	2005	Hierarchical density-based clustering of uncertain data	uncertain data clustering + distance function + pattern clustering + probability + fuzzy set theory + data mining + fuzzy object similarity + single-valued distance function + distance probability function + hierarchical density-based clustering	AuthorProvided Keywords Not Found	The hierarchical density-based clustering algorithm OPTICS has proven to help the user to get an overview over large data sets. When using OPTICS for analyzing uncertain data which naturally occur in many emerging application areas, e.g. location based services, or sensor databases, the similarity between uncertain objects has to be expressed by one numerical distance value. Based on such single-valued distance functions OPTICS, like other standard data mining algorithms, can work without any changes. In this paper, we propose to express the similarity between two fuzzy objects by distance probability functions which assign a probability value to each possible distance value. Contrary to the traditional approach, we do not extract aggregated values from the fuzzy distance functions but enhance OPTICS so that it can exploit the full information provided by these functions. The resulting algorithm FOPTICS helps the user to get an overview over a large set of fuzzy objects.
7F5A24E9	International Conference on Data Mining	shashi shekhar + c n murray + anne e pusey + jaideep srivastava + sandeep u mane	2005	Spatial clustering of chimpanzee locations for neighborhood identification	clustering behavior evaluation + col + social structure + neighborhood identification + temporal information + data mining + spatial clustering + social interactions + chimpanzee locations + Pan troglodytes + behavioral ecologists + marked point patterns + data collection + ecology + point pattern analysis + pattern clustering + chimpanzees social structure + spatial point pattern analysis + female chimpanzees clustering + social interaction + Ripley's K-function + zoology + spatial locations	AuthorProvided Keywords Not Found	"Since 1960, the chimpanzees (Pan troglodytes) of Gombe National Park, Tanzania, have been studied by behavioral ecologists, including Jane Goodall. Data have been collected for more than 40 years and are being analyzed by researchers in order to increase our understanding of the social structure of chimpanzees. In this paper, we consider the following question of interest to behavioral ecologists - ""Does clustering exist among female chimpanzees in terms of their spatial locations ?"" The analysis of this question will help behavioral ecologists to learn about the space use and the social interactions between female chimpanzees. The data collected for this analysis are marked spatial point patterns over the park. Current spatial clustering methods lack the ability to handle such marked point patterns directly. This paper presents a novel application of spatial point pattern analysis and data mining techniques to the ecological problem of clustering female chimpanzees. We found that Ripley's K-function provides a powerful statistical tool for evaluating clustering behavior among spatial point patterns. We then proposed two clustering approaches for marked point patterns using the K-function. Experimental results using the proposed clustering methods provide significant insight into the dynamics of female chimpanzee space use and into the overall social stucture of the species. In addition, the proposed methods can be extended to also include temporal information."
7EEA4907	International Conference on Data Mining	ahhwee tan + xing jiang	2005	Mining ontological knowledge from domain-specific text documents	domain-specific text document + text analysis + complex structure + concept relation concept tuple + data mining + full text parsing + relation extraction + learning systems + ontological knowledge mining + concept extraction + grammars + statistical method + knowledge extraction + ontologies (artificial intelligence) + text mining + ontology learning + statistical analysis + lexico-syntactic method	AuthorProvided Keywords Not Found	Traditional text mining systems employ shallow parsing techniques and focus on concept extraction and taxonomic relation extraction. This paper presents a novel system called CRCTOL for mining rich semantic knowledge in the form of ontology from domain-specific text documents. By using a full text parsing technique and incorporating both statistical and lexico-syntactic methods, the knowledge extracted by our system is more concise and contains a richer semantics compared with alternative systems. We conduct a case study wherein CRCTOL extracts ontological knowledge, specifically key concepts and semantic relations, from a terrorism domain text collection. Quantitative evaluation, by comparing with a state-of-the-art ontology learning system known as text-to-onto, has shown that CRCTOL produces much better precision and recall for both concept and relation extraction, especially from sentences with complex structures.
7FAC9A19	International Conference on Data Mining	carlotta domeniconi + michalis vazirgiannis + nitin kumar + maria halkidi + dimitrios gunopulos	2005	A framework for semi-supervised learning based on subjective and objective clustering criteria	semi supervised learning + learning artificial intelligence + pattern clustering + semisupervised learning + weighted Euclidean subspace + learning (artificial intelligence) + objective clustering criteria + subjective clustering criteria	AuthorProvided Keywords Not Found	In this paper, we propose a semi-supervised framework for learning a weighted Euclidean subspace, where the best clustering can be achieved. Our approach capitalizes on user-constraints and the quality of intermediate clustering results in terms of its structural properties. It uses the clustering algorithm and the validity measure as parameters.
7F2B68BE	International Conference on Data Mining	nobert riedel + jing peng + peng zhang	2005	Discriminant analysis: a unified approach	data reduction + learning artificial intelligence + small sample size problem + data mining + statistical learning theory + statistical analysis + learning (artificial intelligence) + linear discriminant analysis + machine learning + dimension reduction	AuthorProvided Keywords Not Found	Linear discriminant analysis (LDA) as a dimension reduction method is widely used in data mining and machine learning. It however suffers from the small sample size (SSS) problem when data dimensionality is greater than the sample size. Many modified methods have been proposed to address some aspect of this difficulty from a particular viewpoint. A comprehensive framework that provides a complete solution to the SSS problem is still missing. In this paper, we provide a unified approach to LDA, and investigate the SSS problem in the framework of statistical learning theory. In such a unified approach, our analysis results in a deeper understanding of LDA. We demonstrate that LDA (and its nonlinear extension) belongs to the same framework where powerful classifiers such as support vector machines (SVMs) are formulated. In addition, this approach allows us to establish an error bound for LDA. Finally our experiments validate our theoretical analysis results.
7ED5CDED	International Conference on Data Mining	oksana yakhnenko + vasant honavar + adrian silvescu	2005	Discriminatively trained Markov model for sequence classification	pattern classification + amino acid + intrusion detection + discriminative training + text classification + machine learning + likelihood function + maximum likelihood estimation + biological sequence classification + gradient based update equation + speech recognition + support vector machine + protein function prediction + markov processes + cost effectiveness + markov model + directed Markov model + Markov processes + maximum likelihood estimate + conditional likelihood function + discriminatively trained Markov model	AuthorProvided Keywords Not Found	In this paper, we propose a discriminative counterpart of the directed Markov Models of order k - 1, or MM(k - 1) for sequence classification. MM(k - 1) models capture dependencies among neighboring elements of a sequence. The parameters of the classifiers are initialized to based on the maximum likelihood estimates for their generative counterparts. We derive gradient based update equations for the parameters of the sequence classifiers in order to maximize the conditional likelihood function. Results of our experiments with data sets drawn from biological sequence classification (specifically protein function and subcellular localization) and text classification applications show that the discriminatively trained sequence classifiers outperform their generative counterparts, confirming the benefits of discriminative training when the primary objective is classification. Our experiments also show that the discriminatively trained MM(k - 1) sequence classifiers are competitive with the computationally much more expensive Support Vector Machines trained using k-gram representations of sequences.
80278609	International Conference on Data Mining	manu aery + sharma chakravarthy	2005	eMailSift: eMail classification based on structure and content	eMail structure + structure extraction + pattern classification + inexact graph match + electronic mail + eMail classification + eMail content + eMailSift	AuthorProvided Keywords Not Found	In this paper we propose a novel approach that uses structure as well as the content of emails in a folder for email classification. Our approach is based on the premise that representative - common and recurring -structures/patterns can be extracted from a pre-classified email folder and the same can be used effectively for classifying incoming emails. A number of factors that influence representative structure extraction and the classification are analyzed conceptually and validated experimentally. In our approach, the notion of inexact graph match is leveraged for deriving structures that provide coverage for characterizing folder contents. Extensive experimentation validate the selection of parameters and the effectiveness of our approach for email classification.
7DFD3B2D	International Conference on Data Mining	jin huang + charles x ling	2005	Partial ensemble classifiers selection for better ranking	pattern classification + data mining + PECS algorithm + ensemble ranking performance + knowledge discovery + partial ensemble classifiers selection	AuthorProvided Keywords Not Found	Ranking is an important task in data mining and knowledge discovery. We propose a novel approach called PECS algorithm to improve the overall ranking performance of a given ensemble. We formally analyse the sufficient and necessary condition under which PECS algorithm can effectively improve ensemble ranking performance. The experiments with real-world data sets show that this new approach achieves significant improvements in ranking over the original bagging and Adaboost ensembles.
7F818FB8	International Conference on Data Mining	panagiotis papapetrou + stan sclaroff + george kollios + dimitrios gunopulos	2005	Discovering frequent arrangements of temporal intervals	breadth first and depth first search + temporal intervals + temporal databases + temporal pattern mining + data mining + frequent arrangement discovery + depth first search	AuthorProvided Keywords Not Found	In this paper we study a new problem in temporal pattern mining: discovering frequent arrangements of temporal intervals. We assume that the database consists of sequences of events, where an event occurs during a time-interval. The goal is to mine arrangements of event intervals that appear frequently in the database. There are many applications where these type of patterns can be useful, including data network, scientific, and financial applications. Efficient methods to find frequent arrangements of temporal intervals using both breadth first and depth first search techniques are described. The performance of the proposed algorithms is evaluated and compared with other approaches on real datasets (American sign language streams and network data) and large synthetic datasets.
7D20F6B8	International Conference on Data Mining	aristides gionis + panayiotis tsaparas + risto a vaisanen + christos faloutsos + heikki mannila + spiros papadimitriou	2005	Parameter-free spatial data mining using MDL	spatial data + parameter-free spatial data mining + data mining + minimum description length principle + visual databases + spatial correlation + minimum description length + feature cooccurrence patterns + large datasets	AuthorProvided Keywords Not Found	"Consider spatial data consisting of a set of binary features taking values over a collection of spatial extents (grid cells). We propose a method that simultaneously finds spatial correlation and feature co-occurrence patterns, without any parameters. In particular, we employ the minimum description length (MDL) principle coupled with a natural way of compressing regions. This defines what ""good"" means: a feature co-occurrence pattern is good, if it helps us better compress the set of locations for these features. Conversely, a spatial correlation is good, if it helps us better compress the set of features in the corresponding region. Our approach is scalable for large datasets (both number of locations and of features). We evaluate our method on both real and synthetic datasets."
808C6AA6	International Conference on Data Mining	ambuj k singh + hyungjeong yang + mark r verardo + christos faloutsos + jiayu pan + arnab bhattacharya + vebjorn ljosa	2005	ViVo: visual vocabulary construction for mining biomedical images	image collection + col + text document images + data mining + document image processing + visual vocabulary construction + biomedical imaging + medical information systems + classification accuracy + color histogram + medical image processing + biomedical image mining	AuthorProvided Keywords Not Found	"Given a large collection of medical images of several conditions and treatments, how can we succinctly describe the characteristics of each setting? For example, given a large collection of retinal images from several different experimental conditions (normal, detached, reattached, etc.), how can data mining help biologists focus on important regions in the images or on the differences between different experimental conditions? If the images were text documents, we could find the main terms and concepts for each condition by existing IR methods (e.g., tf/idf and LSI). We propose something analogous, but for the much more challenging case of an image collection: We propose to automatically develop a visual vocabulary by breaking images into n × n tiles and deriving key tiles (""ViVos"") for each image and condition. We experiment with numerous domain-independent ways of extracting features from tiles (color histograms, textures, etc.), and several ways of choosing characteristic tiles (PCA, ICA). We perform experiments on two disparate biomedical datasets. The quantitative measure of success is classification accuracy: Our ""ViVos"" achieve high classification accuracy (up to 83 %for a nine-class problem on feline retinal images). More importantly, qualitatively, our ""ViVos"" do an excellent job as ""visual vocabulary terms"": they have biological meaning, as corroborated by domain experts; they help spot characteristic regions of images, exactly like text vocabulary terms do for documents; and they highlight the differences between pairs of images."
7EE72934	International Conference on Data Mining	srinivasan parthasarathy + keith marsolo	2005	Alternate representation of distance matrices for characterization of protein structure	computational biology + Zernike polynomials + discrete wavelet transformation + wavelet-based approach + approximation coefficients + wavelet transforms + Zernike model + Zernike coefficients + wavelet decomposition + 2D matrix + protein structure + data reduction + multistage classification + 1D signal + biology computing + proteins + zernike polynomials + distance matrices + pattern classification + structure-based feature vectors + discrete wavelet transform + wavelet representation + feature vector + matrix algebra + automated protein structure classification	AuthorProvided Keywords Not Found	The most suitable method for the automated classification of protein structures remains an open problem in computational biology. In order to classify a protein structure with any accuracy, an effective representation must be chosen. Here we present two methods of representing protein structure. One involves representing the distances between the Ca atoms of a protein as a two-dimensional matrix and creating a model of the resulting surface with Zernike polynomials. The second uses a wavelet-based approach. We convert the distances between a protein's Ca atoms into a one-dimensional signal which is then decomposed using a discrete wavelet transformation. Using the Zernike coefficients and the approximation coefficients of the wavelet decomposition as feature vectors, we test the effectiveness of our representation with two different classifiers on a dataset of more than 600 proteins taken from the 27 most-populated SCOP folds. We find that the wavelet decomposition greatly outperforms the Zernike model. With the wavelet representation, we achieve an accuracy of approximately 56%, roughly 12% higher than results reported on a similar, but less-challenging dataset. In addition, we can couple our structure-based feature vectors with several sequence-based properties to increase accuracy another 5-7%. Finally, we use a multi-stage classification strategy on the combined features to increase performance to 78%, an improvement in accuracy of more than 15-20% and 34% over the highest reported sequence-based and structure-based classification results, respectively.
81560C49	International Conference on Data Mining	e lozano + e acufia	2005	Parallel algorithms for distance-based and density-based outliers	parallel algorithms + data analysis + parallel algorithm + network intrusion + machine learning + outlier detection + nested loops + data cleaning + data parallelism + distance-based outliers + density-based local outliers + fraud detection + pruning rule	AuthorProvided Keywords Not Found	An outlier is an observation that deviates so much from other observations as to arouse suspicion that it was generated by a different mechanism. Outlier detection has many applications, such as data cleaning, fraud detection and network intrusion. The existence of outliers can indicate individuals or groups that exhibit a behavior that is very different from most of the individuals of the dataset. In this paper we design two parallel algorithms, the first one is for finding out distance-based outliers based on nested loops along with randomization and the use of a pruning rule. The second parallel algorithm is for detecting density-based local outliers. In both cases data parallelism is used. We show that both algorithms reach near linear speedup. Our algorithms are tested on four real-world datasets coming from the Machine Learning Database Repository at the UCI.
7CEA8338	International Conference on Data Mining	tilmann bruckhaus + nazim h madhavji + shengli sheng + charles x ling	2005	Predicting software escalations with maximum ROI	defect report data + enterprise software + escalation prediction + cost-sensitive learning + return on investment + data mining + DP management + software products defects + dataset mining	AuthorProvided Keywords Not Found	Enterprise software vendors often have to release software products before all reported defects are corrected, and a small number of these reported defects will be escalated by customers whose businesses are seriously impacted. Escalated defects must be quickly resolved at a high cost by the software vendors. The total costs can be even greater, including loss of reputation, satisfaction, loyalty, and repeat revenue. In this paper, we develop an Escalation Prediction (EP) system to mine historic defect report data and predict the escalation risk of current defect reports for maximum ROI (Return On Investment). More specifically, we first describe a simple and general framework to convert the maximum ROI problem to cost-sensitive learning. We then apply and compare several best-known cost-sensitive learning approaches for EP. The EP system has produced promising results, and has been deployed in the product group of an enterprise software vendor. Conclusions drawn from this study also provide guidelines for mining imbalanced datasets and cost-sensitive learning.
8142B15C	International Conference on Data Mining	michael steinbach + vipin kumar	2005	Generalizing the Notion of Confidence	transaction data + data mining + association rule + conditional probability + rule based + association analysis + confidence level	confidence + support + association rules + error-tolerant itemsets + data mining	"
In this paper, we explore extending association analysis to non-traditional types of patterns and non-binary data by generalizing the notion of confidence. We begin by describing a general framework that measures the strength of the connection between two association patterns by the extent to which the strength of one association pattern provides information about the strength of another. Although this framework can serve as the basis for designing or analyzing measures of association, the focus in this paper is to use the framework as the basis for extending the traditional concept of confidence to Error-Tolerant Itemsets (ETIs) and continuous data. To that end, we provide two examples. First, we (1) describe an approach to defining confidence for ETIs that preserves the interpretation of confidence as an estimate of a conditional probability, and (2) show how association rules based on ETIs can have better coverage (at an equivalent confidence level) than rules based on traditional itemsets. Next, we derive a confidence measure for continuous data that agrees with the standard confidence measure when applied to binary transaction data. Further analysis of this result exposes some of the important issues involved in constructing a confidence measure for continuous data.
"
8138EAEC	International Conference on Data Mining	ning kang + daniel barbara + carlotta domeniconi	2005	Categorization and keyword identification of unlabeled documents	label assignment + unlabeled document categorization + text analysis + data mining + global unsupervised feature selection + unsolicited e-mail + information filtering + classification + frequent itemset mining + adaptive clustering + pattern clustering + feature extraction + spam email filtering + text mining + word relevance + general classification dataset + algorithm design + keyword identification	AuthorProvided Keywords Not Found	In this paper, we first propose a global unsupervised feature selection approach for text, based on frequent itemset mining. As a result, each document is represented as a set of words that co-occur frequently in the given corpus of documents. We then introduce a locally adaptive clustering algorithm, designed to estimate (local) word relevance and, simultaneously, to group the documents. We present experimental results to demonstrate the feasibility of our approach. Furthermore, the analysis of the weights credited to terms provides evidence that the identified keywords can guide the process of label assignment to clusters. We take into consideration both spam email filtering and general classification datasets. Our analysis of the distribution of weights in the two cases provides insights on how the spam problem distinguishes from the general classification case.
80992BB8	International Conference on Data Mining	nikos mamoulis + david w cheung + huiping cao	2005	Mining frequent spatio-temporal sequential patterns	frequent spatiotemporal sequential pattern + sequential pattern discovery + transaction data + spatiotemporal series + tree structure + pattern identification + data mining + sequential pattern mining + tree data structures + substring tree structure	AuthorProvided Keywords Not Found	Many applications track the movement of mobile objects, which can be represented as sequences of timestamped locations. Given such a spatiotemporal series, we study the problem of discovering sequential patterns, which are routes frequently followed by the object. Sequential pattern mining algorithms for transaction data are not directly applicable for this setting. The challenges to address are: (i) the fuzziness of locations in patterns, and (ii) the identification of non-explicit pattern instances. In this paper, we define pattern elements as spatial regions around frequent line segments. Our method first transforms the original sequence into a list of sequence segments, and detects frequent regions in a heuristic way. Then, we propose algorithms to find patterns by employing a newly proposed substring tree structure and improving a priori technique. A performance evaluation demonstrates the effectiveness and efficiency of our approach.
7CF58F94	International Conference on Data Mining	melanie hilario + julien prados + alexandros kalousis	2005	Stability of feature selection algorithms	stability profile + pattern classification + learning artificial intelligence + learning algorithm stability + feature selection algorithm + stability measure + learning (artificial intelligence) + feature selection	AuthorProvided Keywords Not Found	With the proliferation of extremely high-dimensional data, feature selection algorithms have become indispensable components of the learning process. Strangely, despite extensive work on the stability of learning algorithms, the stability of feature selection algorithms has been relatively neglected. This study is an attempt to fill that gap by quantifying the sensitivity of feature selection algorithms to variations in the training set. We assess the stability of feature selection algorithms based on the stability of the feature preferences that they express in the form of weights-scores, ranks, or a selected feature subset. We examine a number of measures to quantify the stability of feature preferences and propose an empirical way to estimate them. We perform a series of experiments with several feature selection algorithms on a set of proteomics datasets. The experiments allow us to explore the merits of each stability measure and create stability profiles of the feature selection algorithms. Finally we show how stability profiles can support the choice of a feature selection algorithm.
5FE28C6D	International Conference on Data Mining	jonathan stoeckel + glenn fung	2005	SVM feature selection for classification of SPECT images of Alzheimer's disease using spatial information	image classification + feature extraction + spatial information + linear program + support vector machines + support vector machine + linear programming + feature selection		"""Alzheimers disease is the most frequent type of dementia for elderly patients. Due to aging populations the occurrence of this disease will increase in the next years. Early diagnosis is crucial to be able to develop more powerful treatments. Brain perfusion changes can be a marker for Alzheimers disease. In this article we study the use of SPECT perfusion imaging for the diagnosis of Alzheimers disease differentiating between images from healthy subjects and images from Alzheimers disease patients. Our classification approach is based on a linear programming formulation similar to the 1-norm support vector machines. In contrast with other linear hyperplane-based methods that perform simultaneous feature selection and classification, our proposed formulation incorporates proximity information about the features and generates a classifier that does not just select the most relevant voxels but the most relevant """"areas"""" for classification resulting in more robust classifiers that are better suitable for interpretation. This approach is compared with the classical Fisher linear discriminant (FLD) classifier as well as with statistical parametric mapping (SPM). We tested our method on data from four European institutions. Our method achieved sensitivity of 84.4% at 90.9% specificity, this is considerable better the human experts. Our method also outperformed the FLD and SPM techniques. We conclude that our approach has the potential to be a useful help for clinicians. © 2005 IEEE."""
7E96C2C0	International Conference on Data Mining	f de march + j m petit + frederic flouvat	2005	A thorough experimental study of datasets for frequent itemsets	frequent item set + frequent free item set + frequent patterns + data mining + frequent essential item set + frequent closed item set	AuthorProvided Keywords Not Found	The discovery of frequent patterns is a famous problem in data mining. While plenty of algorithms have been proposed during the last decade, only a few contributions have tried to understand the influence of datasets on the algorithms behavior. Being able to explain why certain algorithms are likely to perform very well or very poorly on some datasets is still an open question. In this setting, we describe a thorough experimental study of datasets with respect to frequent item sets. We study the distribution of frequent item sets with respect to item sets size together with the distribution of three concise representations: frequent closed, frequent free and frequent essential item sets. For each of them, we also study the distribution of their positive and negative borders whenever possible. From this analysis, we exhibit a new characterization of datasets and some invariants allowing to better predict the behavior of well known algorithms. The main perspective of this work is to devise adaptive algorithms with respect to dataset characteristics.
80C2BB8C	International Conference on Data Mining	xindong wu + gong chen + xingquan zhu	2005	Sequential pattern mining in multiple streams	transaction processing + PrefixSpan algorithm + pattern classification + multiple data streams + data distribution + data mining + MILE algorithm + pattern discovery + sequential pattern mining + transaction database mining	AuthorProvided Keywords Not Found	In this paper, we deal with mining sequential patterns in multiple data streams. Building on a state-of-the-art sequential pattern mining algorithm PrefixSpan for mining transaction databases, we propose MILE, an efficient algorithm to facilitate the mining process. MILE recursively utilizes the knowledge of existing patterns to avoid redundant data scanning, and can therefore effectively speed up the new patterns' discovery process. Another unique feature of MILE is that it can incorporate some prior knowledge of the data distribution in data streams into the mining process to further improve the performance. Extensive empirical results show that MILE is significantly faster than PrefixSpan. As MILE consumes more memory than PrefixSpan, we also present a solution to balance the memory usage and time efficiency in memory constrained environments.
7EB358B1	International Conference on Data Mining	shantanu godbole + sunita sarawagi + ganesh ramakrishnan	2005	Text classification with evolving label-sets	text analysis + class-detector module + document selection + text classification + classification + evolving label-sets + generative algorithm	AuthorProvided Keywords Not Found	We introduce the evolving label-set problem encountered in building real-world text classification systems. This problem arises when a text classification system trained on a label-set encounters documents of unseen classes at deployment time. We design a class-detector module that monitors unlabeled data, detects new classes, and suggests them to the administrator for inclusion in the label-set. We propose abstractions that group together tokens under human understandable concepts and provide a mechanism of assigning importance to unseen terms. We present generative algorithms leveraging the notion of support of documents in a model for (1) selecting documents of proposed new classes, and (2) automatically triggering detection of new classes. Experiments on three real world taxonomies show that our methods select new class documents with high precision, and trigger emergence of new classes with low false-positive and false-negative rates.
8127B481	International Conference on Data Mining	alan s abrahams + a b becker + daniel fleder + ian c macmillan	2005	Handling generalized cost functions in the partitioning optimization problem through sequential binary programming	mathematical programming + decision trees + cost function + optimization problem + decision tree		This paper proposes a framework for cost-sensitive classification under a generalized cost function. By combining decision trees with sequential binary programming, we can handle unequal misclassification costs, constrained classification, and complex objective functions that other methods cannot. Our approach has two main contributions. First, it provides a new method for cost-sensitive classification that outperforms a traditional, accuracy-based method and some current cost-sensitive approaches. Second, and more important, our approach can handle a generalized cost function, instead of the simpler misclassification cost matrix to which other approaches are limited. © 2005 IEEE.
5E072D5A	International Conference on Data Mining	jennifer neville + david jensen	2005	Leveraging relational autocorrelation with latent group models	latent group models + latent group structure + relational classification + relational databases + inference mechanisms + relational data + collective inference + learning artificial intelligence + relational autocorrelation + relational data sets + statistical dependence + learning (artificial intelligence) + latent group model + relational learning	AuthorProvided Keywords Not Found	The presence of autocorrelation provides a strong motivation for using relational learning and inference techniques. Autocorrelation is a statistical dependence between the values of the same variable on related entities and is a nearly ubiquitous characteristic of relational data sets. Recent research has explored the use of collective inference techniques to exploit this phenomenon. These techniques achieve significant performance gains by modeling observed correlations among class labels of related instances, but the models fail to capture a frequent cause of autocorrelation - the presence of underlying groups that influence the attributes on a set of entities. We propose a latent group model (LGM) for relational data, which discovers and exploits the hidden structures responsible for the observed autocorrelation among class labels. Modeling the latent group structure improves model performance, increases inference efficiency, and enhances our understanding of the datasets. We evaluate performance on three relational classification tasks and show that LGM outperforms models that ignore latent group structure, particularly when there is little information with which to seed inference.
59E09AF0	International Conference on Data Mining	vipin kumar + varun chandola	2005	Summarization - compressing data into an informative representation	transaction processing + data compression + optimization problem + information loss + data summarization + informative representation + data mining + intrusion detection + frequent item sets + optimisation + compaction gain + transaction data + association analysis + objective function	AuthorProvided Keywords Not Found	In this paper, we formulate the problem of summarization of a dataset of transactions with categorical attributes as an optimization problem involving two objective functions - compaction gain and information loss. We propose metrics to characterize the output of any summarization algorithm. We investigate two approaches to address this problem. The first approach is an adaptation of clustering and the second approach makes use of frequent item sets from the association analysis domain. We illustrate one application of summarization in the field of network data where we show how our technique can be effectively used to summarize network traffic into a compact but meaningful representation. Specifically, we evaluate our proposed algorithms on the 1998 DARPA Off-line Intrusion Detection Evaluation data and network data generated by SKAION Corp for the ARDA information assurance program.
8149CFE8	International Conference on Data Mining	william k cheung + xiaofeng zhang	2005	Visualizing global manifold based on distributed local data abstractions	hierarchical local data abstraction + abstraction aggregation + distributed data mining + data mining + data granularity + generative topographic mapping + distributed processing + global generative model + data privacy + distributed local data abstraction + global manifold visualization	AuthorProvided Keywords Not Found	Mining distributed data for global knowledge is getting more attention recently. The problem is especially challenging when data sharing is prohibited due to local constraints like limited bandwidth and data privacy. In this paper, we investigate how to derive the embedded manifold (as a 2-D map) for a horizontally partitioned data set, where data cannot be shared among the partitions directly. We propose a model-based approach which computes hierarchical local data abstractions, aggregates the abstractions, and finally learns a global generative model - generative topographic mapping (GTM) based on the aggregated data abstraction. We applied the proposed method to two benchmarking data sets and demonstrated that the accuracy of the derived manifold can effectively be controlled by adjusting the data granularity level of the adopted local abstraction.
80552E3C	International Conference on Data Mining	anthony k h tung + jiong yang + wei wang + feng pan	2005	Finding representative set from massive data	heuristic algorithm + entropy + massive data volume + greedy algorithms + very large databases + large database + relative entropy + information-theoretic measures + mutual information + information age + greedy algorithm + data explosion	AuthorProvided Keywords Not Found	In the information age, data is pervasive. In some applications, data explosion is a significant phenomenon. The massive data volume poses challenges to both human users and computers. In this project, we propose a new model for identifying representative set from a large database. A representative set is a special subset of the original dataset, which has three main characteristics: It is significantly smaller in size compared to the original dataset. It captures the most information from the original dataset compared to other subsets of the same size. It has low redundancy among the representatives it contains. We use information-theoretic measures such as mutual information and relative entropy to measure the representativeness of the representative set. We first design a greedy algorithm and then present a heuristic algorithm that delivers much better performance. We run experiments on two real datasets and evaluate the effectiveness of our representative set in terms of coverage and accuracy. The experiments show that our representative set attains expected characteristics and captures information more efficiently.
815FB344	International Conference on Data Mining	yousef saad + effrosini kokiopoulou	2005	Orthogonal neighborhood preserving projections	computational biology + locality preserving projection + intrinsic neighborhood geometry + graph theory + computational geometry + orthogonal neighborhood preserving projection + k-nearest neighbor graph + weighted data graph + global geometry + data topology + data reduction + locally linear embedding + linear transformation + k nearest neighbor + linear dimensionality reduction + computer vision + data visualization + data samples	Linear dimensionality reduction + Locally Linear Embedding	Orthogonal neighborhood preserving projections (ONPP) is a linear dimensionality reduction technique which attempts to preserve both the intrinsic neighborhood geometry of the data samples and the global geometry. The proposed technique constructs a weighted data graph where the weights are constructed in a data-driven fashion, similarly to locally linear embedding (LLE). A major difference with the standard LLE where the mapping between the input and the reduced spaces is implicit, is that ONPP employs an explicit linear mapping between the two. As a result, and in contrast with LLE, handling new data samples becomes straightforward, as this amounts to a simple linear transformation. ONPP shares some of the properties of locality preserving projections (LPP). Both ONPP and LPP rely on a k-nearest neighbor graph in order to capture the data topology. However, our algorithm inherits the characteristics of LLE in preserving the structure of local neighborhoods, while LPP aims at preserving only locality without specifically aiming at preserving the geometric structure. This feature makes ONPP an effective method for data visualization. We provide ample experimental evidence to demonstrate the advantageous characteristics of ONPP, using well known synthetic test cases as well as real life data from computational biology and computer vision.
7DD0C563	International Conference on Data Mining	mohammad elhajj + osmar r zaiane + paul nalos	2005	Bifold constraint-based mining by simultaneous monotone and anti-monotone checking	interestingness measure + pattern filtering + data mining + antimonotone checking + bifold constraint-based mining + frequent item set mining + simultaneous monotone checking	Problem Statement	Mining for frequent item sets can generate an overwhelming number of patterns, often exceeding the size of the original transactional database. One way to deal with this issue is to set filters and interestingness measures. Others advocate the use of constraints to apply to the patterns, either on the form of the patterns or on descriptors of the items in the patterns. However, typically the filtering of patterns based on these constraints is done as a post-processing phase. Filtering the patterns post-mining adds a significant overhead, still suffers from the sheer size of the pattern set and loses the opportunity to exploit those constraints. In this paper we propose an approach that allows the efficient mining of frequent item sets patterns, while pushing simultaneously both monotone and anti-monotone constraints during and at different strategic stages of the mining process. Our implementation shows a significant improvement when considering the constraints early and a better performance over Dualminer which also considers both types of constraints.
59936AA8	International Conference on Data Mining	yi zhang + w n street	2005	Bagging with adaptive costs	support vector machines + indexing terms + data mining + linear support vector machine + adaptive cost + ensemble learning + learning artificial intelligence + ensemble method + stacking technique + learning (artificial intelligence) + arcing technique + bagging technique + computer experiment	Data mining + ensemble methods	Ensemble methods have proved to be highly effective in improving the performance of base learners under most circumstances. In this paper, we propose a new algorithm that combines the merits of some existing techniques, namely bagging, arcing and stacking. The basic structure of the algorithm resembles bagging, using a linear support vector machine (SVM). However, the misclassification cost of each training point is repeatedly adjusted according to its observed out-of-bag vote margin. In this way, the method gains the advantage of arcing - building the classifier the ensemble needs - without fixating on potentially noisy points. Computational experiments show that this algorithm performs consistently better than bagging and arcing.
7E787492	International Conference on Data Mining	shawn martin	2005	Training support vector machines using Gilbert's algorithm	support vector machine hyperplane + learning artificial intelligence + optimisation + constrained quadratic programming + support vector machines + support vector machine + optimal separating hyperplane + sequential minimal optimization + Gilbert algorithm + quadratic program + learning (artificial intelligence) + nearest point problem	Sequential Minimal Optimization,+Support Vector Machines,+Gilbert&#146;s Algorithm,+Nearest Point Algorithm	Support vector machines are classifiers designed around the computation of an optimal separating hyperplane. This hyperplane is typically obtained by solving a constrained quadratic programming problem, but may also be located by solving a nearest point problem. Gilbert's algorithm can be used to solve this nearest point problem but is unreasonably slow. In this paper we present a modified version of Gilbert's algorithm for the fast computation of the support vector machine hyperplane. We then compare our algorithm with the nearest point algorithm and with sequential minimal optimization.
802EBADC	International Conference on Data Mining	marek p michalowski + steven minton + claude nanjo + matthew michelson + craig a knoblock	2005	A heterogeneous field matching method for record linkage	learning artificial intelligence + pattern matching + record linkage + heterogeneous transformations + expert-like rules + heterogeneous field matching + machine learning + database management systems + learning (artificial intelligence)	AuthorProvided Keywords Not Found	"Record linkage is the process of determining that two records refer to the same entity. A key subprocess is evaluating how well the individual fields, or attributes, of the records match each other. One approach to matching fields is to use hand-written domain-specific rules. This ""expert systems"" approach may result in good performance for specific applications, but it is not scalable. This paper describes a new machine learning approach that creates expert-like rules for field matching. In our approach, the relationship between two field values is described by a set of heterogeneous transformations. Previous machine learning methods used simple models to evaluate the distance between two fields. However, our approach enables more sophisticated relationships to be modeled, which better capture the complex domain specific, common-sense phenomena that humans use to judge similarity. We compare our approach to methods that rely on simpler homogeneous models in several domains. By modeling more complex relationships we produce more accurate results."
7F5EC720	International Conference on Data Mining	mingsyan chen + hungleng chen + kunta chuang	2005	Labeling unclustered categorical data into clusters based on the important attribute values	maximal resemblance data labeling + sampling methods + categorical clustering + pattern clustering + unclustered categorical data + data mining + synthetic data + categorical data + sampling technique + database management systems + important attribute values + node importance representative	data labeling,+data mining,+categorical clustering	Sampling has been recognized as an important technique to improve the efficiency of clustering. However, with sampling applied, those points which are not sampled will not have their labels. Although there is a straightforward approach in the numerical domain, the problem of how to allocate those unlabeled data points into proper clusters remains as a challenging issue in the categorical domain. In this paper, a mechanism named MAximal Resemblance Data Labeling (abbreviated as MARDL) is proposed to allocate each unlabeled data point into the corresponding appropriate cluster based on the novel categorical clustering representative, namely, Node Importance Representative (abbreviated as NIR), which represents clusters by the importance of attribute values. MARDL has two advantages: (1) MARDL exhibits high execution efficiency; (2) after each unlabeled data is allocated into the proper cluster, MARDL preserves clustering characteristics, i.e., high intra-cluster similarity and low inter-cluster similarity. MARDL is empirically validated via real and synthetic data sets, and is shown to be not only more efficient than prior methods but also attaining results of better quality.
7EE03584	International Conference on Data Mining	inyee lee + mingsyan chen + janming ho	2005	CLUGO: a clustering algorithm for automated functional annotations based on gene ontology	ontology-based clustering algorithm + CLUGO + directed acyclic graph + term distribution + gene ontology + genetics + vocabulary + biology computing + pattern clustering + directed graphs + automated sequence functional annotation + structured vocabulary + ontologies (artificial intelligence)	AuthorProvided Keywords Not Found	We address the issue of providing highly informative and comprehensive annotations using information revealed by the structured vocabularies of gene ontology (GO). For a target, a set of candidate terms for inferring target properties is collected and form a unique distribution on the GO directed acyclic graph (DAG). We propose a novel ontology-based clustering algorithm $CLUGO, which considers GO hierarchical characteristics and the clustering of term distributions. By identifying significant groups in the distributions, CLUGO assigns comprehensive and correct annotations for a target. According to the results of experiments with automated sequence functional annotations, CLUGO represents a considerable improvement over our previous work - GOMIT in terms of recall while maintaining a similar level of precision. We conclude that given a GO candidate term distribution, CLUGO is an efficient ontology-based clustering algorithm for selecting comprehensive and correct annotations.
811A3E84	International Conference on Data Mining	nicolas cebron + michael r berthold	2005	Mining of Cell Assay Images Using Active Semi-Supervised-Clustering	learning vector quantization + high throughput screening		"
Classifying large datasets without any a-priori information poses a problem especially in the field of bioinformatics. In this work, we explore the problem of classifying hundreds of thousands of cell assay images obtained by a highthroughput screening camera. The goal is to label a few selected examples by hand and to automatically label the rest of the images afterwards. We deal with three major requirements: first, the model should be easy to understand, second it should offer the possibility to be adjusted by a domain expert, and third the interaction with the user should be kept to a minimum. We propose a new active clustering scheme, based on an initial Fuzzy c-means clustering and Learning Vector Quantization. This scheme can initially cluster large datasets unsupervised and then allows for adjustment of the classification by the user. Furthermore, we introduce a framework for the classification of cell assay images based on this technique. Early experiments show promising results.
"
80CDA8FF	International Conference on Data Mining	shashi shekhar + jin soung yoo + mete celik	2005	A join-less approach for co-location pattern mining: a summary of results	geographic space + colocation pattern mining + instance-lookup scheme + data mining + visual databases + spatial colocation patterns + spatial relationships + colocation pattern discovery + join-less approach + spatial relationship	AuthorProvided Keywords Not Found	Spatial co-location patterns represent the subsets of features whose instances are frequently located together in geographic space. Co-location pattern discovery presents challenges since the instances of spatial features are embedded in a continuous space and share a variety of spatial relationships. A large fraction of the computation time is devoted to identifying the instances of co-location patterns. We propose a novel join-less approach for co-location pattern mining, which materializes spatial neighbor relationships with no loss of co-location instances and reduces the computational cost of identifying the instances. The join-less co-location mining algorithm is efficient since it uses an instance-lookup scheme instead of an expensive spatial or instance join operation for identifying co-location instances. The experimental evaluations show the join-less algorithm performs more efficiently than a current join-based algorithm and is scalable in dense spatial datasets.
80DDF55B	International Conference on Data Mining	martin scholz	2005	On the Complexity of Rule Discovery from Distributed Data	association rule mining + working paper + algorithm design + supervised learning		"
This paper analyses the complexity of rule selection for supervised learning in distributed scenarios. The selection of rules is usually guided by a utility measure such as predictive accuracy or weighted relative accuracy. Other examples are support and con dence, known from association rule mining. A common strategy to tackle rule selection from distributed data is to evaluate rules locally on each dataset. While this works well for homogeneously distributed data, this work proves limitations of this strategy if distributions are allowed to deviate. To identify those subsets for which local and global distributions deviate may be regarded as an interesting learning task of its own, explicitly taking the locality of data into account. This task can be shown to be basically as complex as discovering the globally best rules from local data. Based on the theoretical results some guidelines for algorithm design are derived.
"
7FFCFED7	International Conference on Data Mining	hanspeter kriegel + karsten borgwardt	2005	Shortest-path kernels on graphs	shortest-path kernel + longest path + graph theory + data mining + graph data + kernel function + positive definite + polynomial time algorithm + shortest path + NP-hard problem + graph kernels + polynomial time + computational complexity	AuthorProvided Keywords Not Found	Data mining algorithms are facing the challenge to deal with an increasing number of complex objects. For graph data, a whole toolbox of data mining algorithms becomes available by defining a kernel function on instances of graphs. Graph kernels based on walks, subtrees and cycles in graphs have been proposed so far. As a general problem, these kernels are either computationally expensive or limited in their expressiveness. We try to overcome this problem by defining expressive graph kernels which are based on paths. As the computation of all paths and longest paths in a graph is NP-hard, we propose graph kernels based on shortest paths. These kernels are computable in polynomial time, retain expressivity and are still positive definite. In experiments on classification of graph models of proteins, our shortest-path kernels show significantly higher classification accuracy than walk-based kernels.
7E8C10F5	International Conference on Data Mining	thomas takeo osugi + deng kim + s m scott	2005	Balancing exploration and exploitation: a new algorithm for active machine learning	active machine learning + active learning + learning artificial intelligence + unlabeled examples + machine learning + learning (artificial intelligence) + decision boundary	AuthorProvided Keywords Not Found	Active machine learning algorithms are used when large numbers of unlabeled examples are available and getting labels for them is costly (e.g. requiring consulting a human expert). Many conventional active learning algorithms focus on refining the decision boundary, at the expense of exploring new regions that the current hypothesis misclassifies. We propose a new active learning algorithm that balances such exploration with refining of the decision boundary by dynamically adjusting the probability to explore at each step. Our experimental results demonstrate improved performance on data sets that require extensive exploration while remaining competitive on data sets that do not. Our algorithm also shows significant tolerance of noise.
80D160EB	International Conference on Data Mining	sandeep yaramakala + dimitris margaritis	2005	Speculative Markov blanket discovery for optimal feature selection	pattern classification + learning artificial intelligence + markov processes + learning problem + data mining + speculative Markov blanket discovery + Markov processes + classification tasks + optimal feature selection + learning (artificial intelligence) + Fast-IAMB + feature selection	AuthorProvided Keywords Not Found	In this paper we address the problem of learning the Markov blanket of a quantity from data in an efficient manner Markov blanket discovery can be used in the feature selection problem to find an optimal set of features for classification tasks, and is a frequently-used preprocessing phase in data mining, especially for high-dimensional domains. Our contribution is a novel algorithm for the induction of Markov blankets from data, called Fast-IAMB, that employs a heuristic to quickly recover the Markov blanket. Empirical results show that Fast-IAMB performs in many cases faster and more reliably than existing algorithms without adversely affecting the accuracy of the recovered Markov blankets.
7F06FB52	International Conference on Data Mining	qiang yang + benyu zhang + zheng chen + jun yan + ying chen + dong zhuang	2005	Efficient text classification by weighted proximal SVM	text analysis + support vector machines + high dimensional data + large-scale text data + text documents + unbalanced data + text classification + weight learning + weighted proximal support vector maching	AuthorProvided Keywords Not Found	In this paper, we present an algorithm that can classify large-scale text data with high classification quality and fast training speed. Our method is based on a novel extension of the proximal SVM mode (Fung and Mangasarian, 2001). Previous studies on proximal SVM have focused on classification for low dimensional data and did not consider the unbalanced data cases. Such methods will meet difficulties when classifying unbalanced and high dimensional data sets such as text documents. In this work, we extend the original proximal SVM by learning a weight for each training error. We show that the classification algorithm based on this model is capable of handling high dimensional and unbalanced data. In the experiments, we compare our method with the original proximal SVM (as a special case of our algorithm) and the standard SVM (such as SVM light) on the recently published RCV1-v2 dataset. The results show that our proposed method had comparable classification quality with the standard SVM. At the same time, both the time and memory consumption of our method are less than that of the standard SVM.
7DB6C8ED	International Conference on Data Mining	hanspeter kriegel + matthias renz + sebastian h r wurst + peer kroger	2005	A generic framework for efficient subspace clustering of high-dimensional data	high dimensional data + pattern clustering + subspace clustering + filter-refinement architecture + data mining + high-dimensional data + data dimensionality + subspace dimensionality	AuthorProvided Keywords Not Found	Subspace clustering has been investigated extensively since traditional clustering algorithms often fail to detect meaningful clusters in high-dimensional data spaces. Many recently proposed subspace clustering methods suffer from two severe problems: First, the algorithms typically scale exponentially with the data dimensionality and/or the subspace dimensionality of the clusters. Second, for performance reasons, many algorithms use a global density threshold for clustering, which is quite questionable since clusters in subspaces of significantly different dimensionality will most likely exhibit significantly varying densities. In this paper, we propose a generic framework to overcome these limitations. Our framework is based on an efficient filter-refinement architecture that scales at most quadratic w.r.t. the data dimensionality and the dimensionality of the subspace clusters. It can be applied to any clustering notions including notions that are based on a local density threshold. A broad experimental evaluation on synthetic and real-world data empirically shows that our method achieves a significant gain of runtime and quality in comparison to state-of-the-art subspace clustering algorithms.
815EDECB	International Conference on Data Mining	joydeep ghosh + kunal punera	2005	CLUMP: a scalable and robust framework for structure discovery	unsupervised discovery + text analysis + pattern clustering + CLustering Using Multiple Prototypes + data mining + model selection + scalable robust framework + structure discovery + CLUMP	AuthorProvided Keywords Not Found	We introduce a robust and efficient framework called CLUMP (CLustering Using Multiple Prototypes) for unsupervised discovery of structure in data. CLUMP relies on finding multiple prototypes that summarize the data. Clustering the prototypes enables our algorithm to scale up to extremely large and high-dimensional domains such as text data. Other desirable properties include robustness to noise and parameter choices. In this paper, we describe the approach in detail, characterize its performance on a variety of datasets, and compare it to some existing model selection approaches.
7DBD8052	International Conference on Data Mining	huan liu + lei tang	2005	Bias analysis in text classification for highly skewed data	information gain + text analysis + chi squared method + support vector machines + binormal separation + empirical study + bias analysis + text classification + highly skewed data + classifier bias + decision tree + support vector machine + class bias + high dimensional data + feature selection metrics + decision trees + metric bias + naive Bayes + Bayes methods + feature selection	AuthorProvided Keywords Not Found	Feature selection is often applied to high-dimensional data as a preprocessing step in text classification. When dealing with highly skewed data, we observe that typical feature selection metrics like information gain or chi-squared are biased toward selecting features for the minor class, and the metric of bi-normal separation can select features for both minor and major classes. In this work, we investigate how these feature selection metrics impact on the performance of frequently used classifiers such as decision trees, naive bayes, and support vector machines via bias analysis for highly skewed data. Three types of biases are metric bias, class bias, and classifier bias. Extensive experiments are designed to understand how these biases can be employed in concert and efficiently to achieve good classification performance. We report our findings and present recommended approaches to text classification based on bias analysis and the empirical study.
7F2CB5B6	International Conference on Data Mining	kiyoung yang + cyrus shahabi	2005	On the stationarity of multivariate time series for correlation-based data analysis	similarity search + data analysis + multivariate time series + time series + stationarity test + search problems + correlation-based data analysis	AuthorProvided Keywords Not Found	Multivariate time series (MTS) data sets are common in-various multimedia, medical and financial application domains. These applications perform several data-analysis operations on large number of MTS data sets such as similarity searches, feature-subset-selection, clustering and classifications. Correlation-based techniques, such as principal component analysis (PCA), have proven to improve the efficiency of many of the above-mentioned data-analysis operations on MTS, which implies that the correlation coefficients concisely represent the original MTS data. However, if the statistical properties (e.g., variance) of MTS data change over time dimension, i.e., MTS data is non-stationary, the correlation coefficients are not stable. In this paper, we propose to utilize the stationarity of the MTS data sets, in order to represent the original MTS data more stably, as well as concisely with the correlation coefficients. That is, before performing any correlation-based data analysis, we first executes the stationarity test to decide whether the MTS data is stationary or not, i.e., whether the correlation is stable or not. Subsequently, for a non-stationary MTS data set, we difference it to render the data set stationary. Even though our approach is general, to focus the discussion we describe our approach within the context of our previously proposed technique for MTS similarity search. In order to show the validity of our approach, we performed several experiments on four real-world data sets. The results show that the performance of our similarity search technique have significantly improved in terms of precision/recall.
00FC4F6E	International Conference on Data Mining	eamonn keogh + ada waichee fu + jessica lin	2005	HOT SAX: Finding the Most Unusual Time Series Subsequence: Algorithms and Applications	 + data mining + time series + anomaly detection		"
In this work, we introduce the new problem of finding time series discords. Time series discords are subsequences of a longer time series that are maximally different to all the rest of the time series subsequences. They thus capture the sense of the most unusual subsequence within a time series. Time series discords have many uses for data mining, including improving the quality of clustering, data cleaning, summarization, and anomaly detection. As we will show, discords are particularly attractive as anomaly detectors because they only require one intuitive parameter (the length of the subsequence) unlike most anomaly detection algorithms that typically require many parameters. While the brute force algorithm to discover time series discords is quadratic in the length of the time series, we show a simple algorithm that is 3 to 4 orders of magnitude faster than brute force, while guaranteed to produce identical results. We evaluate our work with a comprehensive set of experiments. In particular, we demonstrate the utility of discords with objective experiments on domains as diverse as Space Shuttle telemetry monitoring, medicine, surveillance, and industry, and we demonstrate the effectiveness of our discord discovery algorithm with more than one million experiments, on 82 different datasets from diverse domains.
"
80C740B7	International Conference on Data Mining	maurizio atzori + fosca giannotti + francesco bonchi + dino pedreschi	2005	Blocking anonymity threats raised by frequent itemset mining	database analysis + pattern classification + pattern distortion + anonymity threat blocking + data mining + pattern privacy compliance + data privacy + frequent itemset mining	AuthorProvided Keywords Not Found	In this paper we study when the disclosure of data mining results represents, per se, a threat to the anonymity of the individuals recorded in the analyzed database. The novelty of our approach is that we focus on an objective definition of privacy compliance of patterns without any reference to a preconceived knowledge of what is sensitive and what is not, on the basis of the rather intuitive and realistic constraint that the anonymity of individuals should be guaranteed. In particular, the problem addressed here arises from the possibility of inferring from the output of frequent itemset mining (i.e., a set of item-sets with support larger than a threshold a), the existence of patterns with very low support (smaller than an anonymity threshold k)[M. Atzori et. al, 2005]. In the following we develop a simple methodology to block such inference opportunities by introducing distortion on the dangerous patterns.
7F67C874	International Conference on Data Mining	prem melville + foster provost + raymond j mooney + maytal saartsechansky	2005	An expected utility approach to active feature-value acquisition	data training + pattern classification + random feature acquisitions + data analysis + predictive models + classification tasks + active feature-value acquisition + classification model	AuthorProvided Keywords Not Found	In many classification tasks, training data have missing feature values that can be acquired at a cost. For building accurate predictive models, acquiring all missing values is often prohibitively expensive or unnecessary, while acquiring a random subset of feature values may not be most effective. The goal of active feature-value acquisition is to incrementally select feature values that are most cost-effective for improving the model's accuracy. We present an approach that acquires feature values for inducing a classification model based on an estimation of the expected improvement in model accuracy per unit cost. Experimental results demonstrate that our approach consistently reduces the cost of producing a model of a desired accuracy compared to random feature acquisitions.
7DB0E7F5	International Conference on Data Mining	murat dundar + jinbo bi + bharat rao + glenn fung	2005	Semi-supervised mixture of kernels via LPBoost methods	semisupervised mixture-of-kernel problem + kernel method + column generation + linear programming + boosting algorithm + mixture model + classification model + learning artificial intelligence + LPBoost methods + cross validation + learning (artificial intelligence) + sparse-favoring 1-norm regularization + mixture model complexity + computational complexity	AuthorProvided Keywords Not Found	We propose an algorithm to construct classification models with a mixture of kernels from labeled and unlabeled data. The derived classifier is a mixture of models, each based on one kernel choice from a library of kernels. The sparse-favoring 1-norm regularization method is employed to restrict the complexity of mixture models and to achieve the sparsity of solutions. By modifying the column generation boosting algorithm LPBoost to a more general linear programming formulation, we are able to efficiently solve mixture-of-kernel problems and automatically select kernel basis functions centered at labeled data as well as unlabeled data. The effectiveness of the proposed approach is proved by experimental results on benchmark datasets.
800F9EDD	International Conference on Data Mining	joseph p kenny + tamara g kolda + brett w bader	2005	Higher-order Web link analysis using multilinear algebra	algorithms + text analysis + web pages + HITS algorithm + anchor text + singular vector + algebra + multilinear algebra + higher-order representation + higher-order Web link analysis + matrix theory + Web graph + nonnegative matrix + two dimensions + link analysis + score Web pages + linear algebra + sparse three-way tensor + PageRank algorithm + higher order + hyperlink graph + multilinear PARAFAC tensor decomposition + principal eigenvector + web search engine + eigenvectors + Internet + tensor algebra + hyperlink structure + internet + Web search + dimensions	AuthorProvided Keywords Not Found	Linear algebra is a powerful and proven tool in Web search. Techniques, such as the PageRank algorithm of Brin and Page and the HITS algorithm of Kleinberg, score Web pages based on the principal eigenvector (or singular vector) of a particular non-negative matrix that captures the hyperlink structure of the Web graph. We propose and test a new methodology that uses multilinear algebra to elicit more information from a higher-order representation of the hyperlink graph. We start by labeling the edges in our graph with the anchor text of the hyperlinks so that the associated linear algebra representation is a sparse, three-way tensor. The first two dimensions of the tensor represent the Web pages while the third dimension adds the anchor text. We then use the rank-1 factors of a multilinear PARAFAC tensor decomposition, which are akin to singular vectors of the SVD, to automatically identify topics in the collection along with the associated authoritative Web pages.
5D6B2F09	International Conference on Data Mining	dpa corney + emma byrne + bernard f buxton + david t jones	2005	A Logical Framework for Template Creation and Information Extraction	information extraction + search algorithm + structured data + logical framework + text mining		"
Information extraction is the process of automatically identifying facts of interest from pieces of text, and so transforming free text into a structured database. Past work has often been successful but ad hoc, and in this paper we propose a more formal basis from which to discuss information extraction. We introduce a framework which will allow researchers to compare their methods as well as their results, and will help to reveal new insights into information extraction and text mining practices. One problem in many information extraction applications is the creation of templates, which are textual patterns used to identify information of interest. Our framework describes formally what a template is and covers other typical information extraction tasks. We show how common search algorithms can be used to create and optimise templates automatically, using sequences of overlapping templates, and we develop heuristics that make this search feasible. Finally we demonstrate a successful implementation of the framework and apply it to a typical biological information extraction task.
"
815377E6	International Conference on Data Mining	martin b scholz	2005	On the tractability of rule discovery from distributed data	rule selection + learning artificial intelligence + supervised learning + data mining + distributed processing + predictive accuracy + weighted relative accuracy + rule discovery + learning (artificial intelligence) + utility measure + distributed data	AuthorProvided Keywords Not Found	This paper analyses the tractability of rule selection for supervised learning in distributed scenarios. The selection of rules is usually guided by a utility measure such as predictive accuracy or weighted relative accuracy. A common strategy to tackle rule selection from distributed data is to evaluate rules locally on each dataset. While this works well for homogeneously distributed data, this work proves limitations of this strategy if distributions are allowed to deviate. The identification of those subsets for which local and global distributions deviate, poses a learning task of its own, which is shown to be at least as complex as discovering the globally best rules from local data.
7EB093D0	International Conference on Data Mining	jason r chen	2005	Making subsequence time series clustering meaningful	time series analysis + sequential time series clustering + Euclidean distance metric + pattern clustering + data mining + time series + subsequence vector space + euclidean distance + vector space + distance measure + statistical analysis	AuthorProvided Keywords Not Found	"The startling claim was made that sequential time series clustering is meaningless. This has important consequences for a significant amount of work in the literature, since such a claim invalidates this work's contribution. In this paper, we show that sequential time series clustering is not meaningless, and that the problem highlighted in these works stem from their use of the Euclidean distance metric as the distance measure in the subsequence vector space. As a solution, we consider quite a general class of time series, and propose a regime based on two types of similarity that can exist between subsequence vectors, which give rise naturally to an alternative distance measure to Euclidean distance in the subsequence vector space. We show that, using this alternative distance measure, sequential time series clustering can indeed be meaningful. We repeat a key experiment in the work on which the ""meaningless"" claim was based, and show that our method leads to a successful clustering outcome."
7D6BAE6F	International Conference on Data Mining	frans coenen + paul leng	2005	Obtaining best parameter values for accurate classification	accurate classification + pattern classification + best parameter value + data mining + classification association rule mining + confidence threshold + association rule mining	AuthorProvided Keywords Not Found	In this paper we examine the effect that the choice of support and confidence thresholds has on the accuracy of classifiers obtained by classification association rule mining. We show that accuracy can almost always be improved by a suitable choice of threshold values, and we describe a method for finding the best values. We present results that demonstrate this approach can obtain higher accuracy without the need for coverage analysis of the training data.
7E31DC70	International Conference on Data Mining	hanspeter kriegel + christian bohm + elke achtert + peer kroger	2005	Online hierarchical clustering in a data warehouse environment	density estimator + data warehouse + online data mining + pattern mining + online algorithm + data mining + single link clustering + data structure + knowledge discovery + industrial application + single-link clustering + pattern clustering + data warehouse environment + data grouping + online hierarchical clustering + hierarchical clustering + data structures + data warehouses + OPTICS method	AuthorProvided Keywords Not Found	Many important industrial applications rely on data mining methods to uncover patterns and trends in large data warehouse environments. Since a data warehouse is typically updated periodically in a batch mode, the mined patterns have to be updated as well. This requires not only accuracy from data mining methods but also fast availability of up-to-date knowledge, particularly in the presence of a heavy update load. To cope with this problem, we propose the use of online data mining algorithms which permanently store the discovered knowledge in suitable data structures and enable an efficient adaptation of these structures after insertions and deletions on the raw data. In this paper, we demonstrate how hierarchical clustering methods can be reformulated as online algorithms based on the hierarchical clustering method OPTICS, using a density estimator for data grouping. We also discuss how this algorithmic schema can be specialized for efficient online single-link clustering. A broad experimental evaluation demonstrates that the efficiency is superior with significant speed-up factors even for large bulk insertions and deletions.
7E819378	International Conference on Data Mining	raymond chiwing wong + ada waichee fu + ke wang	2005	Privacy-preserving frequent pattern mining across private databases	privacy-preserving frequent pattern mining + data mining + two dimensions + data integrity + data privacy + database management systems + private database	AuthorProvided Keywords Not Found	Privacy consideration has much significance in the application of data mining. It is very important that the privacy of individual parties is not exposed when data mining techniques are applied to a large collection of data about the parties. In many scenarios such as data warehousing or data integration, data from the different parties form a many-to-many schema. This paper addresses the problem of privacy-preserving frequent pattern mining in such a schema across two dimension sites. We assume that sites are not trusted and they are semi-honest. Our method is based on the concept of semi-join and does not involve data encryption which is used in most previous work. Experiments are conducted to study the efficiency of the proposed models.
7E87C831	International Conference on Data Mining	albrecht zimmermann + bjorn bringmann	2005	CTC - correlating tree patterns for classification	tree pattern correlation + pattern classification + structural classification + k most discriminative pattern + data mining + trees (mathematics) + tree mining + pruning technique	AuthorProvided Keywords Not Found	We present CTC, a new approach to structural classification. It uses the predictive power of tree patterns correlating with the class values, combining state-of-the-art tree mining with sophisticated pruning techniques to find the k most discriminative pattern in a dataset. In contrast to existing methods, CTC uses no heuristics and the only parameters to be chosen by the user are the maximum size of the rule set and a single, statistically well founded cut-off value. The experiments show that CTC classifiers achieve good accuracies while the induced models are smaller than those of existing approaches, facilitating comprehensibility.
5AB9664E	International Conference on Data Mining	like gao + xiaoyang sean wang	2005	Feature selection for building cost-effective data stream classifiers	pattern classification + decision models + cost effectiveness + classification cost estimation + data handling + classification relevance + feature selection + cost-effective data stream classifier + cost estimation	AuthorProvided Keywords Not Found	A stream classifier is a decision model that assigns a class label to a data stream, based on its arriving data. Various features of the stream can be used in the classifier, each of which may have different relevance to the classification task and different cost in obtaining its value. As time passes by, some less costly features may become more relevant, but the time needed for decision may be considered as a cost. A challenge is how to balance the different costs when building a cost-effective classifier. This paper proposes a new feature selection strategy that extends the traditional relief algorithm in two aspects: (1) estimate the classification cost associated with each feature, and (2) order all the features with a score that combines both cost estimation and classification relevance. A classifier is then built with the selected features using a traditional classification method. Experimental results show that classifiers constructed with this strategy are indeed cost effective.
7D7B804D	International Conference on Data Mining	shohei hido + hiroyuki kawano	2005	AMIOT: induced ordered tree mining in tree-structured databases	tree-structured databases + right-and-left tree join + serial tree extension + tree structure + data mining + frequent subtree mining + AMIOT + tree data structures + xml database + induced ordered tree mining + frequent ordered subtrees	AuthorProvided Keywords Not Found	Frequent subtree mining has become increasingly important in recent years. In this paper, we present AMIOT algorithm to discover all frequent ordered subtrees in a tree-structured database. In order to avoid the generation of infrequent candidate trees, we propose the techniques such as right-and-left tree join and serial tree extension. Proposed methods enumerate only the candidate trees with high probability of being frequent without any duplication. The experiments on synthetic dataset and XML database show that AMIOT reduces redundant candidate trees and outperforms FREQT algorithm by up to five times in execution time.
7E6103E7	International Conference on Data Mining	g miraglia + o m donzelli + g de nicolao + f di palma	2005	Process diagnosis via electrical-wafer-sorting maps classification	semiconductor device manufacture + automatic classification + pattern classification + fault diagnosis + commonality analysis + data mining + fault detection + process planning + semiconductor manufacturing + electrical wafer test map + electrical-wafer-sorting maps classification + process diagnosis	AuthorProvided Keywords Not Found	The commonality analysis is a proven tool for fault detection in semiconductor manufacturing. This methodology extracts subsets of production lots from all the available data. Then, data mining techniques are used only on the selected data. This approach loses part of the available information and does not discriminate among the lots. The new methodology performance the automatic classification of the electrical wafer test maps in order to identify the classes of failure present in the production lots. Subsequently, the proposed procedure uses the process history of each wafer to create a list of the root cause candidates. This methodology is the core of the software tool ACID which is currently used for process diagnosis at the Agrate site of the ST Microelectronics. A real analysis is presented.
7E03220E	International Conference on Data Mining	henri briand + julien blanchard + regis gras + fabrice guillet	2005	Using information-theoretic measures to assess association rule interestingness	association rule + directed information ratio + association rule discovery + data mining + rule interestingness measure + information-theoretic measures + association rule interestingness + information theory	AuthorProvided Keywords Not Found	Assessing rules with interestingness measures is the cornerstone of successful applications of association rule discovery. However, there exists no information-theoretic measure which is adapted to the semantics of association rules. In this article, we present the directed information ratio (DIE), a new rule interestingness measure which is based on information theory. DIR is specially designed for association rules, and in particular it differentiates two opposite rules a → b and a → b~. Moreover, to our knowledge, DIR is the only rule interestingness measure which rejects both independence and (what we call) equilibrium, i.e. it discards both the rules whose antecedent and consequent are negatively correlated, and the rules which have more counter-examples than examples. Experimental studies show that DIR is a very filtering measure, which is useful for association rule post-processing.
802717CC	International Conference on Data Mining	james bailey + xiaonan ji + guozhu dong	2005	Mining minimal distinguishing subsequence patterns with gap constraints	minimal distinguishing subsequence patterns + relational data + protein comparison + transaction data + maximum gap constraint + pattern mining + data mining + sequential classification model + ConSGapMiner + document comparison + transactional data + contrast information	AuthorProvided Keywords Not Found	Discovering contrasts between collections of data is an important task in data mining. In this paper, we introduce a new type of contrast pattern, called a minimal distinguishing subsequence (MDS). An MDS is a minimal subsequence that occurs frequently in one class of sequences and infrequently in sequences of another class. It is a natural way of representing strong and succinct contrast information between two sequential datasets and can be useful in applications such as protein comparison, document comparison and building sequential classification models. Mining MDS patterns is a challenging task and is significantly different from mining contrasts between relational/transactional data. One particularly important type of constraint that can be integrated into the mining process is the maximum gap constraint. We present an efficient algorithm called ConSGapMiner, to mine all MDSs according to a maximum gap constraint. It employs highly efficient bitset and Boolean operations, for powerful gap based pruning within a prefix growth framework. A performance evaluation with both sparse and dense datasets, demonstrates the scalability of ConSGapMiner and shows its ability to mine patterns from high dimensional datasets at low supports.
